{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SONAR : classification binaire rocher(R) ou mine (M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---------------------------------------------\n",
    "##### CHARGEMENT DES OBSERVATIONS\n",
    "#---------------------------------------------\n",
    "\n",
    "À faire : validation et comparaiosn des méthodes de scaling, sauvegarde des poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#peux faire : \n",
    "#import tensorflow as tf \n",
    "#print(tf.__version__)\n",
    "\n",
    "#autre version \n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "\n",
    "\n",
    "#sequential ajoute les couche de maniere sequentielle, cest une classe initalemnt vide \n",
    "#qui va prendre sequentiellmnt , une couche d'entree, puis fully connected etc..\n",
    "from tensorflow.keras.models import Sequential\n",
    "#charge les types de couche \n",
    "#y'en a pour CNN 1D , faut faite 'chift tab'\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "#optimisers basés sur la SGD: desc gradient stochatic\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Garantir la reproductibilité des résultats \n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1' #  c'est la ligne la plus importante\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' #  c'est facultatif\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                2.4.1                    pypi_0    pypi\n",
      "tensorflow-estimator      2.4.0                    pypi_0    pypi\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar = pd.read_csv(\"sonar.all-data.csv\", header = None)\n",
    "sonar.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sonar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we will look for empty values in each column\n",
    "sonar.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###EDA\n",
    "sonar[range(60)].boxplot(figsize= (16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation des jeux d'apprentissage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = sonar[range(60)].values\n",
    "\n",
    "#On ne prend que les libellé\n",
    "y = sonar[60].values\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.20, random_state=42, stratify = y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.030173</td>\n",
       "      <td>0.039851</td>\n",
       "      <td>0.045374</td>\n",
       "      <td>0.056046</td>\n",
       "      <td>0.076060</td>\n",
       "      <td>0.106449</td>\n",
       "      <td>0.124832</td>\n",
       "      <td>0.140512</td>\n",
       "      <td>0.187339</td>\n",
       "      <td>0.213986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.011189</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.006605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.024730</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.046772</td>\n",
       "      <td>0.055510</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.090071</td>\n",
       "      <td>0.125158</td>\n",
       "      <td>0.138388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>0.005932</td>\n",
       "      <td>0.005134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.019825</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>0.067825</td>\n",
       "      <td>0.081925</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.097875</td>\n",
       "      <td>0.118125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022650</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>0.035950</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.064650</td>\n",
       "      <td>0.092250</td>\n",
       "      <td>0.115400</td>\n",
       "      <td>0.114050</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.036725</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.060275</td>\n",
       "      <td>0.069575</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.142425</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.243725</td>\n",
       "      <td>0.271250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.010775</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.010175</td>\n",
       "      <td>0.008575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  166.000000  166.000000  166.000000  166.000000  166.000000  166.000000   \n",
       "mean     0.030173    0.039851    0.045374    0.056046    0.076060    0.106449   \n",
       "std      0.024730    0.035211    0.039062    0.046772    0.055510    0.061963   \n",
       "min      0.003600    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013125    0.015200    0.019825    0.025700    0.038425    0.067825   \n",
       "50%      0.022650    0.029850    0.035950    0.045100    0.064650    0.092250   \n",
       "75%      0.036725    0.053200    0.060275    0.069575    0.103875    0.142425   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  166.000000  166.000000  166.000000  166.000000  ...  166.000000   \n",
       "mean     0.124832    0.140512    0.187339    0.213986  ...    0.016357   \n",
       "std      0.064102    0.090071    0.125158    0.138388  ...    0.012772   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.081925    0.083000    0.097875    0.118125  ...    0.008600   \n",
       "50%      0.115400    0.114050    0.159600    0.185600  ...    0.014000   \n",
       "75%      0.154200    0.172600    0.243725    0.271250  ...    0.021225   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  166.000000  166.000000  166.000000  166.000000  166.000000  166.000000   \n",
       "mean     0.013502    0.010960    0.011189    0.009494    0.008554    0.008206   \n",
       "std      0.010200    0.007405    0.007647    0.007461    0.005927    0.006133   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007125    0.004925    0.005325    0.003925    0.004625    0.003700   \n",
       "50%      0.011100    0.009950    0.009550    0.007500    0.007250    0.006600   \n",
       "75%      0.017200    0.015050    0.015000    0.012400    0.011550    0.010775   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  166.000000  166.000000  166.000000  \n",
       "mean     0.008122    0.007935    0.006605  \n",
       "std      0.006363    0.005932    0.005134  \n",
       "min      0.000300    0.000200    0.000600  \n",
       "25%      0.003750    0.003925    0.003200  \n",
       "50%      0.006250    0.006800    0.005450  \n",
       "75%      0.010275    0.010175    0.008575  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_x).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(train_x).boxplot(figsize=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_sc = StandardScaler().fit(train_x)\n",
    "scaler_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0286247 , 0.03794036, 0.0428247 , 0.05338133, 0.07643614,\n",
       "       0.10333855, 0.11932651, 0.13161084, 0.16948193, 0.19665301,\n",
       "       0.22418976, 0.24031566, 0.26485   , 0.29034157, 0.31172229,\n",
       "       0.36555301, 0.39679096, 0.4366247 , 0.4954488 , 0.56041325,\n",
       "       0.60596988, 0.62476386, 0.65314578, 0.68178253, 0.68437349,\n",
       "       0.70789337, 0.70761566, 0.69688434, 0.64225904, 0.58462048,\n",
       "       0.5098    , 0.44326205, 0.42563494, 0.40759337, 0.38726205,\n",
       "       0.38098012, 0.35733795, 0.3306994 , 0.32505602, 0.31957229,\n",
       "       0.29471988, 0.28457169, 0.24784458, 0.215     , 0.19972952,\n",
       "       0.16673795, 0.12838253, 0.09435663, 0.05242651, 0.02023193,\n",
       "       0.01628494, 0.01318795, 0.01079759, 0.01060783, 0.0091988 ,\n",
       "       0.00829458, 0.00792711, 0.00768434, 0.00802048, 0.00669217])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_sc.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02158398, 0.03361772, 0.03978886, 0.0482875 , 0.05652321,\n",
       "       0.05620119, 0.06028425, 0.0846981 , 0.1148206 , 0.12200883,\n",
       "       0.11952973, 0.12573793, 0.12719459, 0.15430946, 0.19699562,\n",
       "       0.22390815, 0.25342716, 0.25407037, 0.25682948, 0.26573752,\n",
       "       0.26728732, 0.26568871, 0.24808184, 0.23048422, 0.24450955,\n",
       "       0.2252573 , 0.2323737 , 0.22782409, 0.23457152, 0.21727436,\n",
       "       0.21380545, 0.21544667, 0.20938755, 0.23652779, 0.26536215,\n",
       "       0.2664083 , 0.23980422, 0.20888013, 0.19340289, 0.17989078,\n",
       "       0.17200737, 0.17041828, 0.14092523, 0.13271108, 0.15159265,\n",
       "       0.13356627, 0.08705829, 0.06131978, 0.03500544, 0.01325215,\n",
       "       0.01153662, 0.00953178, 0.00677196, 0.00706417, 0.0072206 ,\n",
       "       0.00567984, 0.00568962, 0.0062646 , 0.00648339, 0.00526256])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_sc.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler_sc.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_sc = scaler.transform(train_x)\n",
    "test_x_sc = scaler.transform(test_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAOFCAYAAABwUV8JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAB6N0lEQVR4nO39f5Rc130YeH4f0CRMUTSVSRyNKEQkMsfJNtgKzTBxYh0kgzJsQDTtMbPejFzQRlLYoQ7iYZkZewKArLNhsFGJBD3SxGnF4tgprKBZs6yJPeE6hClAAzSc4GicWB6ZThu9zsg2JSPyTiYzGliiYOKH3/7RqGZ1o6v6VVd3vffqfT7n4KCrqr/9blfdrnrfd+/93iRN0wAAAIBx2ZZ3AwAAAKgWiSgAAABjJREFAABgrCSiAAAAjJVEFAAAgLGSiAIAADBWU3kd+E/8iT+R3nfffX0ff/311+POO+/c0M/eaGwexxQ7ntiytVdssY8ptvixZWuv2GIfU+x4YsvWXrHjiS1be8Wu9Gu/9mv/IU3Tb1vzwTRNc/n30EMPpYPMz88PfHwrYvM4ptjxxJatvWKLfUyxxY8tW3vFFvuYYscTW7b2ih1PbNnaK3aliPhC2icfNDUXAACAsZKIAgAAMFYSUQAAAMZKIgoAAMBYSUQBAAAYK4koAAAAYyURBQAAYKwkogAAAIyVRBQAAICxkogCAAAwVhJRAAAAxkoiCgAAwFhJRAEAABgriSgAAABjJREFAABgrCSiAAAAjJVEFAAAgLGSiAIAADBWElEAAADGSiIKAADAWElEAQAAGCuJKAAAAGMlEQUAAGCsJKIAAACMlUQUAACAsZKIAgAAMFYSUQAAAMZKIgoAAMBYSUQBAAAYK4koAAAAYyURBQAAYKwkogAAAIyVRBQAAICxkogCAAAwVusmokmSnEiS5N8nSbLQ5/EkSZJ/lCTJl5Ik+Y0kSf785jcTAACASZFlRPRTEfHeAY8/HBHffvPfhyPik6M0qNPpxMzMTOzbty9mZmai0+lseWwexxQ7XGyj0Yhv+ZZviVqtFt/yLd8SjUZjy485ijI+xwDcqozv52WLLVt7xeoXYkePjYiYWu8b0jT9F0mS3DfgW34wIj6dpmkaEb+SJMnbkiR5R5qmvz9US2Lpl2k2m9Fut+PGjRuxffv2mJ2djYiIer2+JbF5HFPscLGNRiNeeOGFOH78eOzevTsuXrwYR44ciYiIubm5LTnmKMr4HANwqzK+n5cttmztFatfiB09dlmapuv+i4j7ImKhz2MvR8SenttnI+IvrPczH3rooXS1+++/Pz137lyapmk6Pz+fpmmanjt3Lr3//vtv+d7Nis3jmGKHi92xY0f6sY99bEXsxz72sXTHjh1bdsxe3disyvgc9xr29807tmztFTue2LK1V2wxj1nG9/OyxZatvWLHE1u29ortHxsRX0j75IPrjohmkKyV3675jUny4Viavhtvf/vb4/z58yseX1xcjBs3bsT58+fjG9/4Rpw/fz5u3LgRi4uLt3zvahuNzeOYYoeLfeONN2L37t0rYnfv3h1vvPHGlr22ERG1Wu2W++bn59eNK+NzHLHx33ezY7PG5RVblOeparFe28mNLfJrW8b387LFlq29YvULsaPHLuuXoabZR0T/24io99z+rYh4x3o/04hoOWObzWZ6//33p9u2bVtxeyuPm/eI6L1HXh7q+8v42vYa9vfNO7Zs7RU7ntiytVdsMY9ZxvfzssWWrb1ixxNbtvaK7R8bA0ZENyMRfSQiXomlkdG/HBH/OsvPXCsRffHFF9Ndu3al586dSz/3uc+l586dS3ft2pW++OKL6z4ZG43N45hljX3iiSfSqamp9GMf+1j6yiuvpB/72MfSqamp9IknnijkcUc5Zq9hT1zK+Nr2clIqdhJiy9ZescU8Zhnfz8sWW7b2itUvxA4XO1IiGhGdiPj9iLgWEZciYjYiDkXEoZuPJxHxjyPityPi30SG9aFpn0S0+0v1jrgNcxK90dg8jlnG2FFGREdt8/79+9MkSdKISJMkSffv37/lx+zayElP2V7bXk5KxU5CbNnaK7a4xyzj+3nZYsvWXrH6hdjssSOPiG7Fv36JaFd3iHcjNhqbxzHLFLtt27b06tWrK2KvXr2abtu2bUuPuxkjfaM8T6Oc9JTlte3lpFTsJMSWrb1ii33MNC3n+3nZYsvWXrHjiS1be8WuNCgRzbKPKERExPT0dFy4cGHFfRcuXIjp6ektPW6r1Yp2ux21Wi2mpqaiVqtFu92OVqu1pccFAAC2hkSUzJrNZszOzsb8/Hxcv3495ufnY3Z2NprN5pYed3FxMfbs2bPivj179sTi4uKWHhcAANgam7F9CxXR3Zy20WjE4uJiTE9PR6vVyr5p7QZ1R2J7y++PYyQWAADYGkZEGUq9Xo+FhYU4e/ZsLCwsbHkSGpHfSCwA5KXT6cTMzEzs27cvZmZmotPp5N0kgE1lRJTCy2skFgBG0el0otVqLX92NZvNTJ9dnU4nms1mtNvtuHHjRmzfvj1mZ2cjInz2ARNDIkop1Ov1qNfrcf78+di7d2/ezQGAgUZJJnuL9HU/99rtdjQaDYkoMDFMzQUA2GSjVHxXpA+oAokoAEAfG12rOUoymdd2aQDjZGouAMAaRpleO0rF926Rvu5xu0X67J8NTBKJKADAGkZZqzlKMqlIH1AFElEAgDWMMr121GRSkT5g0klEAQDWMD09HceOHYuXXnppOZl89NFHM6/VlEwC9CcRBQBYQ61Wi+PHj8fx48dj9+7dcfHixThy5EgcOnQo76YBlJ5EFABgDfPz83HkyJE4ceLE8ojokSNH4qWXXsq7aQClZ/sWAIA1LC4uxjPPPBMLCwtx9uzZWFhYiGeeecZ+nn1sdKsboJqMiAIArGGULViqZpStboBqMiIKALCG7hYs8/Pzcf369eUtWJrNZt5N2zIbHdXs3epmamoqarVatNtte58CfRkRBQBYQ9X28xxlVHOUrW6AajIiCgDQR71eX7FGdFKT0IjRRjW705h7mcYMDCIRpRQUQACgSvL43BtlVLOK05iB0Ziay9h0Op1otVrL05uazWamK8sKIABQJXl97o1SnKlq05iB0RkRZSy6H6pzc3Nx+vTpmJubi2azmekKrwIIAOQlj5HJvD73Rh3VrNI0ZmB0RkQZi94P1fPnz8fevXuj3W5Ho9FQAAGAQsprZDKvzz2jmsA4GRFlLEb5UFUAAYA85DUymefnnlFNYFwkoozFKB+qCiAAkIe8Ribz/NxTHBAYF1NzGYvuh2p3elP3QzXLVWVThQDIwyjFe0aR1+ee4oDAOElEGYtRP1Tr9XrU6/Xl9aUAsNVGuYg6qjw+90ap5wAwLIkoYyOZBKBMqjYjR3FAYJysEQUA6KNKxXsUBwTGSSIKAIDigMBYmZoLAEDlpiID+TIiCgBARFRrKjKTyzZE5WBEFAAAmAi2ISoPI6IAAMBE6N2GaGpqKmq1WrTb7bFsu8RwJKIAAMBEsA1ReUhEAQCAiWAbovKQiAIAwISrSgEf2xCVh2JFAAAwwapUwMc2ROVhRBQAACZY1Qr42IaoHCSiAAAwwRTwoYgkogAAMMEU8KGIJKKwBapSEAAAKD4FfCgixYpgk1WpIAAAUHwK+FBERkRhk1WtIAAAUHwK+FA0ElHYZAoCAADAYBJR2GQKAgAAwGASUdhkCgIAAMBgihXBJlMQAAAABjMiykTLaxsVBQEAAKA/iShDKdP+mN1tVObm5uL06dMxNzcXzWaz0G0GoFjK9LkHUCam5pJZ2fbH7N1G5fz587F3795ot9vRaDQK2V4AiqVsn3sAZWJElMzKtj+mbVQAGEXZPvcAykQiSmZlS+xsowLAKMr2uQdQJhJRMitbYmcbFQBGUbbPPYAysUaUzLqJXXetTDexK+oUJduoADCKsn3uAZSJRJTMypjY1ev1qNfry8WKACCrMn7uAZSFRBQAoA8XNAG2hkSUzJSxBwCKpNPpRKvVWh6xbjabzkmgJCSiZGZfTgCgKFwgh3JTNZfMlLEHAIrCPq9QbhJRMlPGvvg6nU7MzMzEvn37YmZmJjqdTt5NAoAt4QI5lJtElMzsy1ls3SlKc3Nzcfr06Zibm4tmsykZBWAiuUAOo8tzEMMaUTJTxr7YrOEFoErs8wqjyXudtUSUoShjX1ymKAFQJS6Qw2jyHsQwNRcmhClKAFRNvV6PhYWFOHv2bCwsLEhCYQh5D2JIRGFCWMMLAEBWeQ9imJoLE8IUJQAAssp7nbVEFCaINbwAAGSR9yCGRBQAAKCC8hzEsEYUAACAsZKIAgAAMFYSUQAAAMZKIgoAAMBYSUQBAAAYK4koAAAAYyURZSidTidmZmZi3759MTMzE51OJ+8mAQAAJWMfUTLrdDrRbDaj3W7HjRs3Yvv27TE7OxsRMbaNb4HJ9sCxM3H5yrUV99139FRERNx9x23x6jP782gWbEin04lWq7W8UXyz2fR5CXCTRJTMWq1WtNvtqNVqy5vettvtaDQaPliBTXH5yrV47blHlm/3brDdTUihDFy8BRjM1FwyW1xcjD179qy4b8+ePbG4uJhTiwCgmHov3k5NTUWtVot2ux2tVivvpgEUgkS0gja6znN6ejouXLiw4r4LFy7E9PT0VjQTAErLxVuAwUzNrZhRpgo1m82YnZ1djp2fn4/Z2VlXdwFgle7F21qttnyfi7cAb5KIVswo6zy7jzcajeXCC61Wy1oXAFjFxVuAwSSiFTPqVKF6vR71en1FAREAYCUXbwEGk4hWjKlCwKRavfVLb5VdW7+QBxdvAfqTiFaMqULApOrd+mX1ib+tXwCgWFTNrZh6vR6tVisajUYcOHAgGo2GqUIA0MdGK81DP/oULDEiWkGmCgHA+jqdTjz55JNx5513Rpqm8frrr8eTTz4ZEetXmoe1jLJ7AUwaI6IAAGs4fPhwbN++PU6cOBFnzpyJEydOxPbt2+Pw4cN5N42S6t29YGpqKmq1WrTbbUukqCSJKADAGi5duhSf/vSnVyQNn/70p+PSpUt5N23LmDa6tUbdvQAmiam5AACYNjoGdi+ANxkRBQBYw86dO+ODH/xgzM/Px/Xr12N+fj4++MEPxs6dO/Nu2pYwbXTrdXcv6O1Ts7Oz0Ww2824ajJ1EFABgDc8//3xcv349HnvssThw4EA89thjcf369Xj++efzbtqWKOO00bJNJbZ7QXajvLZl6xdVZWoubIEkSW65L03THFoCwEZ1k4PuiOCdd94ZH/3oRyc2aSjbtNGyTiW2e8H6Rnlty9ovqsiIKGyBNE0jTdO498jLy18DUD71ej0WFhbi7NmzsbCwMNEnsmWbNmoq8eQa5bXVL8rDiCgAAMtJdqPRiMXFxZieni70tNEyTiWOWBqxa7Vay89xs9ks7HOcl1Fe27L2iyoyIgoAUDB5rXEr0whwdypxryJPJY54c9ro3NxcnD59Oubm5qLZbFrDuMoor20Z+0VVGRFlornqCBvzwLEzcfnKtRX33Xf0VERE3H3HbfHqM/vzaBZUgjVu2XSnEnefp+5U4iJPweydNtpdI9put6PRaHhte4zy2paxX1SVRJSJ5YMcNu7ylWvx2nOPLN/uLarRTUiBrSFZyaZsU4kjTBvNapTXtoz9oqokokwsH+RU3aBRzYitG9k0mgqjyTNZKVvV97JVoC1bZeI8jfLalq1fVJVElInlqiNVN2hUM2LrRjaNpsJo8kxWuknnfUdPrfg7ZnOYNgpvkogysVx1BKCMJCuTy7RReJNElInlgxyAMpKsTDbTRmGJRJSJ5YMcgLKSrACTTiLKRPNBDgAAxbMt7wYAAABQLRJRAIAJ0ul0YmZmJvbt2xczMzPR6XTybhKMlb+BcjA1FwBgQnQ6nWg2m8uF+rZv3x6zs7MREWokUAn+BsrDiCgAwIRotVrRbrejVqvF1NRU1Gq1aLfbE1sx3sgXq1Xtb6DMjIjCBEmS5Jb7upuTAzD5FhcXY8+ePSvu27NnTywuLubUoq0z6shXp9OJVqu1XFm/2WwaMZsAVfobKDsjojBB0jSNNE3j3iMvL38NQHVMT0/HhQsXVtx34cKFmJ6ezqlFW2eUka9uEjs3NxenT5+Oubm5aDabRlQnQJX+BspOIgoAMCGazWbMzs7G/Px8XL9+Pebn52N2djaazWbeTdt0o4x8mb45uar0N1B2puZSCqbPAMD6up+NjUZj+TOz1WpN5Gdmd+SrVqst35d15Mv0zclVpb+BspOIUniqnwFAdvV6Per1epw/fz727t2bd3O2THfkq3t+0B35yjKqOUoSS/FV5W+g7EzNpfBMnwGA7KpSSbZer0er1YpGoxEHDhyIRqOReeTL9E3InxFRCs/0GWCrPXDsTFy+cm359n1HTy1/ffcdt8Wrz+zPo1kwtKrNItroyJfpm5A/iSiFZ/oMZbc6yYmQ6BTN5SvX4rXnHomIuOWEtve1gqLrnUXU7cvtdjsajYYkaxXTNyFfElEKb5Q1IFAEvUlOhEQH2DpmEQFlIRGl8EyfAYBszCICykKxIsZmlOIJ9Xo9FhYW4uzZs7GwsCAJBYA1VK0IT1UKM8EkMiLKWIxaPME+ogCwvirNIqpaYSbGwznn+EhEGYtRiif4oAGA7KpShEdhJjabc87xMjWXsRileMKo+4gmSRK1Wi2SJIkkSTbUfgCgWBRmYrPZu368JKKMRbd4Qq+sxRNG/aBJ0zTuPfJypGkaaZpmbzQAUFijnFvAWlzcGC+JKGMxSvEEHzQAwGpVK8zE1nPOOV7WiDIWoxRPsI8oALBavV6Pz3/+8/Hwww/HG2+8ETt27IjHH3+88Gv5FMMpLuec4yURZWw2WjyhShUAAYBsOp1OnDp1Kl555ZUVhWXe8573FPYcQTGcYnPOOV4SUUqhKhUAYbUHjp2Jy1eurbjvvqOnlr+++47b4tVn9o+7WQC5a7VacfDgwRVJw8GDBwudOKj0C2+SiAIU2OUr1+K15x5Zvr36YkxvUgpQJRcvXoxvfvObt4wuvvbaa3k3rS/FcIrNiPV4KVYEAEDp3H777fHEE0+s2GrjiSeeiNtvvz3vpvU1PT0dx44di5mZmdi3b1/MzMzEsWPHFMMpCNu3jJcRUQAASufq1asxNzcXDz744HJhmbm5ubh69WreTeurVqvF8ePH4/jx47F79+64ePFiHDlyJA4dOpR30wgj1uNWuERUJTGgqFav17RWEyA/u3fvjkcffXTFGtH3v//98dJLL+XdtL7m5+fjyJEjceLEieU2HzlypNBtrpLu9i21Wm35vmG2b5HHDKdQiah52UCR9a7XtFYTIF/NZnPN88YiT6NcXFyML37xi/GRj3xk+XPk2rVr8eyzz+bdNGK07VvkMcMrVCKqkhgAAFmUcauNUUfc2Fqj9Cl5zPAKVaxocXExLl26tGIB96VLl8zLBgDgFvV6PRYWFuLs2bOxsLBQ+BP+7ojb/Px8XL9+fXnErdls5t00btpon7K+dHiFGhG955574vDhw/Hiiy8uD2kfPHgw7rnnnrybBgAAIynjKC7ZGO0eXqFGRCMikiQZeBsAYFySJIkkSaJWqy1/DaMo2yhuGXU6nRUzLDudzpYf02j38Ao1IvrVr341PvWpT624SnT8+PH40Ic+lHfTYGxUXAMojjRNI2KpIFm3WBnF4TOT1fIqGmS0e3iFSkSnp6dj586dsbCwsLzId35+3pA2laHiGgBk4zOTteRZNKher0e9Xr+lsj5rK9TUXEPaVF3vm+fU1FTUarVot9uFLkUPAHnwmclaFA0qj0IlovV6PVqtVjQajThw4EA0Gg1D2lSKN08Aymrc6/J8ZrKWbtGgXooGFVOhEtEIC7ipNm+eAJRRd5rs3NxcnD59Oubm5qLZbG5pMlrFz8w8ivCUjRmW5VGoNaJQdd03z+56l+6bp2lGABRZHuvyqvaZaU1sNooGlYdEFArEmycAZZTHNNlRPzPLVnE3zyI8ZaNoUDlIRKFgvHkCUDbdabK1Wm35vnFMk93oZ2YZRxetiWXSFG6NKFsvr/UF1jUAwGQq27q8MlbcreKaWLZenufnRkQrJq8rgGW88ggAZZTHlNOyLS0p4+hi1dbEsvXyPj83IloxeV0BLOOVRwAomzyq13aVaeeDMo4u2uaQzZb3+blEtGLyugJYxiuPAFA2eZ9YlkXZphJ3lSnZp/jyPj83Nbdi8iomkNdxAaBK8j6xLIuyTSWGrZD3+XmmEdEkSd6bJMlvJUnypSRJjq7x+N1JkvzzJEleTZLkN5Mk+Zub39TJk8fi4LyuAJb1yiMAlEkZp5zmxegiVZf3+fm6I6JJkmyPiH8cEd8bEZci4leTJPnFNE0v9nzbfxERF9M0/YEkSb4tIn4rSZKfTdP06pa0egLktTg4ryuArjwCwNZT0GaylW3vU4ot7/PzLFNzvzMivpSm6e9ERCRJ8nMR8YMR0ZuIphFxV5IkSUS8NSL+j4i4vsltnSh5bkqc1z6V9scEgK2V94nluFUpMcu7wimTKc/z8yxTc98ZEb/Xc/vSzft6fSIipiPiqxHxbyLiyTRN/2hTWjihrOEAALZCXlNOx73kKM8KwXlQiIpJk2VENFnjvnTV7QMR8esR8d0R8Z9ExOeSJPmXaZr+wYoflCQfjogPR0S8/e1vj/Pnz/c96De+8Y2Bjw+y0dhxHvNd73pXfOITn4gHH3xwOfaLX/xivOtd7xrq5+TxPJU1dqNxecWO8ruOctwyxo7zmN3vX+v1GfSzeh+bhNj1nre8Y4f9XUeN3ej3it1YbNnaW8bPzIjhft+zZ89Gu92Ov/t3/27s2rUrfvd3fzd+/Md/PC5evBj79u3L9DOGbe/TTz8dP/qjPxpJksQf/uEfxlvf+tZoNBrx9NNPxzve8Y7MP6csr8/i4mLcuHEjzp8/vxx748aNWFxcnOhzx7K1V+wQ0jQd+C8ivisiTvfcfioinlr1Paci4q/03D4XEd856Oc+9NBD6SDz8/MDH9+K2HEe88UXX0x37dqVnjt3Lv3c5z6Xnjt3Lt21a1f64osvbulxqxp775GXN3zMvGJHeZ7K+PtuNHacx+z9/tWvz6Cftfqxsseu97wVIXaY33XU2I1+r9ji/81vVmzZPjPTdPjf9/7770/PnTu34rjnzp1L77///sw/Y9j2btu2Lb169eqK2KtXr6bbtm0b6ueU5fXZjOd4I8fNO7Zs7RW7UkR8Ie2TD2YZEf3ViPj2JEl2RcS/i4gfjoiDq77nKxGxLyL+ZZIkb4+IPxsRvzN8WlwdVVvDAQBMrjyWHOW99cS4KUTFpFk3EU3T9HqSJE9ExOmI2B4RJ9I0/c0kSQ7dfPyFiPgHEfGpJEn+TSxN5T2Spul/2MJ2TwTFe2D8Hjh2Ji5fubZ8+76jp5a/vvuO2+LVZ/bn0SyATZNHAZ88ksKqJWYGMZg0WUZEI03TX4qIX1p13ws9X381Ipy9AYV3+cq1eO25RyIibrkI1JuUApRRXpVV80gKq5iYGcRgkmRKRAEAKL68tofLc59yiRmUU5btW5gw4y6vDgCMR57bw+W1bQxQTkZEK8ZmyAAwuapWwAcoLyOiFWMzZACYXN21mvPz83H9+vXltZrNZjPvpgGsYES0YvKcsgMAbK0qFvDJQx6ViWHSSEQrxpQdAJhsCvhsLcucYHOYmlsxpuwAAGycZU6wOYyIVowpOwAAG59ea5kTbA6JaAWZsgMAVNko02stc4LNYWouQ7EHKQBQdqNMr7XMCTaHEVEyszgfAJgEo0yvtcwJNocRUTKzOB8AmATd6bW9hpleW6/XY2FhIc6ePRsLCwuSUNgAI6JkZnE+ADAJms1mvO9974s777wzvvzlL8e9994br7/+evzkT/5k3k2DyijciKg1iMU16tVDAIDNtBnnjUmSbEHLgPUUakTUGsRi6y7O774+3cX5puYCAOM2ynljq9WKz3zmM1Gr1ZZ3EZifn49GozGx55wb3a4GtkqhRkStQSy2er0erVYrGo1GHDhwIBqNxlCL8412AwCbZZTzxqotN+om7XNzc3H69OmYm5uLZrPpXIxcFWpEtGpvCmW00T1IjXYDAJtplPPGqu0F2pu0d8/h2u32RI8AU3yFGhG1BnFyGe0GoGqSJIkkSaJWqy1/zeYZ5byxanuBGuyhiAqViFbtTaFKvAECUDVpmkaapnHvkZeXv2bzjHLeOOpyo1HksVTJYA9FVKipuTYInlxVmwIDAGytUc8bN7rcaBR5LVVScJIiKlQiGpHPmwJbzxsgALDZynbemNdaTYM9FFHhElEmkzdAAKDq8lyqVLaknclXqDWiTLZ6vR4LCwtx9uzZWFhYkIQCAJWS51pN2+hRNEZEAQBgDPJaqmQbPYpIIgoAAGOQ11Klqu0jutZWSapWF49EFABggjgJL7Y81mpWbRu9bn+/7+ipeO25R3JuDf1YIwoAMEHsX8pq9hGliCSiAABUTpWK93TXps7Pz8f169eX16Y2m828m0aFmZoLAEClVK14j230KCIjogAAlNJGRzV7i/dMTU1FrVaLdru95dVr82QbPYrGiChD6XQ60Wq1lq+mNZtNb2QAwNiNMqpZteI9UERGRMms0+nEk08+Ga+//npERLz++uvx5JNPTvSaCgCgmEYZ1VS8B/InESWzw4cPx9TUVJw4cSJOnz4dJ06ciKmpqTh8+HDeTQMAKmaUUU3FeyB/puaS2aVLl+LMmTMrNkM+efJk7N+/P++mAQAV0x3VrNVqy/dlHdVUvKccVu+JayuiyWJEFACA0hl1VFPxnuKzH+5kMyJKZjt37owPfOAD8eKLL8aNGzdifn4+PvCBD8TOnTvzbhoAUDFGNaHcjIiS2fPPPx83btyIxx57LPbv3x+PPfZY3LhxI55//vm8mwYAlNRGt2CJKOeo5ii/7yixUDRGRMms++bearUiSZK4884746Mf/Wgp3vQBgOLpVuS/8847I+LNivwR62/BUkajbDkzSiwUkRFRhlLGK48AQDFVrSL/KFvOjBILRSQRBQAgF5cuXYqTJ0+uSK5OnjwZly5dyrtpW2KULWdGiYUikohSCkmSRJIkUavVbinlDQBQBt0tZ3pl3XJmlFgoIokopdAt290t4Q0AlF+3In/vFiyTXJF/lC1nRt2uBopGsSIAAHLx/PPPx5NPPhmPPfZYfPnLX4577703bty4ER//+MfzbtpAnU4nWq3W8rYxzWYzU92Mer0en//85+Phhx+ON954I3bs2BGPP/545tgI29UwOSSiAADkoowV+UetfHvq1Kl45ZVXVsS+5z3vyZyM1uv1OH/+fOzdu3czfh3Ijam5AADkpmwV+VW+hc1RuETURr0AABSVyrewOQo1NddGvQAAFFm3em2tVlu+b9jKtxuJhUlTqBFR0xUAAKqlbLPhVL6FzVGoEVHTFQAAqqOMs+FGqV6r8i28qVAjojbqBQCojrLOhhulwFLZijNRfGWbVdBVqBHR7nSF7lWx7nSFor8Zkc1G99wCxu+u6aPx7pNHV955svtYRMQj424SMIHMhoPRlHFWQVehElHTFSZXmf9IoIq+vvhcvPbcm8lm75519x09lVOrgEmjeA8s2eiATe+sgu5ndbvdjkajUfhz7EIlohE26p1UZf4jAQC2htlwMNqATZlnFRQuEWUylfmPBADYGmbDwWgDNmWeVVCoYkVMLoWoAIC1KN5D1Y0yYFPmLYGMiDIWpt4AwGRLkmTF7TRNc2rJ5FL4cTKNMqpZ5lkFElHGosx/JADA+rqJ531HT60odsbmUPhxco06YFPWGjsS0ZIq4xWxsv6RAONTtm1jHjh2Ji5fubbivt6qwnffcVu8+sz+cTcLmEAKP06uqg7YSERLyBUxYFKVbduYy1eu9W1vRDHbDJSTwo+TrYoDNooVlVDvFbGpqamo1WrRbrettwQAmFAKPzJpJKIl5IoYAEC1lLk6KqzF1NwSKvN+QQDA+lZXoI1QhXYtZayZsVFVXUfI5JKIlpCtUABudUuho5O9j0UUrdARDKIC7fqqWDOjiusImVwS0RJyRQzgVr2FjhQNgvLY6KimKrJQbhLRknJFDAAou1FGNdXMgHJTrAgAgFyMshOAKrJQbhJRAAByMcqopiqyUG6m5gIAkItRdgJQMwPKzYgoAAC5GHVUs16vx8LCQpw9ezYWFhYkoVAiRkQB2FS3bKMSsbyVim1UgF55jmqOsgdplfYvha0iEQVgU/VuoxKxcisV26gAq+WxE8Ao1XqruH8pbAVTc4HSeeDYmbjv6KnlpKb79X1HT8UDx87k3DoAim6Uar2jxELRdDqdmJmZiX379sXMzEx0Op2xHduIKFA6l69cWx5xW30F3YgbAOsZpVqv/Uvpp2xTtvMe3TciCgBApYyyB6n9S1lLN6mbm5uL06dPx9zcXDSbzbGOMA4r79H9iUpE8xxaBgBgvDZ67jdKtV77l7KWvJO6jch7dH9ipubmPbQMAMD4jHLuN0q1XvuXspa8k7qNGGUf380wMSOiZbwKAQDAxox67jfKHqT2L2W1Mk7Zznt0f2JGRMt4FQIAgI1x7keRdJO67gh9N6kr8qBY3qP7E5OI5j20DADA+Dj3o0jyTuo2Ko99fLsmZmpu3kPLAACMj3M/isaU7eFMzIhoWa9CAAAwvLKe+5Vtr0nYKhOTiEbkO7QMUDR3TR+Nd588uvLOk72PR0Q8Ms4mAWyqsp372eUB3jRRiSgAb/r64nPx2nNvJpqrT9TuO3oqh1YBVFdvpd/ue3K73Y5GoyERpXImZo0oTIqNbs4NABSbSr/wJiOiUCCm7ADA5FLpF95kRLSCjLgV16ibcwMAxaXSL7zJiGjFGHErNlN2AGBylbXSL2wFI6IVY8St2LpTdnqZsgMAk8Nek6ylijMWjYhWjBG3Yms2m/G+970v7rzzzvjKV74S73rXu+L111+Pn/zJn8y7aQAAbIGqzlg0IloxRtzKI03TvJsAAMAWq+qMRSOiFdNdJN+94tJdJD/pHb0sWq1WfOYzn1mxv9j8/Lz9xSrsrumj8e6TR1feebL38YiIRwKgrDqdTrRareU1k81m02celVLVGYsS0YqxSL7YqvpGRH9fX3wuXnvuzUSze4Gi676jp3JoFcDmqOqUROiV57Y+eV4IMjW3gkZZJF/FhdTjZOo0AFVS1SmJ0CuvbX26F4Lm5ubi9OnTMTc3F81mc2zn90ZEycxVy61n6jQAVWImEOQ3Y7HVasXBgwdXHPfgwYNjmy05UYmoNQZbq/eqZXd6YLvdtn5xE5k6DUCV5DklEYqkXq9HvV6/ZQnOVrp48WJ885vfvGWQ6bXXXhvL8Sdmam7eQ8tV4KrleNhfDICqGHVKYtWWDFXt92Vr3X777fHEE0+smBr/xBNPxO233z6W40/MiKjRuq3nqiUAsJlGmQlUtSVDVft92XpXr16Nubm5ePDBB5eXhM3NzcXVq1fHcvyJGRE1Wrf18lpIDQBMro3OBKpaoaOq/b5svd27d8d3fMd3xMMPPxzf+73fGw8//HB8x3d8R+zevXssx5+YEVGjdVvP+kVgUt2yX6u9WqHwqjYIUbXfl61Xq9XihRdeiOPHj8fu3bvj4sWLceTIkTh06NBYjj8xiahqo+ORx0JqgK3Wu1+rvVqhHMo6CJEkyS33pWm6blxZf1+Ka35+Po4cORInTpxYHmQ6cuRIvPTSS2M5/sQkokbrAACqo6yDEN2k876jp5YvgGVR1t+X4lpcXIwvfvGL8ZGPfGT5Iuy1a9fi2WefHcvxJyYRjTBal9VGr8QBABRF1QYhqvb7svXyHmWfmGJFVTNK+e40TSNN07j3yMvLXwMAlE3Vtjyr2u/L1sq7EOlEjYhWhfLdAACj6XQ60Wq1lkcXm82m8ygqJe9RdiOiJaR8NwDAxmeIdS/qz83NxenTp2Nubi6azeZQM8xgEuQ5ym5EtISU7wYAqm6UGWK9F/W7tUXa7XY0Gg2jojAmRkRLqLuwuJfy3QBAlYwyQ6ysF/VHqRECRWNEtISU7wYAqm6UZDLvaqEboUYIk8aIaAnV6/VotVrRaDTiwIED0Wg0lO8GACpllBlieVcL3Qg1Qpg0EtEo5zQH5bsBgCobJZks40X9sk4nZuuVMZeJMDXXNAcAgBIadeuJer0e9Xp9uVhR0ZVxOjFbr8y5TOUTUVXTIB8PHDsTl69cW3HffUdPRUTE3XfcFq8+sz+PZgFQImVLJkehRghrKXMuU/lE1DQHyMflK9fiteceWb7dexLRTUgBmHydTidardbyqGaz2Sz8CXQeRh0BZjKVOZepfCJqmgMAeRg0KyDCzACqoczTCvNQpRFgsilzLlO4YkXjXmxbxqppAJRfd1ZA99+n3nvniturk1SYRCrBwpKN5kBlzmUKNSKax1Ux0xwAAPJR5mmFTKY8poqPkgOVOZcp1IhoXlfFbIUCADB+o+wFCputmxDOzc3F6dOnY25uLprN5pbP0Bw1ByprLlOoRNRVMWAS3TV9NN598t3L/xpfbqy4fdf00bybCJCLMk8rzENZ94ssi7wGxRYXF+PSpUsrXttLly5NfA5UqKm5ZV5sC9DP1xef61shOEKVYKC6yjytcNwUdtp6eQ2K3XPPPXH48OF48cUXl1/bgwcPxj333LOlx81boUZEXRUDAKiWsk4rHDeFnbZenlPFkyQZeHsSFSoRrdfr0Wq1otFoxIEDB6LRaLgqBgAwwUw3zaasS9jK9PrmNSj21a9+NY4fP74iBzp+/Hh89atf3dLj5q1QU3Mj7I8EAFAVpptmV8YlbGV7ffOaKj49PR07d+6MhYWF5Rxofn6+0K/tZijUiCgAANVR1ummeYzyNZvNeN/73he7du2Kffv2xa5du+J973tfoZewlfH1zWOqeFWXJxZuRLRK8tinCACgKBYXF+Of/tN/Gg8//HC88cYbsWPHjnjssccKPd20CKN8aZqO5TijKut04nGratEuiWhOivAmBgCQp7e97W3x0z/90/H888/H7t274+LFi3H48OF429velnfT+uod5etOo2y329FoNLb0HK7VasVnPvOZFcedn5/f8uOOoozTifNSxeWJpubmpIxTFQAANtMf/MEfxLd+67fGgw8+GFNTU/Hggw/Gt37rt8Yf/MEf5N20vvIa5Svj6GJVp5ySjRHRnJTxzQQAYDNdv349Pvaxj62Ykvixj30sHnvssbyb1ldeo3xlHF2s6pRTsjEimpM89ykCACiCHTt2xNe+9rUVxWG+9rWvxY4dO/JuWl95jfKVdXTRPrH0Y0Q0J903k+4a0e6biam5AEBVPP7443HkyJGIiNi9e3d8/OMfjyNHjsShQ4dybll/eY3yGV1k0khEczLqm4mKuwBA2c3NzUVExNNPP71cNffQoUPL968nr/OhvArLVLGgDZNLIpqjjb6ZqLgLAEyKubm5mJubcz4EOchzcMsa0RJScRcAqDrnQ2yFTqcTMzMzsW/fvpiZmYlOp5N3k7ZM92LO3NxcnD59Oubm5qLZbI7tdzYiWkIq7gIAVed8qBzKtJysaqPsrVYrDh48uGKp4MGDB8e29lgiWkJlLN8NALCZpqen4z3veU/82q/9WqRpGkmSxEMPPeR8qEDKltj1jrJ3p4q32+1oNBqFbO+oLl68GN/85jdveX1ee+21sRzf1NwSKmv5bgCAzbJt27b4whe+ED/wAz8Q/+yf/bP4gR/4gfjCF74Q27Y5vS2Ksk2frtoo++233x5PPPHEitfniSeeiNtvv30sx/eXWkL1ej1arVY0Go04cOBANBoN5bsBgEpZWFiI7/me74nf/u3fjh/6oR+K3/7t347v+Z7viYWFhUzxVVoLGJHP71u2xK4767DXJM86vHr1aszNza0Y3Jqbm4urV6+O5fim5paU8t0AQJWlaRo///M/H3fffffy+dDly5fjbW9727qxZZsyOqq8ft+yLSfrzjrsPk/dWYdFHcEd1e7du+PRRx9dsUb0/e9/f7z00ktjOb4RUQAASidJknjqqadW3PfUU09FkiTrxpZtyuio8vp9y7acrGqzDpvNZrz44osrqua++OKLY3t9jIgCG/bAsTNx+cq1Fffdd/RURETcfcdt8eoz+/NoFky8QX97Ef7+qIbv/d7vjU9+8pMREfF93/d98SM/8iPxyU9+MvbvX7/vl23K6Kjy+n27CVzviFvRE7sqzTrM+/WRiAIbdvnKtXjtuUeWb/e+afeeFAOba9DfXoS/P6rh9OnTceDAgXjhhRfik5/8ZCRJEvv374/Tp0+vG1u2KaOjyvP3rVJiV0Z5vj6m5uaoaovkAQA20+nTp+OP/uiPYn5+Pv7oj/4oUxIaMfqU0bKdw5VtimyeyvbalpkR0ZxUbZE8AEBRjDIlMc9zuLXWv6Zpum5c3lMwyyLP17bT6USr1Vp+fZrN5sS/PkZEc1K1RfIAAEVSr9djYWEhzp49GwsLC5lP+vM8h0vTNNI0jXuPvLz8dVYb/X2rJK/XtpsA9xYNajabEz8aKxHNSdUWyQMArCWvqZAbPa5zuMmV12tb1QEqU3NzUrVF8gCUn0rZbLbNmAq5erpqllHCUY7rHG5y5fXaLi4uxqVLl2JmZmZ5au6RI0cm/uKGEdGcWDQOQNl0q/V2/33qvXcuf706QYUsNmMkaCNTVUc5rnO4yZXXa3vPPffE4cOHV0zNPXz4cNxzzz1bety8GREd0UYXFls0DgBUXV5TIUc5blnP4fIqhlOmIjx5vrarR/bXKkw1aSSiIxh1Ool9lQCAKstrKuSoxy3bOVxe1WDLuEtEHq/tV7/61fjUpz61IgE+fvx4fOhDHxrL8fNiau4IqrqwGABgM+Q1FbJq02vzOmd1rpzN9PR07Ny5c0VV4507d078uuNMI6JJkrw3In4yIrZHxD9J0/S5Nb5nb0T8w4i4LSL+Q5qm/+mmtbKgVE0DANi4vKZClnV67UaVcQp0lXQvjHRHjrsXRiY9YV83EU2SZHtE/OOI+N6IuBQRv5okyS+maXqx53veFhE/FRHvTdP0K0mS/Mktam+hVLFq2kY3UgYAWEte01zLNr12FGWdAl0VVbsw0pVlau53RsSX0jT9nTRNr0bEz0XED676noMR8T+kafqViIg0Tf/95jazmKo2rSNitI2UAQAYP1Ogs8trX9t6vb5iau6kJ6ER2abmvjMifq/n9qWI+EurvufPRMRtSZKcj4i7IuIn0zT99Ka0sMCqevUCAIDyqNfr8fnPfz4efvjheOONN2LHjh3x+OOPmwK9ShmLK5VZlkR0rdrBq4fBpiLioYjYFxF3RMT/lCTJr6Rp+m9X/KAk+XBEfDgi4u1vf3ucP3++70G/8Y1vDHx8kI3GbiTuHe94R3ziE5+Ib3zjG/HWt741ImLon5HH79qVR2xebfY8bU1s7/eubvN6P2czYtd6nooYO+h3LWPsOF7bUWK9thv/Ox7me4d9fUY57mbEiS12bF6fe1U4Dzt79mz8wi/8Qjz77LOxa9eu+N3f/d34iZ/4iXjb294W+/bty/xz8jpXHtfz9PTTT8eP/uiPRpIk8Yd/+Ifx1re+NRqNRjz99NPxjne8I/PPyatPlS62O72y37+I+K6ION1z+6mIeGrV9xyNiL/fc7sdEX990M996KGH0kHm5+cHPr4VsXkcM8/Ye4+8nEtsHm3O63ct2/M0bOzq7+1t83o/Z7NiVz9PRYwd9LuWMXZcr+0osV7bjf8dD/O9w7w+oxx3M+LEFjs2lgY5lv+N45hdVTgPu//++9Nz586lafpmm8+dO5fef//9Q/2cPJ6rcT5P27ZtS69evZqm6ZvtvXr1arpt27ahfk4Z84Ktio2IL6R98sEsa0R/NSK+PUmSXUmS3B4RPxwRv7jqe/4/EfFXkiSZSpLkLbE0dVc5LAAA1pWqP7GlVK/NpltcqZfiSltn3UQ0TdPrEfFERJyOpeTyv0/T9DeTJDmUJMmhm9+zGBGfjYjfiIh/HUtbvCxsXbMBAIAsJFjZlLG4Upll2kc0TdNfiohfWnXfC6tu/0RE/MTmNQ0AALZGp9OJVqu1XESn2WxObEGaqu5TOayyFVcqu0yJKAAATIqqVUeVYGVXpf1l85ZljSgAAEyMVqsV7XY7arVaTE1NRa1Wi3a7PdEjhFXcp5Jik4gCAFApoxbv6XQ6MTMzE/v27YuZmZnodDpb0UyYaKbmllSS3Lq9qypzAADr6xbvqdVqy/dlLd5TtWm9sFWMiJZUt7y5UucAAMNpNpvxvve9L3bt2hXf/d3fHbt27Yr3ve99maqjVnFaL2wFiSgAAJW11iyzQezJCZvD1FwoGNOui+uu6aPx7pNH37zjZO9jERGPjLtJUBoPHDsTl69cW3HffUdPRUTE3XfcFq8+sz+PZlFRrVYrPvOZz0StVluujjo/Px+NRmPd6bWjTOsF3iQRhYLpJp33HT0Vrz0nsSmSry8+t/yarC7r3j2hBtZ2+cq1Fe9pvX9D/n4Yt1FGNe3JCZtDIgoAQKWMMqppT07YHNaIAgBQKd1Rzfn5+bh+/fryqGaWYkXA5jAiCgBApYwyqmn7FtgcRkQBYIOWCli9e/lf48uNFbfvmj66/g8BclGv12NhYSHOnj0bCwsLmZPIsm7f0ul0YmZmJvbt2xczMzPR6XTybhIFkGe/MCIKABvUW8AqQhErqIIybt9iFJe15N0vjIgCAEBG3UJHvYq+fUtZR3HZWnn3i8IloqYNAABQVGUsdFTGUVy2Xt79olBTc/MeHgYAgEHKuH3LKNvVMLny7heFGhHNe3gYAADWs9FCR3kp4yguWy/vflGoEdG8h4cBAGDS1Ov1+PznPx8PP/xwvPHGG7Fjx454/PHHC59As7XyHt0v1IhoGRd/AwBAkXU6nTh16lS88sor8bnPfS5eeeWVOHXqlFos5KpQiWjew8MAALCeshXXtPyNtXTr88zNzcXp06djbm4ums3m2Ppzoabm5j08DAAAg5SxuKblb6yl9wJFdx/sdrsdjUajmvuIlm3xNwAA1VHG0UXL31hL3hcoCpeIAgBAUeV98r4Rlr+xlrwvUBRqai4AABTZ9PR0HDt2LF566aXlpWSPPvpooUcXVc1lLd0LFN1p5t0LFOMa3ZeIAgBARrVaLY4fPx7Hjx+P3bt3x8WLF+PIkSNx6NChvJvWV2/V3N51re95z3skoxWWd30eU3MBACCj+fn5OHLkSJw4cSIeeeSROHHiRBw5ciTm5+fzblpfZVzXmpe8KiInSRJJkkStVlv+ehzyrM9jRBQAADJaXFyML37xi/GRj3xkudLotWvX4tlnn827aX2VcV1rHvKsiJymaURE3Hf0VLz23CNbeqyiMCIKAAAZ5V3gZSPK2OY8GDkeL4koAABkVMYKtGVscx6MHI+XqbkArOm+o6dW3vHZpdt333FbDq0BKIa8C7xsRBnbnIfuyHGtVlu+z8jx1pGIAnCL1etTqrRmBWA99Xo96vX68hrRMihjm8ct7+1MNqrT6USr1Vq+yNBsNktxkUEiCgBA5axVlbRbMIZqKuPIcZ4FlkYlEQWACnng2Jm4fOXaivt6p2Hffcdt8eoz+8fdLBi7KlYpZX1lGznuLbDUbXO73Y5Go1H4RLRwxYry2rsHAKrg8pVr8dpzjyz/+9R771xxe3WSCkBxjVpgKc/cq1AjomUeWgYAtsbqUVwjuABLRimwlHfuVagRUXv3AACr9Y7iGsEFeNMoW/PknXsVakTU3j0AAADZjFJgKe/cq1Ajot2h5V7D7N1jfSkAAFstSZJIkiRqtdry15CXer0eCwsLcfbs2VhYWMg8rXbU3GtUhUpERxla7s5xnpubi9OnT8fc3Fw0m81MyagEFgCArNI0jTRN494jLy9/DWUzSu61GQo1Nbder8fnP//5ePjhh+ONN96IHTt2xOOPP54pq99o6eK8F+kCAACMW977phZqRLTT6cSpU6filVdeic997nPxyiuvxKlTpzKNUG50jnPei3QBAGBSmXlYbBud1rsZCjUiOsqGrBstXZz3Il2KyVYBAACjMfOQQQo1IjpKUrjROc55L9KlmGwVAAAwGjMPGaRQI6LT09Nx7NixeOmll5bnKT/66KOZksKNznHuJrDdKzXdBNYfCAAAbJyZhwxSqES0VqvF8ePH4/jx47F79+64ePFiHDlyJA4dOpQpvl6vR71eX57WmzUmIr9FugAAMIk2unSOaihUIjo/Px/f//3fH08//fRy1dzv//7vj/n5+bybBgAADMHMQwYpVCJ68eLF+OY3vxmvvPLKigXNr732Wqb4TqcTrVZreWSz2WyuO7JpETUAAJNuI+fJo6razMM8nuMyK1Qievvtt8cTTzyxomruE088EU8//fS6sZ1OJ5588sm48847I03TeP311+PJJ5+MiMEJ5SiVegEAoOjyHHjZyNK5MjK4NbxCVc29evVqPPvss7Fr167Yt29f7Nq1K5599tm4evXqurGHDx+O7du3x4kTJ+LMmTNx4sSJ2L59exw+fHhgnEXUAABMMtVrt57neHiFSkTf+c53xrVrS1tjpGkaERHXrl2Ld77znevGXrp0KT796U+vePE//elPx6VLlwbG2b4FAIBJZuBl65X1OU6SJJIkiVqttvz1uBQqEY2IeMtb3rJiVPMtb3nLlh5vo/uPAgBAGRh42XplfY7TNI00TePeIy8vfz0uhVoj+tWvfjU+9alPrVjQfPz48fjQhz60buzOnTvjgx/8YPzsz/7sclWuD37wg7Fz586BcVVbRA0AQLWoXrv1PMfDK1QiOj09HTt37oyFhYXlBc3z8/OZriQ8//zz8eSTT8Zjjz0WX/nKV+Jd73pXXL9+PT72sY+tG1uVRdQAAFSPgZet5zkeXqES0VGuJHRf5O733nnnnfHRj37Uiw/reODYmbh85dqK++47emr567vvuC1efWb/uJsFAGwiAy9bz3M8nEIloqNeSfDiw/AuX7kWrz33yPLt1X8/vUkpAABshsIVK6rX67GwsBBnz56NhYUFI5oAAAAF0+l0YmZmJvbt2xczMzPR6XSGii/UiCgAAADF1ul0otlsLi+p3L59e8zOzkZEZB5IlIgCTLBbplZ/duX6X5h0q9fBWwMPMLpWqxXtdjtqtdrysq52ux2NRkMiClB1vWt/I5ZOwFffB5Oudx28NfAAm2NxcTH27Nmz4r49e/bE4uJi5p9RuDWiAAAAeRh13WNVTE9Px4ULF1bcd+HChUzbbnZN1Ihop9OJVqu1XHG32WwqdgQAAKxrM9Y9VsUo2252TUwiquMUX5Ikt9yXpmkOLQEAgJU2Y91jVYy67WbEBE3N7e04U1NTUavVot1uD5WVs7XSNI00TePeIy8vfw0AAEWwGeseq2TUbTcnZkRUxwEAgLWZmba+7rrHWq22fN+w6x7JbmISUR0HgBVVUG1VA7Csm3SqoN7fZqx7JLuJSUR1HIBq6z2xcqIFwLA2Y90j2U1MIqrjAEyGW/Z2vDmyaVQTgK1Wr9ejXq/fsu9wkZV155CJSUQjytlxAHjT6lFMI5sA5VbWJKksyrxzyEQlogAAQDGUOUkqizJvOSMRhU30wLEzcfnKtRX39U4zvPuO2+LVZ/aPu1kAAGNX5iSpLMq8c4hEFDbR5SvXVkwjXD1N/Ja1bwAAE6rMSVJZlHnnkG15NwAAAJg83SSpV1mSpLLo7hwyPz8f169fX945pNls5t20dRkRBQAANp3tFbdemXcOkYgCAACbrsxJUpmUdecQU3NjqaLXzMxM7Nu3L2ZmZqLT6eTdJAAAKL16vR4LCwtx9uzZWFhYkISyrPIjospKQ7XcNX003n3y6Jt3nOx9LCLCnpUAAFut8omostJQLV9ffG65srGqxgAA+aj81FxlpQEAAMar8iOiZd57BwAAKIYkSW65L03THFpSDpUfES3z3jsAAEAxpGkaaZrGvUdeXv56ko1a8LVwI6KdTidardZyiedms7mlazWVlQYAAMhuMwq+FioRzauCbVn33gEAABi3zSj4Wqipub2/0NTUVNRqtWi329FqtfJuGgAAALE5BV8LlYiqYAsAAFBs3YKvvYYt+FqoRHQzfiEAAICqGLVo0EZsRsHXQq0R7f5C3TWi3V/I1FwAACifcRcirZo8a+xEjFbwtVCJqAq2AFTFXdNH490nj66882Tv4xERj4yzSQCbKq8kqUo2o2jQRo1a8LVQiWiECrYAVMPXF5+L1557M9Fc/bl339FTObQKYPPkmSRVRZlr7BRqjSgAAFAsG12DWOYkqSzKXGOncCOiAABAMYwyvbabJNVqteX7ypIklUWZa+xIRAEAgDWNMr22zElSWZS5xo5EFAAAWNMo02vLnCSVSVlr7BQuEVXiGaD8bim089ml23ffcVsOrQFgo0adXlvWJImtV6hEVIlngPLrrQQbsZSUrr4PgHIYdXqtQSb6KVQimleJZ38gAABwq1Gm1xpkYpBCJaJ5lHj2BwIAAP1tdHqtfUQZpFD7iOaxD07vH8jU1FTUarVot9tjqea10T2ZAACg6OwjyiCFSkS7c9Dn5+fj+vXry3PQm83mlh0zrz+Q7kjs3NxcnD59Oubm5qLZbEpGAQCYCHkMMjE+ow6qFWpqbr1ej4MHD8Z3f/d333L/Vslro11TFQAAmGT2EZ1cm7G8sVAjohERaZpGmqZx75GXl7/eSnmMwkaYqgAAwGSr1+vRarWi0WjEgQMHotFo2Ed0QmzG8sZCjYjmIa+NdvMaiQUAWO2BY2fi8pVrK+7r7gd89x23xavP7M+jWUyAsu0jmiTJLfdt9cBYGW3GoFrhRkTzUK/XY2FhIc6ePRsLCwtjuUqT10gsAMBql69ci9eee2T536fee+fy16sTVJhk456duRnyKIC6Get/Kz8impe8RmIBWFt39CciIj775td333FbDq0BmAyNRiN+5md+Jt54443YsWNHPP744zE3N5d3syZGXltRbsb6X4lojso2VQFgUr323CPLX9939NSK2wBsTKPRiBdeeCGOHz8eu3fvjosXL8aRI0ciIiSjmySvAqibMahmai4AALDpfuZnfiaOHz8eP/ZjPxbf8i3fEj/2Yz8Wx48fj5/5mZ/Ju2kTI88CqKMub5SIAgAAm+6NN96IQ4cOrbjv0KFD8cYbb+TUoslT5r1aJaIAAMCm27FjR7zwwgsr7nvhhRdix44dObVo8pS5AKo1ogAAQF+dTidardbyWsBms5lpGubjjz++vCZ09+7d8fGPfzyOHDlyyygpG1fmAqgTlYhu9I8EAAC41ShVWbsFiZ5++unlqrmHDh1SqIiImKBEtNPpxJNPPhl33nlnRES8/vrr8eSTT0bE1pYuBgCASTVqVda5ubmYm5uzS8QWyWv7ls0wMWtEDx8+HFNTU3HixIk4ffp0nDhxIqampuLw4cN5Nw0AAEopz6qsrK/3QsHU1FTUarVot9tD7eeZl4lJRC9duhQnT55c8SKcPHkyLl26lHfTAACglMpclbUKynyhYGKm5gIAAJurW5W1O/WzW5W1DCNuVTA9PR3Hjh2Ll156ablOzqOPPlqKCwUTk4ju3LkzPvCBD8SLL764/EfygQ98IHbu3Jl30wAAoJTKXJW1Cmq1Whw/fjyOHz8eu3fvjosXL5amMvHEJKLPP/98PPnkk/HYY4/Fl7/85bj33nvjxo0b8fGPfzzvpgHAprpr+mi8++TRlXee7H08IuKRcTYJmGD1ej3q9bqCQwU0Pz8fR44ciRMnTixfKDhy5Ei89NJLeTdtXROTiHavyrRarUiSJO6888746Ec/6moNABPn64vPxWvPvZlorj45vO/oqRxaBcC4LS4uxhe/+MX4yEc+svxZcO3atXj22Wfzbtq6JqZYUcRSMrqwsBBnz56NhYUFSSgAADCx8iwm1el0YmZmJvbt2xczMzPR6XSGip+YEVEAAIAqyauY1GbsXyoRBQAAKKG8ikn17l/anRLcbrej0WhIRKFKHjh2Ji5fubbivt41YnffcVu8+sz+cTcLgCF5PweGlUcxqc3Yv1QiChPg8pVrCpcATADv50AZdNem1mq15fuGXZs6UcWKAAAA2Frdtanz8/Nx/fr15bWpzWYz888wIgoAAEBmm7E2VSLKxFq9zsYaGwAA2Byjrk2ViOYoSZJb7kvTNIeWTKbedTbW2AAwDEWDgLIoa04hEc1Rt4Pcd/TUisIEAEC+FA0CyqKsOYViRQAAAIyVRDQiOp1OzMzMxL59+2JmZiY6nU7eTQIAgNJznk0/lZ+a2+l0otlsRrvdjhs3bsT27dtjdnY2ImKoqk8AAMCbnGczSOVHRFutVrTb7ajVajE1NRW1Wi3a7Xa0Wq28mwYAAKXlPJtBKp+ILi4uxp49e1bct2fPnlhcXMypRQAAUH7Osxmk8ono9PR0XLhwYcV9Fy5ciOnp6ZxaBAAAxbHRdZ7Osxmk8mtEm81mzM7OLs9dn5+fj9nZWVMGAACovFHWeTrPZpDKJ6LdP6BGoxGLi4sxPT0drVbLAmoAACqvd51ndz/ddrsdjUZj3fNl59kMUvlENGLpj6Rer9+yWTVAEdx39NTKOz775u2777htzK0BoEpGXefpPJt+JKIU2gPHzsTlK9dW3Nc9Kb/7jtvi1Wf259EsGJvXnntkxe37jp665T4A2CrddZ61Wm35Pus82QwSUQrt8pVrK066e6+m3TJKBACMnYvGk806T/rpdDrRarWWp103m82hpl1LRAEA2DAXjSebdZ6sZZQiVl2V374FAADor16vx8LCQpw9ezYWFhYkoawoYjU1NRW1Wi3a7fZQI+US0dj43kgAAABVM2oRqwhTczdlWBkAAKAqNqOIVeVHRFutVhw8eDAajUYcOHAgGo1GHDx40AJsAACANXSLWM3Pz8f169eXi1g1m83MP6PyI6IXL16M119/PU6cOLE8IvrYY4/Fl7/85bybRo7umj4a7z559M07TvY+FhFh+wwAAKppM4pYVT4Rvf3226PRaEStVluu8tZoNOLpp5/Ou2nk6OuLzy1XAFy9AbMKgAAAVF29Xo96vX7LuXJWlU9Er169Gp/4xCfiwQcfXN4b6ROf+ERcvXo176YBAABMpMonort3745HH310xbDywYMH46WXXsq7aQAAABOp8olos9lcs2quYkUAAABbY6IS0U6nE61Wa3lks9lsrrtgdjMW2gIAAJDdxCSio+wHOupCWwAAALLLtI9okiTvTZLkt5Ik+VKSJEcHfN9fTJLkRpIk/7fNa2I2rVYr2u121Gq1mJqailqtFu122xRbAACATdbpdGJmZib27dsXMzMz0el0hopfd0Q0SZLtEfGPI+J7I+JSRPxqkiS/mKbpxTW+73hEnB6qBZtkcXEx9uzZs+K+PXv2xOLiYh7NAQAYqweOnYnLV66tuK93y7G777gtXn1m/7ibBUygUWajdmWZmvudEfGlNE1/JyIiSZKfi4gfjIiLq76vERG/EBF/MWP7N9X09HQcO3YsXnrppeW1no8++mhMT0/n0RwAgLG6fOXa8h7YEfbBBrZO72zU7ntNu92ORqORORHNMjX3nRHxez23L928b1mSJO+MiL8WES9kbPumq9Vqcfz48Xjsscfi1KlT8dhjj8Xx48ejVqtt6XFHHZIGAAAok82YjZplRDRZ47501e1/GBFH0jS9kSRrffvNH5QkH46ID0dEvP3tb4/z588PPPB6j/d6+eWX44d/+Idjbm4uvvKVr8S73vWu+OEf/uF4+eWX44d+6Icy/YxvfOMbQx3z7Nmz0W634+/+3b8bu3btit/93d+NH//xH4+LFy/Gvn37Mv+ciOF+16rF9n7v6tcoax9a67XdqthB7c1y3M343nG2eTNen1Fix/najhKbV7+ocmwR3qPW+1mTFjtpf/Pez8+v+dhmx2Ztn9j8Y4c9V96s2LI9T1WIfde73hWf+MQn4sEHH1x+bb/4xS/Gu971ruw/J03Tgf8i4rsi4nTP7aci4qlV3/O7EfHazX/fiIh/HxGPDvq5Dz30UDrIvUdeHvj4atu2bUuvXr2apmmazs/Pp2maplevXk23bdu2buyLL76Y3n///em2bdvS+++/P33xxRczHfP+++9Pz507t+KY586dS++///6h2j7s71ql2NXf232es/yc3sd747YydlB7sxx3s753XG3erNdnlNhxvbajxObVL6ocW4T3qPV+1qTFTtrfvPfz+b6PbWZs1vaJLUbs6j41jtgyPk9ViH3xxRfTXbt2pefOnUs/97nPpefOnUt37dp1Sx4VEV9I++SDWUZEfzUivj1Jkl0R8e8i4ocj4uCqZHZX9+skST4VES+nafpStlR4c0xPT8eFCxdWTMW9cOHCumtER1loq0ASAABQNd08qdFoLNfnabVamdeHRmSYmpum6fUkSZ6IpWq42yPiRJqmv5kkyaGbj+e2LrRXs9mM2dnZ5YRyfn4+Zmdn192+ZZSFthtNfplcd00fjXefXLXD0cnexyMiHgkAANa2ugK06s/FVK/Xo16vL+dQw8oyIhppmv5SRPzSqvvWTEDTNP3Q0K3YBBvNykcZ1dxo8svk+vricyoWAgATZXUNmKUZl1untwK0c6nJlSkRLYuNZOWjjGpuxpD0ONlfDAC2ns9bJk038bzv6KkVF9xhFBOViG7EqKOaow5Jj5P9xQBg6/m8BVhf5RPRso1qAgAAlF3lE9GIco1qAgAAlN22vBsAAABAtRgRBQAAJoKtX8pDIgqUzi37tdqrFQAIW7+UiUQUKJ3e/Vp9yAAAlI81ogAAAIyVRBQAAICxmqhENEmSSJIkarVaJEkylmN2Op2YmZmJffv2xczMTHQ6nbEcFwAAoKwmao1omqYRsbRGrLt+bCt1Op1oNpvRbrfjxo0bsX379pidnY2Ipb1JAQAAuNVEJaLj1mq1ot1uR61WWy6Y0m63o9FoSESBFW4povTZleXkKS+vLQAMTyI6gsXFxdizZ8+K+/bs2ROLi4s5tQgootUzNMY1a4Ot57UFgI2ZqDWi4zY9PR0XLlxYcd+FCxdieno6pxYBAAAUn0R0BM1mM2ZnZ2N+fj6uX78e8/PzMTs7G81mM++mAQAAFJapuSPorgNtNBqxuLgY09PT0Wq1rA8FAAAYwIhojLYFS71ej4WFhTh79mwsLCxIQgEA4KY8tlekHCo/ImoLFgAA2Brj3l6R8qh8ImoLFgCq5K7po/Huk0dX3nmy9/GICCeLAGytyieitmABoEq+vvjcilGJ7kXYrlv2RQWALVD5NaK2YAEAABivyieitmABAAAYr8pPza3X6/H5z38+Hn744XjjjTdix44d8fjjj1sfCgAAsEUqn4h2Op04depUvPLKKyuq5r7nPe+RjAIAAGyByk/N7a2aOzU1FbVaLdrtdrRarbybBgAAUEij7hFb+RFRVXMpigeOnYnLV66tuK+3euXdd9wWrz6zf9zNAgCAW4y6R2zlE9Fu1dxarbZ8n6q55OHylWu2VAAAoBIqn4h2q+a22+24cePGctVcU3NXMloHAABslsonot2CRI1GIxYXF2N6ejparZZCRasYrQMA2DgX9WGlyieiEUvJaL1evyW5AgCAzeCiPqxU+aq5AAAAjJdEFAAAgLGSiAIAADBWElEAAADGSrEigCGsKCbx2ZXVDmHS3TV9NN598ujKO092H4uIGH5DcwCqSSIKkFFvtcP7jp5acRuq4OuLz/Wt+qniJwDDMDUXAACAsZKIjujAgQOxbdu2qNVqsW3btjhw4EDeTQIAACg0iegIDhw4EGfOnIlDhw7FP//n/zwOHToUZ86ckYwCAAAMYI3oCD73uc/F3/7bfzt+6qd+Ks6fPx8/9VM/FRERL7zwQs4tAwAAKC4joiNI0zSeffbZFfc9++yzkaZpTi0CAAAoPiOiI0iSJJ566qnlkdCIiKeeeiqSJMmxVQAA5fDAsTNx+cq15du91ZfvvuO2ePWZ/Xk0CxgDiegIvvd7vzc++clPRkTE933f98WP/MiPxCc/+cnYv9+bJgDAei5fuba8JVDvdkARtgSCSScRHcHp06fjwIED8cILL8QnP/nJSJIk9u/fH6dPn867aQAAAIUlER1RN+lcfRUPANZzy4jPZ1dOSwSASSURBYAcdKcjdt139NQt9wH9WV8K5SYRBQCgdKq0vnR10h0h8ab8JKIl440IAKBaepPuiMlPvKkGiWjJeCMCAADKblveDQAAAKBaJKIAAACMlUR0RJ1OJ2ZmZmLfvn0xMzMTnU4n7yYBAAAUmjWiI+h0OtFsNqPdbseNGzdi+/btMTs7GxER9Xo959YBAAAUkxHREbRarWi321Gr1WJqaipqtVq02+1otVp5Nw0AAKCwjIjelCTJittpmq4bs7i4GJcuXYqZmZlYXFyM6enpOHLkSCwuLm5VMwEAAEpPInpTmqZx39FTK7ZGWc8999wThw8fjhdffHF5au7Bgwfjnnvu2cKWwmS4a/povPvk0ZV3nuw+FhGR/W8RAIBykYiOaPVI6urb5OeWROdk72MREp18fX3xub574toPFwBgsklER/DVr341PvWpT0Wj0Viemnv8+PH40Ic+lHfTiJWJTm+SEyHRAQCAPClWNILp6enYuXNnLCwsxNmzZ2NhYSF27twZ09PTeTcNAACgsCSiI2g2mzE7Oxvz8/Nx/fr1mJ+fj9nZ2Wg2m3k3DQAAoLBMzR1Bd6/Q3qm5rVbLHqIAAAADSERHVK/Xo16v37IGEQAAgLWZmgsAAMBYSUQBAAAYK4koAAAAYyURBQAAYKwkogAAAIyVRBQAAICxkogCAAAwVvYRBQAK7a7po/Huk0ffvONk72MREY+Mu0kAjEgiCgAU2tcXn4vXnltKNs+fPx979+5dfuy+o6dyahVV9MCxM3H5yrUV9/X2wbvvuC1efWb/uJsFpSQRZcsNetP2hg0AlMXlK9eWL4pEuDACo5CIsuUGvWl7wwYAgOpRrAgAAICxkogCAAAwVqbmAgCwYbdUNY5YrmysqjHQj0QUqJwVa5M/u7LaIUAVjZJM9lY1jlALomgUjaSoJKJApfSeLN139NSK2wBVJZmcXIpGUlTWiAIAADBWElEAAADGSiI6ok6nEzMzM7Fv376YmZmJTqeTd5MAAAAKzRrREXQ6nWg2m9Fut+PGjRuxffv2mJ2djYiIer2ec+sAAFjL6gI+vWslFfCB8ZCIjqDVakW73Y5arba88Lvdbkej0ZCIAgAUVG8Bn97iPREK+DBeg6oaR0z2hRGJ6AgWFxdjz549K+7bs2dPLC4u5tQiAACgLAZVNY6Y7AsjEtERTE9Px4ULF6JWqy3fd+HChZiens6xVTCcQXvHLT0eYTNyAAA2k0R0BM1mM2ZnZ5fXiM7Pz8fs7Gy0Wq28mwaZDdo7LmKyr8QBAJAPiegIuutAG41GLC4uxvT0dLRaLetDN9Gg0TojdQBMGrNUgKqQiFJog0brjNQBsFXySgjNUgGqQiI6gk6nE08++WTceeedkaZpvP766/Hkk09GhO1bAKDMJIQAW0siOoLDhw/H9u3b48SJE8v7iB48eDAOHz5cyETUdB8A8mKpBQC9JKIjuHTpUpw5c2bFPqKf/vSnY//+Yu714+ouAHmx1AKAXhJRAACACnng2Jm4fOXaivu6FwXvvuO2ePWZrR9Yk4iOYOfOnfHoo4/GtWvX4tq1a3HbbbfFbbfdFjt37sy7aQAAAGu6fOVa7rNUJKIj2L17d5w5cyb+2B/7Y/G1r30t3vrWt8bXvva12LNnT95No2Ks/wVY2y3vj94bAQpBIjqCX/7lX473v//98eu//utx+fLluOeee+L7vu/74ud//ufzbhoVY/0vwNp63x+9NwIUh0R0BG+88Ub89E//dLzlLW9Z/nD75je/GT/7sz+bd9MAAAAKa1veDSizHTt2xAsvvLDivhdeeCF27NiRU4sAAACKz4joCB5//PE4cuRIRCytF/34xz8eR44ciUOHDuXcMgAAgOKSiI5gbm4uIiKefvrpeOONN2LHjh1x6NCh5fsBAAC4lam5I5qbm4s//MM/jPn5+fjDP/xDSSgAAMA6jIgCQAndUvH1s2/evvuO28bcGgAYjkQUAEqmd7umiKWkdPV9AFBkElFgw27ZKD5iebN4G8UDANCPRBQKYlBSt/R4RNESu96N4iNWbhZvo3gAAPqRiEJBDErqIiR2AABF9MCxM3H5yrUV9/Wet919x23x6jP7x92swpOIAgAAbNDlK9cMJmyARBQAYBPltdSijEs8gOqSiAIAbKK8llpY4gGUyba8GwAAAEC1GBEdUZIkt9yXpmkOLQEAACgHI6IjStM00jSNe4+8vPw1AAAA/UlEAQAAGCuJKAAAAGNljSgAAFBpDxw7E5evXFtxX2+l6bvvuC1efWb/uJs10QqTiA568b3wAABQDbfsiTuG/XAvX7lm+6MxK0wiOujF98IDAFBmtyRXEWNJsMqod09cCeHkKkwiCgAAk6o3uYqQYIFiRQAAAIyVRBQAAICxkogCAAAwVtaIwia7ZY3HZ1eW/gYAgKqTiMIm6i1CELGUlK6+j82xIuGX7AMAlIpEFCid3uResg8AUD7WiAIAADBWElEAAADGytTcHDxw7ExcvnJtxX29693uvuO2ePWZ/eNuFgAAwFhIRHNw+cq1FWvazp8/H3v37l2+fUvV1QK4a/povPvk0ZV3nux9PCLCOj2AMlDdG4C8SUTJ5OuLz5UueQbgVqp7A1AE1ogCAAAwVkZEAQDIxS1Lfyz7WZMlUkwiiSgAALnoXfpj2U9/lkhl5+JGeUhEAQCAieDiRnlYIwoAAMBYSUQBAAAYK1NzAQAASuaBY2fi8pVrK+7rnX589x23xavP7B93szKTiAIAAJtqUJJU9ASpLC5fuVbqIlYS0ZJRvhsAgKIblCQVPUFiPCSiJaN8NwAAUHaKFQEAADBWRkQBAGBCDVrWZUkXeZKIAgDAhBq0rMuSLvJkai4AAABjJREFAABgrEzNBQCgdG5Z+2g7u01nL1C2kkQU+lixbuKzb3599x235dAaAKBX79pH29ltDXuBspUkorCG3jfd+46eWnEbAAAYjUS0Ym65emWkD4Ah9Psc8RkCwDAkohWyelTPSB8Aw/A5AsBmyVQ1N0mS9yZJ8ltJknwpSZKjazz+/iRJfuPmv88nSfLA5jcVAACASbBuIpokyfaI+McR8XBE7I6IepIku1d92+9GxH+apumfi4h/EBE/vdkNBQAAYDJkmZr7nRHxpTRNfyciIkmSn4uIH4yIi91vSNP08z3f/ysRsXMzG0m53VJePWK5xLry6gAAUD1ZEtF3RsTv9dy+FBF/acD3z0bEK6M0isnSW149QulvAACouiyJaLLGfema35gktVhKRPf0efzDEfHhiIi3v/3tcf78+RWP997+xje+seL26u9dz7DfP2rcsLGDftf1ftYosYN+1jDfu5ltXq8NmxE7zudplNi8+kUZX9us7RNb3diytbcKsXm9n280tojvq3nFrvcc96umfOdtxXxtR4kt4uszSmzW5ymvWK9tMfvFoJ+VWZqmA/9FxHdFxOme209FxFNrfN+fi4jfjog/s97PTNM0HnroobTXvUdeXnF7fn6+72PrGfb7R40bNnbQ77rezxoldr2fNcz3blab12vDZsWO63kaJTavflHG1zZr+8RWN7Zs7a1CbF7v5xuNLeL7al6xW3kelsdrO0psEV+fUWLHdR42SqzXtnj9Yr2f1SsivpD2yQezVM391Yj49iRJdiVJcntE/HBE/GLvNyRJ8q6I+B8i4m+kafpvh0+HAQAAqIp1p+amaXo9SZInIuJ0RGyPiBNpmv5mkiSHbj7+QkT8vYj44xHxU0mSRERcT9P0L2xds4FJ0G8q19133JZDawAAGJcsa0QjTdNfiohfWnXfCz1f/62I+Fub2zRgkvUWsIpYSkpX3wfA+Lg4CIxTpkS06B44diYuX7m24r7um+ndd9wWrz6zP49mAQCUgouD2Qzakm7p8Qjb0kE2E5GIXr5yzfYgAABsqUFb0kU476QaNmsQcCISUQAAALbeZg0CSkQBAAqk31rNCOs1gckhEQUAKAhrNYGqyLKPKAAAAGwaiSgAAABjJREFAABgrCSiAAAAjJVEFAAAgLGSiAIAADBWElEAAADGyj6igM3TAQAYK4koVJzN0wEAquWu6aPx7pNHV955svtYRMTWnwtKRAEAqJRbTsJP9j4WMY6TcMjT1xefWzHwcP78+di7d29ErDFTbotIRAEAqJTek/DeE/CI8Z2EQ9UpVgQAAMBYGREFAADIwaC1mkuPR0zqVHGJKAAAQA4GrdWMmOyp4qbmAgAAMFZGRAEAADaoytNrRyERpfBumZLw2aXbd99xWw6tYTWvDwBQZVWeXjsKiSiF1vtHHbH0h7z6PvLj9QEAYCMkomTWb+QrwugXAACQXeUT0QeOnYnLV64t3+5Ntu6+47Z49Zn9eTSrcIx8AQBbYcWFbhe5oTIqn4hevnJtOaEynxsAYHx6L2q7yA3VUvlEFCaFqdMAAJSFRJSJVpXpPqZOAwBQJhJRJpbpPgAAUEzb8m4AAAAA1VKYEdG7po/Gu08eXXnnye5jERFGswCgzPqtZZ+05RJA+QzKRZYej5CPbK7CJKJfX3xuxdTJ3gq2qtdSFQoOAZPKWnagyAblIhHyka1QmESU7CQrk8lJGgAAVSERLRnJCgDQj4vVQFlIRAEAJoCL1UCZqJoLAADAWBkRBQAKb8WU0zFNNzXNtfjy6Bej0KfgTRJRAKDQeqeXjmu6qWmuxZdHvxhFGfvUKNsr2pqR9UhEc2CfIgAAim6U7RVtzch6JKI5sE8RAABQZYoVAQAAMFYSUQAAAMbK1FwAgE2mOipF0q8/6ovkSSIKALCJylgdlcmlP1JUElEAACg4o+xMGokoAAAUmFFNJpFEFACYaCtGkowiMSIjk7A5JKIAwMTqHTUyisSojEzC5rF9CwAAAGNlRHQEDxw7E5evXFu+3TtV4+47botXn9mfR7MAAAAKTSI6gstXri1Pxzh//nzs3bt3+bFb1g8AAAAQERJRxsRGylBOSZK8+fXxpf/TNM2pNQDApJCIsuUs7Ify6iadq2d9AACMQiIKAABMDFs2lYNEFAAAKJSNJpO2bCoPiSgAAFAYkslqsI8oAAAAY2VEFAAAoGTumj4a7z55dOWdJ3sfj4go7miyRBQAAKBkvr743Ippy6sr3N+yfWLBTEQiOuhqQNGvBAAAAFTNRCSig64GFP1KAAAAQNUoVgQAAMBYSUQBAAAYK4koAAAAYyURBQAAYKwkogAAAIzVRFTNBQAAYOtt1taZElEAAAAy2aytM03NBQAAYKwkogAAAIyVRBQAAICxqvwa0VsW257sfSwi62JbAAAAsql8Itq72LZ3oW3EcIttAQAAyMbUXAAAAMZKIgoAAMBYVX5qLgAA1bNiCdZn3/z67jtuy6E1lN0tS/qG6FOjxJZZoRLRfi/CJL8AAACMV7c+SMTS+WfvbRjW6v4zTJ8aJXZUeedehUlE83wRAAAAqqIIuZc1ogAAAIyVRBQAAICxkogCAAAwVoVZIwoAAEyOvIvhUGwSUQAAYFMVoRgOxSYRHcFd00fj3SePvnnHyd7HIiL8sQEAAKwmER3B1xefW76yc/78+di7d+/yY7dMRQAAACAiJKIAAEAf1nmyVSSiAADALazzZCtJRAEAgMrrN/obYQR4K0hEc6KjAwBAMRj9HT+JaA50dAAAoMq25d0AAAAAqkUiCgAAwFiZmgsw4ZIkefPr40v/p2maU2sAAIyIAky8NE0jTdOYn59f/hoAIE9GRAEAAEqozDtxSEQBAABKpuw7cZiaC0BfnU4nZmZmYt++fTEzMxOdTifvJgEAE8CIKABr6nQ60Ww2o91ux40bN2L79u0xOzsbERH1ej3n1gEAZSYRBWBNrVYrDh48GI1GIxYXF2N6ejoOHjwYrVZLIgoAjEQiCsCaLl68GN/85jdvGRF97bXX8m4aAFBy1ogCsKbbb789nnjiiajVajE1NRW1Wi2eeOKJuP322/NuGgBQckZEAVjT1atXY25uLh588MG4ceNGzM/Px9zcXFy9ejXvpgEAJScRBWBNu3fvjkcffXTFGtH3v//98dJLL+XdNACg5CYmEe23mWvRN3IFKKpms7lm1dxWq5V30wCAkpuIRLTsm7kCFFG3Mm7viKiKuQDAZpiIRBSArVGv16Ner8f58+dj7969eTcHAJgQquYCAAAwVkZEAQAAyGwz6vNIRAEAAMhks+rzmJoLQF+dTidmZmZi3759MTMzE51OJ+8mAQATwIgoAGvqdDprbt8SESrnAgAjkYjGqjnOn33za3uQAlXWarWi3W5HrVZbrprbbrej0WhIRAGAkVQ+Ee2dz2z/UYA3LS4uxp49e1bct2fPnlhcXMypRQDApLBGFIA1TU9Px4ULF1bcd+HChZiens6pRQDApJCIArCmZrMZs7OzMT8/H9evX4/5+fmYnZ2NZrOZd9MAgJKr/NRcANbWXQfaaDRicXExpqeno9VqWR8KAIxMIgpAX/V6Per1+nKxIgCAzWBqLgAAAGMlEQUAAGCsTM0dkT1IAQAAhiMRHYE9SIFJ1+l0otVqLRcrajabihUBACOTiAKwpk6nE81mM9rtdty4cSO2b98es7OzERGSUQBgJNaIArCmVqsV7XY7arVaTE1NRa1Wi3a7Ha1WK++mAQAlJxEFYE2Li4uxZ8+eFfft2bMnFhcXc2oRADApJKIArGl6ejouXLiw4r4LFy7E9PR0Ti0CACaFRBSANTWbzZidnY35+fm4fv16zM/Px+zsbDSbzbybBgCUnGJFAKypW5Co0WgsV81ttVoKFQEAI5OIAtBXvV6Per0e58+fj7179+bdHABgQpiaCwAAwFhJRAEAABgriSgAAABjJREFAABgrCSiAAAAjJVEFAAAgLGSiAIAADBWElEAAADGSiIKAADAWElEAQAAGCuJKAB9dTqdmJmZiX379sXMzEx0Op28mwQATICpvBsAQDF1Op1oNpvRbrfjxo0bsX379pidnY2IiHq9nnPrAIAyMyIKwJparVa02+2o1WoxNTUVtVot2u12tFqtvJsGAJScRBSANS0uLsaePXtW3Ldnz55YXFzMqUUAwKSQiAKwpunp6bhw4cKK+y5cuBDT09M5tQgAmBQSUQDW1Gw2Y3Z2Nubn5+P69esxPz8fs7Oz0Ww2824aAFByihUBsKZuQaJGoxGLi4sxPT0drVZLoSIAYGQSUQD6qtfrUa/X4/z587F37968mwMATAhTcwEAABgriSgAAABjJREFAABgrDIlokmSvDdJkt9KkuRLSZIcXePxJEmSf3Tz8d9IkuTPb35TAQAAmATrJqJJkmyPiH8cEQ9HxO6IqCdJsnvVtz0cEd9+89+HI+KTm9xOADao0+nEzMxM7Nu3L2ZmZqLT6YwlFgCgnyxVc78zIr6UpunvREQkSfJzEfGDEXGx53t+MCI+naZpGhG/kiTJ25IkeUeapr+/6S0GILNOpxPNZjPa7XbcuHEjtm/fHrOzsxER627DMkosAMAgWabmvjMifq/n9qWb9w37PQCMWavVina7HbVaLaampqJWq0W73Y5Wq7WlsQAAgyRLg5gDviFJ/npEHEjT9G/dvP03IuI70zRt9HzPqYh4Nk3TCzdvn42Iw2ma/tqqn/XhWJq6G29/+9sf+rmf+7lbjler1W65b35+PtMvszo2a9wosZvZXrHZY722kxs7jtd2lNiiPE9ZY/ft2xenT5+Oqamp+MY3vhFvfetb4/r163HgwIE4e/bslsWO0ua1Yr22kxvrtZ3cWO/nkxvrtRW7VuxacbVa7dfSNP0La/6ANE0H/ouI74qI0z23n4qIp1Z9z38bEfWe278VEe8Y9HMfeuihdJD5+fmBj29FbB7HFDue2LK1V2yxj1mm2Pvvvz89d+7cithz586l999//5bG9tIvxG5mbNnaK7bYxxRb/NiytVfsShHxhbRPPphlau6vRsS3J0myK0mS2yPihyPiF1d9zy9GxAduVs/9yxFxObU+FCB3zWYzZmdnY35+Pq5fvx7z8/MxOzsbzWZzS2MBAAZZt1hRmqbXkyR5IiJOR8T2iDiRpulvJkly6ObjL0TEL0XE90XElyLimxHxN7euyQBk1S0q1Gg0YnFxMaanp6PVamUqNjRKLADAIFmq5kaapr8US8lm730v9HydRsR/sblNA2Az1Ov1qNfrcf78+di7d+/YYgEA+skyNRcAAAA2jUQUAACAsZKIAgAAMFYSUQAAAMZKIgoAAMBYSUQBAAAYK4koAAAAYyURBQAAYKwkogAAAIyVRBQAAICxkogCAAAwVhJRAAAAxkoiCgAAwFhJRAEAABgriSgAAABjJREFAABgrCSiAAAAjJVEFAAAgLGSiAIAADBWElEAAADGSiIKAADAWElEAQAAGCuJKAAAAGMlEQUAAGCsJKIAAACMlUQUAACAsZKIAgAAMFYSUQAAAMZKIgoAAMBYSUQBAAAYK4koAAAAYyURBQAAYKwkogAAAIyVRBQAAICxkogCAAAwVkmapvkcOEn+t4j48oBv+RMR8R82+OM3GpvHMcWOJ7Zs7RVb7GOKLX5s2dorttjHFDue2LK1V+x4YsvWXrEr3Zum6bet+UiapoX8FxFfGHdsHscU67UV67UVq1+ILfYxxXptxeoXYjc/1tRcAAAAxkoiCgAAwFgVORH96Rxi8zim2PHElq29Yot9TLHFjy1be8UW+5hixxNbtvaKHU9s2dorNqPcihUBAABQTUUeEQUAAGASbbQ60lb9i4j3RsRvRcSXIuLoEHEnIuLfR8TCBo75pyJiPiIWI+I3I+LJIWK/JSL+dUS8ejP22JDH3h4RX4yIlzfQ7tci4t9ExK/HENWqIuJtEfHzEfH/vfk7f1fGuD9781jdf38QEX9niOP+lzefo4WI6ETEtwwR++TNuN9c75hr9YWI+I8i4nMR8b/c/P+PDRH7128e948i4i8MedyfuPk8/0ZE/LOIeNsQsf/gZtyvR8SZiLhn2L4fEf9VRKQR8SeGOO7fj4h/1/M6f1/WY0ZE4+bf729GxPNDHPMzPcd7LSJ+fYjY74iIX+n+HUTEdw4R+0BE/E+x9Hf0zyPiW/vErvkesV6/GhC3bp8aELtunxoQu26f6hebpU8NOG6WPtX3uOv1qwHHXbdfDYhdt18NiB3Yr6LP58Z6/Wmd2Cx9ql9slj7VLzZLnxr4OblOn+p33Cx9qu9xM/Spfscd2KcGxGXpT/1iM71P3fzeFecUWfrUgNhMn319YjN99vWJzfrZt+b506D+NOCY6/anQcddrz8NOG6mz74+sev2qQGxWT/7XotV55lZ+1Sf2KznU2vFZj2fWis2a5+6JTZLv+pzzEx9qt8xs/SpPsfNej61Vux3RLbzqbViM79PrfhZWb5pXP9i6Q/ltyPiT0fE7bH0Zrw7Y+xfjYg/HxtLRN8REX/+5td3RcS/HeK4SUS89ebXt0XEv4qIvzzEsX8sIl6MjSeifd9oB8SdjIi/dfPr22PAB8Q6r9X/L5b2Bsry/e+MiN+NiDtu3v7vI+JDGWNnYikJfUtETEXE/xgR3z5MX4iI5+PmhY2IOBoRx4eInY6lJPx8DH7jXCt2f0RM3fz6+JDH/daer380Il7IGnvz/j8VEadjab/efonoWsf9+xHxX63zmqwVV7v52uy4eftPDtPensc/FhF/b4jjnomIh29+/X0RcX6I2F+NiP/05tePRcQ/6BO75nvEev1qQNy6fWpA7Lp9akDsun2qX2yWPjXguFn6VL/YdfvVoDav168GHHfdfjUgdmC/ij6fG+v1p3Vis/SpfrFZ+lS/2Cx9qu/nZIY+1e+4WfpUv9gsfWrdz/a1+tSAY2bpT/1iM71P3Xx8xTlFlj41IDbTZ1+f2EyffX1is3723XL+tF5/GnDMdfvTgNhMn3392jyoP61z3EyffX1is372vbb6eczap/rEZj2fWis26/nUWrFZ+9QtsVn6VZ9jZupTfWKznk+t2d4sfarPcbOeT60Vm/l9qvdf0abmfmdEfClN099J0/RqRPxcRPxglsA0Tf9FRPwfGzlomqa/n6bp/3zz66/H0tXtd2aMTdM0/cbNm7fd/JdmiU2SZGdEPBIR/2ToRm9QkiTfGksn5O2IiDRNr6Zp+n9u4Efti4jfTtP0y0PETEXEHUmSTMVSUvnVjHHTEfEraZp+M03T6xHxyxHx1/p9c5++8IOxlIDHzf8fzRqbpulimqa/tV4j+8SeudnmiKWrTDuHiP2Dnpt3Rp9+NaDv/zcRcbhf3DqxA/WJ+9sR8Vyapm/c/J5/P+wxkyRJIuI/j6UR86yxaUR8682v744+/apP7J+NiH9x8+vPRcQP9Ynt9x4xsF/1i8vSpwbErtunBsSu26fWeT8c2KdGfC/tF7tuv1rvuIP61YDYdfvVgNiB/WrA58a671P9YjP2qX6xWfpUv9gsfWrQ5+R6fWrDn7EDYrP0qYHH7denBsRl6U/9YjO9T/U5p8j02bdWbNbPvj6xmT77+sSu26cGnD+t+7k3yrlXn9hMn32DjrveZ1+f2EyffX1iM/WpPjL1qbVk7VN9YjP1qT6xmc6nBli3X22yTH1qkPX6VB+Z+lQfG+pTRUtE3xkRv9dz+1JkPInZLEmS3BcRD8bSlcisMduTJPn1WJr297k0TbPG/sNY6th/NFwrl6URcSZJkl9LkuTDGWP+dET8bxHx/0qS5ItJkvyTJEnu3MCxfziG6Nxpmv67iPivI+IrEfH7EXE5TdMzGcMXIuKvJknyx5MkeUssXaX5U0O29+1pmv7+zbb8fkT8ySHjN8NjEfHKMAFJkrSSJPm9iHh/RPy9IeL+s4j4d2mavjpcE5c9kSTJbyRJciJJkj+WMebPRMRfSZLkXyVJ8stJkvzFDRz3r0TE/5qm6f8yRMzfiYifuPk8/dcR8dQQsQsR8Z/d/PqvR4Z+teo9InO/2sh7S4bYdfvU6thh+lRv7LB9ao02Z+5Tq2KH6ld9nqtM/WpV7N+JIfrVqth1+1Wfz41M/WmEz5wssX37VL/YLH1qrdisfWpAm9ftU31iM/WpdZ6rvn2qT9zfiQz9qU9s1vepfxi3nlNkfY9aKzar9WIHvU+tGZuhT90SN8R7VL/2ZnmPWis263tUv+NGrP8etVbs34ls71FrxWbtU2udZ2btUxs5R80aO6hPrRmb8bPvltiM/apfe7P0qbVis/apQc/Ten1qrdi/E9n61FqxQ59PLf2kDMOm4/p3s+H/pOf234iIuSHi74sNTM3tiX9rRPxaRPxfNxj/tlhaLzST4Xu/PyJ+6ubXe2NjU3Pvufn/n4ylacx/NUPMX4iI6xHxl27e/snIOHze8zNuj4j/EEtvRllj/lhEnIuIb4ulq7wvRcT/fYj42Yj4n2PpassLEfHfDNMXIuL/XPX414btR5FtelK/2GYsrWlIho29+dhTMWD9cW9sLI02/6uIuPvm7ddi8NSN1c/V22Np6vW2iGhFxImMcQsR8Y9iaXrZd8bSVOw1f98Bz9MnI+LHh3xt/1FE/NDNr//ziPgfh4j9v8TSVJRfi4hnIuJ/X+fYK94jsvar1XFD9ql+sVn6VN/3tAx9ajl2A31q9fOUqU/1iR2mX/V7rrL0q9XHHaZfrY7N3K+i53Mja39aK3aYPjUgdt0+1S82S59aFfvnhulTazxXmfvUGrGZ+9SA5ypLn+o9Zub+tEbsuv0p+pxTZOlT/WKz9KkMsX371Hqx/frUWnGR8T1qwPO0bn8aELtuf8rwPPXtTwOOu26fGhCb6T0q1jjPzNKn+sVm6VMZYge+Tw2K7den1vl9s/SrteKynkutFZvpPWqd52nge1Sf42Z6n+oTO9T51PLPyvJN4/oXEd8VEadXdZanhoi/LzaYiMZScnQ6In5sxN/hmcg2J/zZWBrxfS2W1lp+MyL+3yMc9+9nPO5/HBGv9dz+KxFxashj/WBEnBky5q9HRLvn9gfi5pvjBn7Xj0bEjwzTF2Jpwfc7bn79joj4rWH7UWwwEY2ID8bSAu63DBvb89i9g/p2rExE3x1LV9Nfu/nveiyNRP/HGzhu5sci4rMRsbfn9m9HxLcN8TxNRcT/GhE7h3xtL8ebW1ElEfEHG3yO/0xE/OsBsbe8R2TpV2vFZe1T/WKz9KlBx12vT62OHaZPZTjuoNdgrec4U78a8Fyt26/6HDdTv8rw+w7sVze/55lYKoSR+X1qdWzWPtUvNkufGnTc9frUGrH/j6x9KsNx+/apPs9z5veqPs9VpveqVcfM/D61zu+6Zn+KPucUWfpUv9gsfWpQ7Hp9ar3j9utTfeJ+IUt/ynjMNfvTgOd43f60zvM0sD8NOO66fSrj77vue9TN7/v7sfH3qb8fG3+fWo5dr0+td9x+fWpA7NDvU32OuWafGvAcb+Q9qvd5yvweteq4G3mfWuv3zdSn0jQtXCI6FRG/ExG74s1iRfcPEZ/phV4jLomIT0fEP9xA7LfFzWI/EXFHRPzLiPj+IX/G3hhyRDSW5rjf1fP15yPivRlj/2VE/NmeDvQTQx775yLibw4Z85diqfLXW24+3ycjojFE/J+8+f+7YqlqWt/Kf2v1hViqtta7uH5QVbs1+1FsIBGNpSrQF9d7A+kT++09Xzci4ueHbfPNx16L4UZE39Hz9X8ZET+XMe5QRPw/b379Z2Jpmn3mEdGbz9Uvb+B5Woybb9ixtHb514aI7farbbH0HvBYn7g13yPW61f94rL0qQHHXLdPDYhdt0+t1+ZBfWrAcdftUwNi1+1Xg9q8Xr8acNx1+9WA2IH9Kvp8bqzXnwbFZuxT/Y6bpU/1i83Sp9b9nBzQp/odN0uf6hebpU/1bfOgPjXgmFn6U7/YTO9TPT9nb6ysXpvps291bJY+NeC4mT/71ogd5rPvlvYO6k8Djpnpc69PbObPvrXaPKg/rXPczJ99a8Su26eiz3lmlj7VLzZLnxpw3CzvU/1is7xPrXtevVa/GnDMLO9R/WKzvEf1be96fWrAcbO8T/WLHep9avnnZfmmcf6LpfV//zaWsv/mEHGdWFp7eC2Wrv7MDhG7J5bmO3dLO/96DCjdvSr2z8VSSezfiKWh9L4Vzwb8jL0xfCL6p2MpUX81lhK8YZ6r74ilssy/EUtTZAcmdati3xIR/3vcnKYwZJuPxVISuRAR/13crAaWMfZfxtIb0KsRsW/YvhARfzwizsZSufGzEfEfDRH7125+/UYsXWE6PUTsl26+gXT7Vb9KbWvF/sLN5+o3YqkU9js30vdjwAdyn+P+d7FUfvs3IuIXo+fNdJ2422PpKu1CLE2j/u5h2hsRn4qIQxt4bffE0lSQV2NpCs1DQ8Q+GUvvN/82Ip6L/onzmu8R6/WrAXHr9qkBsev2qQGx6/apfrFZ+tSA42bpU/1i1+1Xg9oc6/SrAcddt18NiB3Yr6LP50ZkeJ8aEJulT/WLzdKn+sVm6VPrfk5G/z7V77hZ+lS/2Cx9qm+bB/WpAcfM0p/6xWZ6n+r5OXvjzYQj02dfn9hMn319YjN99vWJzfTZtzouS38acMx1+9OA2Eyfff3aPKg/rXPcTJ99fWLX7VPR5zwzS58aEJvlfapfbJb3qX6xWd6n1j2vXqtfDThmlveofrFZ3qP6tne9PjXguFnep/rFDvU+1f3XHX4FAACAsSha1VwAAAAmnEQUAACAsZKIAgAAMFYSUQAAAMZKIgoAAMBYSUQBAAAYK4koAAAAYyURBQAAYKz+/9HOOjKbY+X3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(train_x_sc).boxplot(figsize=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMaxScaler()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_mnx = MinMaxScaler().fit(train_x)\n",
    "\n",
    "\n",
    "X_scaled = scaler_mnx.transform(train_x)\n",
    "\n",
    "train_x_mnx=scaler_mnx.transform(train_x)\n",
    "test_x_mnx=scaler_mnx.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_mnx=scaler_mnx.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1313, 0.2339, 0.3059, 0.4264, 0.401 , 0.3823, 0.3729, 0.459 ,\n",
       "       0.6828, 0.5966, 0.6254, 0.5632, 0.6343, 0.997 , 1.    , 0.9988,\n",
       "       1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
       "       1.    , 1.    , 1.    , 1.    , 1.    , 1.    , 0.9657, 0.9306,\n",
       "       1.    , 0.9647, 1.    , 1.    , 0.9497, 0.948 , 0.9857, 0.9297,\n",
       "       0.8995, 0.8246, 0.7733, 0.7762, 0.7034, 0.7292, 0.5522, 0.3339,\n",
       "       0.1981, 0.0825, 0.1004, 0.0709, 0.0361, 0.0352, 0.0447, 0.0394,\n",
       "       0.0355, 0.044 , 0.0364, 0.0439])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_mnx.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(train_x_mnx).boxplot(figsize=(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---------------------------------------------\n",
    "##### PREPARATION DES DONNEES\n",
    "#---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation des jeux d'apprentissage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = sonar[range(60)].values\n",
    "\n",
    "#On ne prend que les libellé\n",
    "y = sonar[60].values\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.20, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On encode : Les mines sont égales à 0 et les rochers égaux à 1\n",
    "#remplace par  0 et 1\n",
    "\n",
    "sonar[60].replace({\"M\": 1, \"R\": 0} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y devient \n",
    "y = sonar[60].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---------------------------------------------\n",
    "##### CREATION DES JEUX D'APPRENTISSAGE ET DE TEST\n",
    "#---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On mélange\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#Creation des jeux d'apprentissage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.20, random_state=42, stratify = y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.6158\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5631\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5618\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5728\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5678\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5105\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6302\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.5742\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.5327\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6563\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6056\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7300\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7101\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7440\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8318\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8359\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8421\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8322\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8091\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8467\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8241\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7781\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8133\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8597\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8598\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8984\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8146\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8336\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8438\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7977\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8181\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.9067\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8681\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8461\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8509\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8049\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8617\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8218\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8364\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8664\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8092\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8177\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8397\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.7993\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8043\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8321\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8569\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8449 ETA: 0s - loss: 0.3035 - accuracy: 0. - ETA: 0s - loss: 0.3502 - accuracy: 0.84\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8387\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7945\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8780\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8036\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.9173\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8225\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8760\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8891\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8314\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8299\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8596\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8920\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8878: 0s - loss: 0.2865 - accuracy: \n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.9135\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8761\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.9149\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.9153\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.9160\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8394\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8040\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8859\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8557\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8885\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8115\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.9034\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.2965 - accuracy: 0.8852\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.2800 - accuracy: 0.8653: 0s - loss: 0.2\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.9225\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8862\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8802\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9391\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8646\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.1952 - accuracy: 0.9461\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.2387 - accuracy: 0.9092\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.8877\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9004\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8990\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.9183\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9314\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9544\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9298\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.9106\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8990\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8732\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9107\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.8937\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9419\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9117\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9326\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5750\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5220\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5613\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5486\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5424\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.4880\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6285 - accuracy: 0.5997\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6242\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6483\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7531: 0s - loss: 0.5548 - accuracy: 0.75\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7340\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.8224\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8397\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8426\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8615\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8114\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8399\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8659\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8535\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8572\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8532\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8460\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8348\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8890\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8412\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8340\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8809\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8402\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8527\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8206\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8329\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8701\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8858\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8994\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8504\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8325\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.8893\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8678\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8475\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.9215\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8441\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8428\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8511\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8245\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8050\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8471\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8412\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8360\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8569\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3230 - accuracy: 0.8648\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7792\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8840\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.7997\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.8781\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.7968\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8660\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8732\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8662\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.7907\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8614\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8698\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9029\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8620\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8641\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9528\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8763\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.9331\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8535\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8452\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.8911\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8658\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8728\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3494 - accuracy: 0.8019\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8920\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8784\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.9030\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8496\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8317\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.9091\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8963\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8617\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8943\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9127\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8792\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9003\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8576\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8978\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8854\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8607\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9043\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8639\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.9230\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8484\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.9001\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8323\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9258\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.8945\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8933\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.5945\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4864\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5589\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5800\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5123\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.4976\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.5970\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6677\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6688\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7824\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7503\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8143\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7178\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.8021\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.7485\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7778\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8224\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8087\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8115\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7991\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8692\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7769\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8307\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.8635\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8549\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8784\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8633\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7905\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8233\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8790\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8248\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8275\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8754\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8354\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8842\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8704\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8042\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8783\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8746\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8120\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8978\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8170\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8487\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8314\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8569\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8654\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8522\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8851\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8720\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8466\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8784\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8203\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8522\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8281\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.9078\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8942\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8733\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8900\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8762\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8856\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8698\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7944\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8565\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8038\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8572\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9448\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.9194\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8957\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8982\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8798\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8145\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8918\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8627\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8349\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.9168\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8827\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8867\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.9255\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8003\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8614\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8501\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8544\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9166\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8981\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.9189\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.8850\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8661\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8688\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8791\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8911\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.8954\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.9093\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8637\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.9042\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8996\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.9070\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9175\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9181\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8827\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5309\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4932\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5335\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5881\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5034\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.4840\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.5936\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.5779\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6125\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7185\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6443\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.7372\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6896\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7274\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7276\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7981\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.8201\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8251\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8433\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.8268\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7595\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7980\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4652 - accuracy: 0.8533\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7680\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8154\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4614 - accuracy: 0.8735\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4537 - accuracy: 0.8694\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5695 - accuracy: 0.7828\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8360\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8561\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7589\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4831 - accuracy: 0.7771\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8637\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8917\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8705\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8612\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8634\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8639\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8797\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8165\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8341\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8335\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8631\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8321\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8237\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8805\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8192\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8414\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8166\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7981\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8653\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7966\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8872\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8381\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8848\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8939\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8334\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8295\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8554\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8693\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8340\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8541\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8796\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9425\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8530\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.9203\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8675\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8664\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8491\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8593\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8859\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8301\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8555\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8445\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.9091\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.9153\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8487\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8828\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8955\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8622\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8627\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8761\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8829\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.9205\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8824\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.9014\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8941\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8784\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8852\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.9083\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8845\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.9212\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9369\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8549\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9175: 0s - loss: 0.2574 - accuracy: 0.\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4820\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4697\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5231\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5893\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5244\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5610\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.6074\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5819\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5576\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5729\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5490\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5816\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5403\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5410\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5604\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.5760\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5772\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5950\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5622\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5435\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5218\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4904\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5909\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.4901\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5798\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5177\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5915\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5242\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5218\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.4605\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5282\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5773\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5968: 0s - loss: 0.6710 - accuracy\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5341\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5306\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5753\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.5789\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5121\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.4709\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5579\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5980\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.6963 - accuracy: 0.5022\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6936 - accuracy: 0.5184\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.6850 - accuracy: 0.5698\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5723\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.4809\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5710\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5276\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5397\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5135\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.4557\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.4783\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5578\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.4924\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6837 - accuracy: 0.5764\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5420\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5852\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5695\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5925\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5245\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5410\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5608\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5755\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.4896\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.6390\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5434\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5546\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.4920\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5381\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5087\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5779\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5579\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5742\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5046\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5451\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5927\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5719\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.4881\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5536\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5372\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6171\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5596\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5801\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5761\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5137\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.6197\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5380\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5803\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5686\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5113\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5548\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5034\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5657\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5191\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5163\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5808\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5432\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5869\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5224\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.5018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 2s 1ms/step - loss: 0.6933 - accuracy: 0.4860\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4760\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5206\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.6044\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5323\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5579\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5798\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5859\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5354\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6879 - accuracy: 0.5809\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5448\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5683\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5269\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5413\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5677\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5607\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5879\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5611\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5961: 0s - loss: 0.6830 - accuracy: 0.60\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5444\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5281\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5021\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5943\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.4714\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5628\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5309: 0s - loss: 0.6914 - accuracy: 0.53\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5878\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5150\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.4800\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.4480\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5274\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5708\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5933\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5153\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5336\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5805\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5559\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5020\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.4559\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5286\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5793\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.5094\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5191\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5616\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5775\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.4666\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5538\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5325\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5217\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5089\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.4550\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.4623\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5662\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.4654\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5464\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5279\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5833\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5742\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5862\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5260\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5341\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5437\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5890\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.4884\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6478\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6892 - accuracy: 0.5470\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5349\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.4888\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5190\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5025\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5146\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.5539\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6849 - accuracy: 0.5751\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5098\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.5356\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6776 - accuracy: 0.6229\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6840 - accuracy: 0.5800\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.4762\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6900 - accuracy: 0.5419\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5288\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6785 - accuracy: 0.6181\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.6880 - accuracy: 0.5542TA: 0s - loss: 0.6835 - ac\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6850 - accuracy: 0.5742\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6839 - accuracy: 0.5808\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6948 - accuracy: 0.5079\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6775 - accuracy: 0.6250\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6953 - accuracy: 0.5043\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6831 - accuracy: 0.5876\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6868 - accuracy: 0.5624\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.4915\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5264\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6961 - accuracy: 0.4997\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5392\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5122\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5023\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5612\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5442\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5729\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4876\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4857\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5683\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5586\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4586\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5845\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4929\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5603\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4776\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4973\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4968\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5223\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5805\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5302\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4766\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4805\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5646\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4877\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4850\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5836\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5384\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5723\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5537\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5317\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5504\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5498\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4922\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5182\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5864\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5419\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5007\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5158\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5013\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5536\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.6060\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5002\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6096\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5659\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5293\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5416\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5436\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5942: 0s - loss: 0.6609 - accura\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5901\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5037\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5177\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5042\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5212\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5461\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5187\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.4744\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.4879\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5930\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5323\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5253\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5532\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5627\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5096\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5701\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5601\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4819\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5056\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6889 - accuracy: 0.5495\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5853\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5011\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5717\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5209\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5951\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5754\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6027\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5408\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5128\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5927\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5227\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5944\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.4861\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.4545\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5644\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5526\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5499\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5471\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5932\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5086\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5615\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5453\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5410\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4904\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5010\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5194\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5445\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5407\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5054\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4571\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.4846\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6909 - accuracy: 0.5349\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.4692\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6875 - accuracy: 0.5592\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6940 - accuracy: 0.5111\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.5542\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.4440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.5303\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.5426\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6926 - accuracy: 0.5365\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6943 - accuracy: 0.4639\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.5717\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4979\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.5583\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.4979\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4833\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4962\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5605\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.6023\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5337\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.4644\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.4923\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5730\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5158\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6949 - accuracy: 0.4937\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6837 - accuracy: 0.6086: 0s - loss: 0.6775 - ac\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5433\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.5607\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5514\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5332\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5649\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5716\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5661\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5278\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5169\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6859 - accuracy: 0.5778\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.5138\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5200\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5359\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6978 - accuracy: 0.4761\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5803\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6047\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5165\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5005\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5854\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5640\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5207\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5344\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5480\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5603\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5979\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5324 ETA: 0s - loss: 0.7024 - accuracy\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5173\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5173\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5122\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5499\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5253\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4819: 1s - loss: 0.7008 - accu\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5051\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.6022\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5357\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5238\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5546\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5114\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5151\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5799\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5859\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.4977\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5035\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5325\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5940\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5337\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5750\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.4939\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5913\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5853\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5726\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5095\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5527\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.6070\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.4984\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5903\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.4595\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5038\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5906\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5684\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5426\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5953\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5730\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5043\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5383\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5529\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5285\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4993\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5363\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4993\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5760\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5336\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5001\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.4662\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.4807\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5063\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.4796\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5482\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5031\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5511\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.4698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5689: 0s - loss: 0.6927 - accura\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5353\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5293\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4482\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5806\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4811\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5765\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.5021\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6946 - accuracy: 0.4757: 0s - loss: 0.697\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6952 - accuracy: 0.4649\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6903 - accuracy: 0.5616\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6875 - accuracy: 0.6008\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6909 - accuracy: 0.5459: 0s - loss: 0.6886 \n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.4670\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5010\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5525\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5248\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4776\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5743\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5340\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5709\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5441\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5404\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5500\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5609\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5471\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5348\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5251\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5504\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5077\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6914 - accuracy: 0.5329\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5387\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.4587\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5828\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.6015\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5146\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.4862\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5563\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5513\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5295\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5367\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5521\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5415\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.5827\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5309\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5195\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5269\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4830\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5516\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5170\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5023\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5341\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5880\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5322\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5163\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5391\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5048\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5149\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5569\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5466\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5074\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5155\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5614\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5831\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5295\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5598\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.4873\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5974\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5717\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5475\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4979\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.6040\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5697\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5151\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5767\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.4632\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4944\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5241\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5679\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5560\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.6022\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5540\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5047\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5289\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5241\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5053\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.4995\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5577\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.4725\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5539\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5052\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5140\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.4445\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.4749\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5038\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.4687\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5382\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.4913\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.4862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4677\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5459\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5267\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4563\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6915 - accuracy: 0.5934\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4844\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5699\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4796\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4633\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4541\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5581\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5998\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5203\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4704\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5035\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5382\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5269\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4530\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5426\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5325\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5653\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5382\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5341\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5404\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5579\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5094\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5236\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5050\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5360\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5044\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5399\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5263\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.4647\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5797\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6125\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5012\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.4761\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5544\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5512\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5247\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5219\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5512\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5469\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.5181\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5178\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4964\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4890\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5674\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5314\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4870\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6894 - accuracy: 0.5578\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6887 - accuracy: 0.5670\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6895 - accuracy: 0.5569\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.5050\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.5369\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.5190\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6930 - accuracy: 0.5142\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5505\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5588\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5098\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5096\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5657\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5905\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5390\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5176\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.4862\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5819\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5704\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5353\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5063\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5977\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5671\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4854\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5620\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.4514\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.4873\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5166\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5700\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5297\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5941\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5424\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6903 - accuracy: 0.5469\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5253\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5070\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4887\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5028\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5494\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.4712\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5667\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6962 - accuracy: 0.4722\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5112\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4944\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4901\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5166\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.4659\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5081\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4938\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5274\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.4720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.6158\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5631\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5618\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5728\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5678\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5105\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.6302\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.5742\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5259\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6037\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.5412\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6140 - accuracy: 0.6178\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6166\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.6633\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6848\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7237\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6818\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7597\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7736: 0s - loss: 0.5250 - accuracy: 0.77\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7838\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7173\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7806\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.5338 - accuracy: 0.7836\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5316 - accuracy: 0.7420\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4583 - accuracy: 0.7724\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.8203\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.8303\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7831\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.8614\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8512\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7443\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7861\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8438\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8095\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8337\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8463\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8019\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8486\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4624 - accuracy: 0.8032\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.8180\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.4000 - accuracy: 0.8418\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.8106\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8143\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8314\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8028\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7805\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8086\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8471\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8222\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8431\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8564\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7436\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8263\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7836\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8566\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8126\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8516\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8570\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8423\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8026\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8626\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8356\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8690\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8405\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8522\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.9190\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8356\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8851\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8083\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8035\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8776\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8379\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8759\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7832\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8464\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8009\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8430\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8482\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8411\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4047 - accuracy: 0.8641\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.9005\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8357\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8977\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3137 - accuracy: 0.8817\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8578\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.9022\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8418\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8890\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8625\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8624\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8276\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8325\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8589\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8115\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8657\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8340\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8677\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8836\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8652\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5750\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5220\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5613\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5486\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5424\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.4880\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.5997\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5641\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5317\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.5682\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5215\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6099\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6260\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.7009\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6528\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.6801\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6772\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7970\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8222\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8020\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7475\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8079\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8463\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8535\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8084\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8229\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8692\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.8191\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8412\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8458\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7508\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8028\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.9018\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7993\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8888\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8815\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8118\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8725\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8388\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8324\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.9224\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7988\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8386\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8544\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8386\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8211\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8402\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8642\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8557\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8630\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8164\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8109\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8145\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.9083\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8156\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8390\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8774\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8065\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8698\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8786\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8217\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.9019\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8649\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9315\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8689\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8861\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8271\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8160\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8673\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8852\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8435\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7961\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9001\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8593\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8753\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8804\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8632\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8953\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9110\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8525\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8977\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9171\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8589\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9289\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8539\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.9067\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.9132\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8630\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8678\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8800\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.9121\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8471\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.9024\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8610\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9154\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8782\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8730\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 1ms/step - loss: 0.6928 - accuracy: 0.5572\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4864\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5589\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5800\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5123\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4976\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5922\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5401\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5260\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5504\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5167\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5632\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5464\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5517\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5797\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5341\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.6484\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5524\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5560\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5208\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5272\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5815\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.4712\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.6143\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5385\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.6219\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5377\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4931\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.4677\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5232\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5881\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6406\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4959\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5415\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5481\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5630\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5236\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.4843\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5655\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5842\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.4802\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.4982\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5672\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6074\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5203\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5427\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5935\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5222\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5018\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.4339\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7036 - accuracy: 0.4531\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5488\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5122\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5600\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5138\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5338\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6153\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5537\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5741\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5129\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.6223\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5502\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4990\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6528\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5565\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5563\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.4877\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.4841\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5608\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5393\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5653\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5732\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4922\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4961\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5170\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5557\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4982\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5050\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5889\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5874\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5428\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6161\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5673\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4982\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6226\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5250\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5633\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6844 - accuracy: 0.5745\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5224\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5332\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4930\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5949\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5328\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5142\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5483\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.5015\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5745\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5137\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5681\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4932\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5335\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5881\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5034\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.4840\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.5936\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.5534\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.5738\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.5878\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6105\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6796\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6624\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6760\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7100\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7784\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8079\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8124\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8585\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8097\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8095\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8523\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8155\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7990\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8327\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8661\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8316\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7827\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8533\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8498\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7257\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7728\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8576\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8428: 0s - loss: 0.3788 - accuracy: 0.\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8860: 0s - loss: 0.3482 - accuracy\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8416\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8131\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8628\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8327\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4494 - accuracy: 0.8220\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.8841\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.5323 - accuracy: 0.7529: 0s - loss: 0.6077 - accu\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8192\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.3847 - accuracy: 0.8478\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8086\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4061 - accuracy: 0.8398\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8420\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8225\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8012\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8296\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7990\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7394\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8254\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7780\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8700\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7844\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8705\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8718\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8097\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8398\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8522\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8881\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8761\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8166\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.9073\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9343\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8497\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8783\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8022\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8162\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9154\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8573\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8643\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7901\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8455\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8644\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8367\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8758\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8049\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8583\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8991\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8583\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8877\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8739\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8855\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.9101\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8657\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8996\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8535\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8692\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8779\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8543\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8674\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8470\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.9120\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8398\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.9259\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8529\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8495\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 1ms/step - loss: 0.6934 - accuracy: 0.4805\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4697\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5231\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5893\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5244\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5610\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6074\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.5819\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.5576\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.5729\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6286\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6937\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6628\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6687\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.6829\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7726\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8023\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7817\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7987\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8108\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.6945\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8541\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8121\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8241\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8178\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8690\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8526\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7886\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8457\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8700\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.8231\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8275\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8651\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8796\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8713\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8560\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8153\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8712\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8773\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8436\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8853\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7595\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8691\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8404\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7665: 0s - loss: 0.4855 - accura\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8325\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8372\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8551\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8547\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8542\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.8113\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8280\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8587\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.7854\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.9109\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.5518 - accuracy: 0.7952\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.8468\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8682\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8090\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8532\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8268\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8754\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8492\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8414\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8765\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9417\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8115\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8626\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8322\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8641\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8759\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8475\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8428\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8243\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8842\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8255\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8601\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8728\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8109\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8708\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8999\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7767\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8922\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8832\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8128\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2771 - accuracy: 0.9283\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7672\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8760\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8534\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8472\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.9015\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8677\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8337\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8225\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8852\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8114\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8828\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8601\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8375\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.4835\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4760\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5206\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.6044\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5323\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5579\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5798\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5859\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5354\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.6159\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6465\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6070 - accuracy: 0.6906\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.6922\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7317\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7558\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8231\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8695\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8325\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8827\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8003\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8373\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8306\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8436\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8559\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8158\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8723\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8583\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7903\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8726\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8695\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8080\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8542\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.8531\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8489\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.9210\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9015\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8834\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8804\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8599\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8219\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8891\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8403\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8756\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8383\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8494\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8565\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8579\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8662\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8864\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8954\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8689\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8586\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8721\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8647\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.9045\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8532\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8889\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8819\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8985\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3737 - accuracy: 0.8488\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8679\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9317\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.3603 - accuracy: 0.8573 ETA: 0s - loss:\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.2249 - accuracy: 0.9212\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.2313 - accuracy: 0.9056\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.1740 - accuracy: 0.9308\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.9019\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2651 - accuracy: 0.9094\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.8873\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8952\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8981\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8327\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8930\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8403\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.8871\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.9062\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9110\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.9111\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.8778\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.2191 - accuracy: 0.9012\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9111\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8536\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.9072\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.8773\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.9126\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9242\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8960\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9289\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9073\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.8897\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9183\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8870\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.8804\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8930\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9166\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8954\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9218\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9023\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.9135\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 2s 1ms/step - loss: 0.6933 - accuracy: 0.5266\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5683\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5586\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4586\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5845\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.4929\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5599\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.6451\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6507\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6789\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6750\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7533\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7960\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7420\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5429 - accuracy: 0.7335\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.8028\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7850\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4828 - accuracy: 0.8315\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.4998 - accuracy: 0.7653\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7946\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3766 - accuracy: 0.8321\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8225: 0s - l\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4013 - accuracy: 0.8352\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7623\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7954\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7943\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.4405 - accuracy: 0.7938\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3582 - accuracy: 0.8336\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8433\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3671 - accuracy: 0.8346\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5046 - accuracy: 0.7509\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3600 - accuracy: 0.8204\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4284 - accuracy: 0.7420\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2897 - accuracy: 0.8841\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2798 - accuracy: 0.8888\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2838 - accuracy: 0.8661\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3372 - accuracy: 0.8514\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3776 - accuracy: 0.8494\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3471 - accuracy: 0.8681\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2891 - accuracy: 0.8957\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3228 - accuracy: 0.8556: 0s - loss: 0.3136 - \n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4358 - accuracy: 0.8087\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8347\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8693\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8534\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8461\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8991\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8803\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8317\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8871\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8326\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.8977\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8742\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8475\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8731\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8429\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8931\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8762\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8635\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.8665\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8421\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8049\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8530\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8937\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8382\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.8974\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8724\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8202\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9187\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.9055\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8939\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8885\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8212\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.9083\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.8896\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.8888\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9360\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9151\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9143\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9331\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8497\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.9010\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8658\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8636\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8833\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8720\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.9002\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.9227\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8593\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8995\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9148\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9154\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8821\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9470\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9508\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9087\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9228\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8740\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9245\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.6933 - accuracy: 0.4994\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.5426\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6927 - accuracy: 0.5365\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6941 - accuracy: 0.4639\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6910 - accuracy: 0.5717\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4979\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5583\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4979\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4833\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4962\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5605\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.6023\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5337\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.4644\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.4923\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5730\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5158 ETA: 0s - loss: 0.6975 - accuracy: \n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4937\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.6086\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5433\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5607\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5514\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6912 - accuracy: 0.5332\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5649\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5716\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5661\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5278\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5169\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5778\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5138\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5200\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5359\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.4761\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5803\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6047\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5165\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5005\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6840 - accuracy: 0.5854\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5640\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5207\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5344\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6891 - accuracy: 0.5480\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5603\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5979\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5324\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5173\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5173\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5122\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5499\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6922 - accuracy: 0.5253\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.4819\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6950 - accuracy: 0.5051\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6812 - accuracy: 0.6022\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6908 - accuracy: 0.5357\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.5238\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.5546\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6942 - accuracy: 0.5114\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.5151\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6844 - accuracy: 0.5799\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5859\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6962 - accuracy: 0.4977\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5035\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5325\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5940\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5337\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5750\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4939\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5913\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5853\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5726\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6946 - accuracy: 0.5095\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6883 - accuracy: 0.5527\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6802 - accuracy: 0.6070\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4984\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5903\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.7016 - accuracy: 0.4595\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5038\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5906\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6860 - accuracy: 0.5684\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6898 - accuracy: 0.5426\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6820 - accuracy: 0.5953\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6853 - accuracy: 0.5730\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.5043\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5383\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5529\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5285\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4993\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5363\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4993\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5760\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5336\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.5001\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.4662\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4807\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5063\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.4796\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5482\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5031\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5511\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.4698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.5661\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5081\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5293\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4488\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5888\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6647\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.6970\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.6718\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6613\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7118\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7334\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7743\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.8226\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7648\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7467\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8081\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8290\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7926\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7698\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8432\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8310\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7845\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8365\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8274\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7861\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7718\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8041\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8432\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8419\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8467\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8310\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8435\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7878\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8461\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8673\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.8480\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8124\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8718\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8979\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8830\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8280\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8593\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8266\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8727\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8314\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8672\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8210\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8552\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8771\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8449\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8653\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8871\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9103\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8805\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8593\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8882\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8483\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2899 - accuracy: 0.8797\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8577\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8873\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8805\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8546\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8698\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8350\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8505\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8906\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8326\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8861\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8519\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8494\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8799\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8593\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8940\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8825\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8419\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.8996\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.9107\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8812\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8526\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9254\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8448\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9106\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8842\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8557\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8830\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8477\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.9067\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9246\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9254\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8854\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.8925\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9328\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8258\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.8820\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8704\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9219\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5459\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5267\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4592\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6249\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.6923\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.7631\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.7170\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.7354\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.7248\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7231: 0s - loss: 0.5670 - accuracy: 0.72\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8029\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7842\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8010\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7349\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8340\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7799\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7732\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7440\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8181\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8075\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7646\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8340\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8289\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7689\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7716\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8366\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8352\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8578\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8475\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8535\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8167\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7913\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8435\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8525\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8181\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8105\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8788\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8774\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8659\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8108\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8181\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8061\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8723\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8314\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8215\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8732\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8416\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8334\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.9047\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8254\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9137\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8460\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8521\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8965\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8094\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8664\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8517\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8323\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8665\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8656\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8609\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8509\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8528\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8189\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8691\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8555\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8403\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8729\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8607\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8779\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8392\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9343\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8634\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8303\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9069\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8940\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8720\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8618\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8895\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8352\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9060\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8502\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8541\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8747\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8454\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9232\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.8938\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.87 - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8736\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8892\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8910\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9136\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8873\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8740\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8506\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9238\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5785\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5631\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5618\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5728\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5678\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5105\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6325 - accuracy: 0.6302\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.5742\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.5327\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6783\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6237\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7098\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7167\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7645\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7307\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7932\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7946\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8289\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8052\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8265\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8254\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8375\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8038\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8321\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8108\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8495\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8833\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7827\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8251\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8155\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7817\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7867\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8907\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8207\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8716\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8596\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8148\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8853\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8253\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8127\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8465\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8351\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8287\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8095\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8396: 0s - loss: 0.3647 - accu\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7967\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8219\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8253\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8104\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8302\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8209\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7853\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8697\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7515\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8484\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8055\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8861\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8931\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8323\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8347\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8168\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8174\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8864\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8020\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8429\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.9015\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8287\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8627\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8425\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8048\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8160\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8490\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8745\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8174\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8321\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8418\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8781\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8794\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8196\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8549\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8907\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3716 - accuracy: 0.8514\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8899\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3193 - accuracy: 0.8804\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8500\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8818\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8129\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8640\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8933\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8630\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8550\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8732\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8456\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8250\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8730\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8612\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8654\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.9010\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8330\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8052\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8923\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8314\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8580\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.9221: 0s - loss: 0.2709 - accuracy: 0.\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8721\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8122\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8518\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.9309\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8588\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8812\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8044\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8299\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8968\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8541\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8734\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8482\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8469\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.9110\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9221\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.6123\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5220\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5613\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5486\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.5424\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.4880\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6582\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6865\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6670\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8192\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7318\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8149\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8390\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8359\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8508\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8191\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8443\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8663\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8292\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8518\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8407\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8454\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8283\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8920\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8296\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8585\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8886\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8220\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8501\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8298\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8258\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8243\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8702\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8999\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.9024\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8511\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8425\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9025\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.8581\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8471\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8981\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8683\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8500\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8538\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8400\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8128\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8825\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8608\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8360\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8733\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8739\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7710\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8696\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8029\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.9067\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.7987\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8660\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8987\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8773\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8329\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8549\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8936\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9328\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8752\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8609\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9184\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8846\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9362\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8920\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8689\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8926: 0s - loss: 0.2406 - accuracy: 0.\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8891\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8892\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.7953\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8405\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8818\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.9187\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.8842\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8325\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.9043\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9084\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8689\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9025\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9130\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8887\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9304\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8706\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8900\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.9052\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.9218\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9077\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.9015\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9230\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8487\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.9001\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8850\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9258\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.8899\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.9079\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.8876\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9055\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8696\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8833\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.8942\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9038\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.8862\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.9105\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9393\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9018\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9187\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8427\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8690\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9073\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8297\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9377\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9116\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8669\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9322\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9358\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 1ms/step - loss: 0.6929 - accuracy: 0.5572\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4864\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5589\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5800\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5123\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5295\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.7103\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7772\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.6613\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8507\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7410\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4137 - accuracy: 0.8289\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7386\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8264\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7800\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8154\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8570\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8542\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8198\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8223\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8397\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.7959\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8736\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8497\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8478\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8466\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8741\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7727\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8457\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8355\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8152\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8082\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8554\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8290\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8935\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8500\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8285\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8412\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8151\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8297\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.9047\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8133\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8235\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.7997\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.7808\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8085\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8044\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8155\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8302\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8335\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.7999\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7226\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8626\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7502\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8477\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.7889\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8446\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8707\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.7720\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8074\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8562\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8260\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8440\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8113\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8755\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9016\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8500\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8707\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8101\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.7853\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8495\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8096\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8345\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7216\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8113\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8319\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8724\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8642\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7747\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8307\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8870\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8477\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8122\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8532\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8311\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8799\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8791\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8739\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8626\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8455\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8964\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8534\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8173\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8071\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8919\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8395\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8813\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.8780\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.9016\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8918\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8532\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8264\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8406\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8843\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.8829\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.8361\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8475\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.9020\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8202\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2390 - accuracy: 0.8712\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3786 - accuracy: 0.7872\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8449\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8039\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8089\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8395\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8570\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8392\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8914: 0s - loss: 0.2449 - accuracy\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9059\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.9261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5309\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.4932\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.6911 - accuracy: 0.5335: 0s - loss: 0.692\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.6807 - accuracy: 0.5939\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6584 - accuracy: 0.6421\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.6038 - accuracy: 0.6769\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5213 - accuracy: 0.8410\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7686\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.6990\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8321\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7576\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8034\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7305\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8525\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8563\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.3790 - accuracy: 0.8522\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.8268\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.3561 - accuracy: 0.8778: 0s - loss: 0.3394 - accuracy\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.3847 - accuracy: 0.8637\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3664 - accuracy: 0.8530\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8100\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3446 - accuracy: 0.8321\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8632\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8479\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8576\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8556\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8698\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7705\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8779\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8050\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.8507\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7883\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8884\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8534\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.9016\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8385\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8548\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8569\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8563\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8473\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.9007\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8389\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.3584 - accuracy: 0.8135: 0s - loss: 0.3728 - \n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.3546 - accuracy: 0.8116\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 1s 6ms/step - loss: 0.3371 - accuracy: 0.8564: 1s - los\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8428\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8535\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8372\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8502\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8556\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8408\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7497\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8924\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7887\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8928\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.7913\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8680\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8867\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8403\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8730\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8474\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9256\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8324\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8423\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.8934\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9504\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8729\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9252\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8552\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8367\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9192\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8737\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8741\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8394\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8859\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8759\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8892\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8937\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8275\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.9156\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9101\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8941\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9237\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8956\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.9131\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9398\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9222\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.8979\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8835\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.8951\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9366\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9429\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.8995\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9102\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9392\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8684\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9173\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9432\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9060\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9298\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8854\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9124\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9294\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9211\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9426\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9133\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.8776\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9135\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9373\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9331\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9030\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9217\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9340\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8887\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.9021\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9477\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9028\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9453\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9805\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4820\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4697\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5231\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.5893\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.5244\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.5853\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7658\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5408 - accuracy: 0.7159\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.6995\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8882\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7785\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8267\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7461\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8605\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8156\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8597\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8689\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8281\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8731: 0s - loss: 0.3745 - accuracy: 0.\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8081\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8106\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8753\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8578\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8393\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8624\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8865\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8700\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7985\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8577\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8251\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8037\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8071\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8851\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8728\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8810\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8518\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8888\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8562\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8642\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8331\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8992\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7967\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8642\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8373\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8364\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8044\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8703\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8554\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8308\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8618\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8224\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7741\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8605\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7711\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.9138\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7894\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8737\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8853\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8438\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8341\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8480\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8877\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8193\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8647\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8957\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9227\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8444\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.9082\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8477\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.7855\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2831 - accuracy: 0.8905\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8495\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8697\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.7850\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8386\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8430\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8607\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.7981\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.7816\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8485\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9072\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8127\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.8807\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.8853\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8188\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8904\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8626\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8903\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8561\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8372\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8426\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8688\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.7929\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8584\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8901\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8396\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.8877\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8704\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8659\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8865\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8192\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8436\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8719\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9185\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9065\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8069\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8892\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.8922\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8472\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.8804\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8124\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8272\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.8739\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8028\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8442\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8294\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8903\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9084\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9109\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 1ms/step - loss: 0.6933 - accuracy: 0.4860\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4760\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5206\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.6044\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5323\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5579\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5798\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5859\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5354\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5809\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5448\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5683\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5269\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5413\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5677\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5607\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5879\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5611\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5961\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5444\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5281\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5021\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5943\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.4714\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5628\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5309\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5878\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5150\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.4800\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.4480\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5274\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5708\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5933\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5153\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5336\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5805\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5559\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.5020\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.4559\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5286\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5793\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5094\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5191\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5616\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5775\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.4666\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5538\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5325\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5217\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5089\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.4550\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.4623\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5662\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.4654\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5464\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5279\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5833\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.5742\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5862\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5260\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5341\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5437 ETA: 0s - loss: 0.6907 - accuracy\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5890\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.4884\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.6478\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5470\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5349\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.4888\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5190\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5025\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5146\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5539\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5751\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5098\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5356\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.6229\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5800\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.4762\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5419\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5288\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.6181\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5542\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5742\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5808\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5079\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.6250\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5043\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5876\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5624\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4915\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5264\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4997\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5392\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5122\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5023\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5612\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5442\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5729\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4876\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.4813\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5374\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5379\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.4819\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5688\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5728\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.4632\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5411\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5973\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5217\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5491\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5415\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5822\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5173\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5410\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5871\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5779\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5557\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.6005\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4857\n",
      "Epoch 2/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5683\n",
      "Epoch 3/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5586\n",
      "Epoch 4/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.4586\n",
      "Epoch 5/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5845\n",
      "Epoch 6/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4929\n",
      "Epoch 7/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5603\n",
      "Epoch 8/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4776\n",
      "Epoch 9/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4973\n",
      "Epoch 10/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4968\n",
      "Epoch 11/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5223\n",
      "Epoch 12/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5805\n",
      "Epoch 13/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5302\n",
      "Epoch 14/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4766\n",
      "Epoch 15/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4805\n",
      "Epoch 16/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5646\n",
      "Epoch 17/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4877\n",
      "Epoch 18/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4850\n",
      "Epoch 19/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5836\n",
      "Epoch 20/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5384\n",
      "Epoch 21/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5723\n",
      "Epoch 22/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5537\n",
      "Epoch 23/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 24/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5317\n",
      "Epoch 25/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5504\n",
      "Epoch 26/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5498\n",
      "Epoch 27/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4922\n",
      "Epoch 28/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5182\n",
      "Epoch 29/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5864\n",
      "Epoch 30/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5419\n",
      "Epoch 31/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5007\n",
      "Epoch 32/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5158\n",
      "Epoch 33/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5013\n",
      "Epoch 34/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5536\n",
      "Epoch 35/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.6060\n",
      "Epoch 36/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.5002\n",
      "Epoch 37/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5000\n",
      "Epoch 38/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6096\n",
      "Epoch 39/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5659\n",
      "Epoch 40/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5293\n",
      "Epoch 41/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5416\n",
      "Epoch 42/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5436\n",
      "Epoch 43/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5942\n",
      "Epoch 44/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5901\n",
      "Epoch 45/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5037\n",
      "Epoch 46/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5177\n",
      "Epoch 47/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5042\n",
      "Epoch 48/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5212\n",
      "Epoch 49/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5461\n",
      "Epoch 50/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5187\n",
      "Epoch 51/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.4744\n",
      "Epoch 52/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.4879\n",
      "Epoch 53/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5930\n",
      "Epoch 54/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5323\n",
      "Epoch 55/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5253\n",
      "Epoch 56/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5532\n",
      "Epoch 57/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5627\n",
      "Epoch 58/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5096\n",
      "Epoch 59/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5701\n",
      "Epoch 60/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5601\n",
      "Epoch 61/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4819\n",
      "Epoch 62/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5056\n",
      "Epoch 63/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5495\n",
      "Epoch 64/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5853\n",
      "Epoch 65/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5011\n",
      "Epoch 66/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5717\n",
      "Epoch 67/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5209\n",
      "Epoch 68/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5951\n",
      "Epoch 69/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5754\n",
      "Epoch 70/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6027\n",
      "Epoch 71/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5408\n",
      "Epoch 72/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5128\n",
      "Epoch 73/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5927\n",
      "Epoch 74/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5227\n",
      "Epoch 75/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5944\n",
      "Epoch 76/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.4861\n",
      "Epoch 77/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.4545\n",
      "Epoch 78/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5644\n",
      "Epoch 79/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5526\n",
      "Epoch 80/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5499\n",
      "Epoch 81/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5471\n",
      "Epoch 82/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5932\n",
      "Epoch 83/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5086\n",
      "Epoch 84/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5615\n",
      "Epoch 85/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5453\n",
      "Epoch 86/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5410\n",
      "Epoch 87/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4904\n",
      "Epoch 88/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5010\n",
      "Epoch 89/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5194\n",
      "Epoch 90/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5445\n",
      "Epoch 91/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5407\n",
      "Epoch 92/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5054\n",
      "Epoch 93/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4571\n",
      "Epoch 94/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.4846\n",
      "Epoch 95/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5349\n",
      "Epoch 96/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.4692\n",
      "Epoch 97/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5592\n",
      "Epoch 98/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5111\n",
      "Epoch 99/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5542\n",
      "Epoch 100/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.4440\n",
      "Epoch 101/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4817\n",
      "Epoch 102/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4905\n",
      "Epoch 103/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4999\n",
      "Epoch 104/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4990\n",
      "Epoch 105/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5178\n",
      "Epoch 106/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4891\n",
      "Epoch 107/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5415\n",
      "Epoch 108/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5231\n",
      "Epoch 109/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5732\n",
      "Epoch 110/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5745\n",
      "Epoch 111/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5329\n",
      "Epoch 112/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5286\n",
      "Epoch 113/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.4781\n",
      "Epoch 114/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4829\n",
      "Epoch 115/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4742\n",
      "Epoch 116/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5338\n",
      "Epoch 117/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5872\n",
      "Epoch 118/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.6656\n",
      "Epoch 119/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5295\n",
      "Epoch 120/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4933\n",
      "Epoch 2/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5426\n",
      "Epoch 3/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5365\n",
      "Epoch 4/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4639\n",
      "Epoch 5/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5717\n",
      "Epoch 6/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4979\n",
      "Epoch 7/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5583\n",
      "Epoch 8/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4979\n",
      "Epoch 9/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.4833\n",
      "Epoch 10/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4962\n",
      "Epoch 11/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5605\n",
      "Epoch 12/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.6023\n",
      "Epoch 13/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5337\n",
      "Epoch 14/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.4644\n",
      "Epoch 15/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4923\n",
      "Epoch 16/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5730\n",
      "Epoch 17/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5158\n",
      "Epoch 18/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4937\n",
      "Epoch 19/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.6086\n",
      "Epoch 20/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5433\n",
      "Epoch 21/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5607\n",
      "Epoch 22/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5514\n",
      "Epoch 23/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5332\n",
      "Epoch 24/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5649\n",
      "Epoch 25/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5716\n",
      "Epoch 26/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5661\n",
      "Epoch 27/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5278\n",
      "Epoch 28/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5169\n",
      "Epoch 29/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5778\n",
      "Epoch 30/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5138\n",
      "Epoch 31/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5200\n",
      "Epoch 32/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5359\n",
      "Epoch 33/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4761\n",
      "Epoch 34/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5803\n",
      "Epoch 35/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6047\n",
      "Epoch 36/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5165\n",
      "Epoch 37/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5005\n",
      "Epoch 38/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5854\n",
      "Epoch 39/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5640\n",
      "Epoch 40/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5207\n",
      "Epoch 41/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5344\n",
      "Epoch 42/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5480\n",
      "Epoch 43/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5603\n",
      "Epoch 44/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.5979\n",
      "Epoch 45/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5324TA: 0s - loss: 0.6925 - accuracy\n",
      "Epoch 46/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5173\n",
      "Epoch 47/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5173\n",
      "Epoch 48/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5122\n",
      "Epoch 49/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5499\n",
      "Epoch 50/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5253\n",
      "Epoch 51/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.4819\n",
      "Epoch 52/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5051\n",
      "Epoch 53/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.6022\n",
      "Epoch 54/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5357\n",
      "Epoch 55/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5238\n",
      "Epoch 56/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5546\n",
      "Epoch 57/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5114\n",
      "Epoch 58/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5151\n",
      "Epoch 59/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5799\n",
      "Epoch 60/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5859\n",
      "Epoch 61/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4977\n",
      "Epoch 62/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5035\n",
      "Epoch 63/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5325\n",
      "Epoch 64/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5940\n",
      "Epoch 65/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5337\n",
      "Epoch 66/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5750\n",
      "Epoch 67/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.4939\n",
      "Epoch 68/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5913\n",
      "Epoch 69/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5853\n",
      "Epoch 70/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5726\n",
      "Epoch 71/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5095\n",
      "Epoch 72/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5527\n",
      "Epoch 73/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.6070\n",
      "Epoch 74/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4984\n",
      "Epoch 75/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5903\n",
      "Epoch 76/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4595\n",
      "Epoch 77/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5038\n",
      "Epoch 78/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5906\n",
      "Epoch 79/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5684\n",
      "Epoch 80/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5426\n",
      "Epoch 81/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5953\n",
      "Epoch 82/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5730\n",
      "Epoch 83/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5043\n",
      "Epoch 84/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5383\n",
      "Epoch 85/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5529\n",
      "Epoch 86/120\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.52 - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5285\n",
      "Epoch 87/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4993\n",
      "Epoch 88/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5363\n",
      "Epoch 89/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4993\n",
      "Epoch 90/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5760\n",
      "Epoch 91/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5336\n",
      "Epoch 92/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5001\n",
      "Epoch 93/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.4662\n",
      "Epoch 94/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.4807\n",
      "Epoch 95/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5063\n",
      "Epoch 96/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.4796\n",
      "Epoch 97/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5482\n",
      "Epoch 98/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5031\n",
      "Epoch 99/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5511\n",
      "Epoch 100/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.4698\n",
      "Epoch 101/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.4917\n",
      "Epoch 102/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5077\n",
      "Epoch 103/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5061\n",
      "Epoch 104/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.4971\n",
      "Epoch 105/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5192\n",
      "Epoch 106/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.4515\n",
      "Epoch 107/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5368\n",
      "Epoch 108/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5464\n",
      "Epoch 109/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5888\n",
      "Epoch 110/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5858\n",
      "Epoch 111/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5393\n",
      "Epoch 112/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5395\n",
      "Epoch 113/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4935\n",
      "Epoch 114/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.4754\n",
      "Epoch 115/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4992\n",
      "Epoch 116/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5077\n",
      "Epoch 117/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5854\n",
      "Epoch 118/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6608\n",
      "Epoch 119/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5315\n",
      "Epoch 120/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5706\n",
      "Epoch 2/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5353\n",
      "Epoch 3/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5293\n",
      "Epoch 4/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4037\n",
      "Epoch 5/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6475\n",
      "Epoch 6/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.6724\n",
      "Epoch 7/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.7119\n",
      "Epoch 8/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7340\n",
      "Epoch 9/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.6960\n",
      "Epoch 10/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7894\n",
      "Epoch 11/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7930\n",
      "Epoch 12/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.8321\n",
      "Epoch 13/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7982\n",
      "Epoch 14/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8311\n",
      "Epoch 15/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.8056\n",
      "Epoch 16/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8235\n",
      "Epoch 17/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8506\n",
      "Epoch 18/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8186\n",
      "Epoch 19/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7827\n",
      "Epoch 20/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8520\n",
      "Epoch 21/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8435\n",
      "Epoch 22/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8309\n",
      "Epoch 23/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8485\n",
      "Epoch 24/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8602\n",
      "Epoch 25/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8707\n",
      "Epoch 26/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8612\n",
      "Epoch 27/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8997\n",
      "Epoch 28/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8762\n",
      "Epoch 29/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.9042\n",
      "Epoch 30/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8614\n",
      "Epoch 31/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8983\n",
      "Epoch 32/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.9037\n",
      "Epoch 33/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8575\n",
      "Epoch 34/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.9003\n",
      "Epoch 35/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.9321\n",
      "Epoch 36/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8905\n",
      "Epoch 37/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8869\n",
      "Epoch 38/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9275\n",
      "Epoch 39/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8924\n",
      "Epoch 40/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.9311\n",
      "Epoch 41/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8783\n",
      "Epoch 42/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8794\n",
      "Epoch 43/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8751\n",
      "Epoch 44/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.9296\n",
      "Epoch 45/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8794\n",
      "Epoch 46/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.9185\n",
      "Epoch 47/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9403\n",
      "Epoch 48/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8774\n",
      "Epoch 49/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8791\n",
      "Epoch 50/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9517: 0s - loss: 0.1421 - accura\n",
      "Epoch 51/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8856\n",
      "Epoch 52/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9630\n",
      "Epoch 53/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9118\n",
      "Epoch 54/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.9058\n",
      "Epoch 55/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9433\n",
      "Epoch 56/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9274\n",
      "Epoch 57/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8937\n",
      "Epoch 58/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.9087\n",
      "Epoch 59/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9155\n",
      "Epoch 60/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9100\n",
      "Epoch 61/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.9065\n",
      "Epoch 62/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.9014\n",
      "Epoch 63/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.8969\n",
      "Epoch 64/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.9051\n",
      "Epoch 65/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8810\n",
      "Epoch 66/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9321: 0s - loss: 0.1845 - accuracy\n",
      "Epoch 67/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.9003\n",
      "Epoch 68/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.9205\n",
      "Epoch 69/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9293\n",
      "Epoch 70/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.9087\n",
      "Epoch 71/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9094\n",
      "Epoch 72/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9301\n",
      "Epoch 73/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8980\n",
      "Epoch 74/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9433\n",
      "Epoch 75/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9220\n",
      "Epoch 76/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9686\n",
      "Epoch 77/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9356\n",
      "Epoch 78/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8696\n",
      "Epoch 79/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9592\n",
      "Epoch 80/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9589\n",
      "Epoch 81/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9516\n",
      "Epoch 82/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.9602\n",
      "Epoch 83/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9719\n",
      "Epoch 84/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8838\n",
      "Epoch 85/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9350\n",
      "Epoch 86/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9374\n",
      "Epoch 87/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9028\n",
      "Epoch 88/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9277\n",
      "Epoch 89/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8843\n",
      "Epoch 90/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9443\n",
      "Epoch 91/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.9546\n",
      "Epoch 92/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9554\n",
      "Epoch 93/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2936 - accuracy: 0.8986\n",
      "Epoch 94/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9749\n",
      "Epoch 95/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9619\n",
      "Epoch 96/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9171\n",
      "Epoch 97/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9736\n",
      "Epoch 98/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.9090\n",
      "Epoch 99/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9691\n",
      "Epoch 100/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9487\n",
      "Epoch 101/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9727\n",
      "Epoch 102/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9807\n",
      "Epoch 103/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9831\n",
      "Epoch 104/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9742\n",
      "Epoch 105/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9616\n",
      "Epoch 106/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.9514\n",
      "Epoch 107/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9720\n",
      "Epoch 108/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9406\n",
      "Epoch 109/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9382\n",
      "Epoch 110/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9590\n",
      "Epoch 111/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9077\n",
      "Epoch 112/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9256\n",
      "Epoch 113/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9656\n",
      "Epoch 114/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8931\n",
      "Epoch 115/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9252\n",
      "Epoch 116/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9753\n",
      "Epoch 117/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9525\n",
      "Epoch 118/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9419\n",
      "Epoch 119/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9283\n",
      "Epoch 120/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.6933 - accuracy: 0.4677\n",
      "Epoch 2/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5459\n",
      "Epoch 3/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5267\n",
      "Epoch 4/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4563\n",
      "Epoch 5/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5934\n",
      "Epoch 6/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4844\n",
      "Epoch 7/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5699\n",
      "Epoch 8/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4796\n",
      "Epoch 9/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4633\n",
      "Epoch 10/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4541\n",
      "Epoch 11/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5581\n",
      "Epoch 12/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5998\n",
      "Epoch 13/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5203\n",
      "Epoch 14/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.4704\n",
      "Epoch 15/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5035\n",
      "Epoch 16/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5382\n",
      "Epoch 17/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5269\n",
      "Epoch 18/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4530\n",
      "Epoch 19/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5426\n",
      "Epoch 20/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5325\n",
      "Epoch 21/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5653\n",
      "Epoch 22/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5382\n",
      "Epoch 23/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5341\n",
      "Epoch 24/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5404\n",
      "Epoch 25/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5579\n",
      "Epoch 26/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5094\n",
      "Epoch 27/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5236\n",
      "Epoch 28/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5050\n",
      "Epoch 29/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5360\n",
      "Epoch 30/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5044\n",
      "Epoch 31/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5399\n",
      "Epoch 32/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5263\n",
      "Epoch 33/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4647\n",
      "Epoch 34/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5797\n",
      "Epoch 35/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6125\n",
      "Epoch 36/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5012\n",
      "Epoch 37/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4761\n",
      "Epoch 38/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5544\n",
      "Epoch 39/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5512\n",
      "Epoch 40/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5247\n",
      "Epoch 41/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5219\n",
      "Epoch 42/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5512\n",
      "Epoch 43/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 44/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5469\n",
      "Epoch 45/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5181\n",
      "Epoch 46/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5178\n",
      "Epoch 47/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4964\n",
      "Epoch 48/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4890\n",
      "Epoch 49/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5674\n",
      "Epoch 50/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5314\n",
      "Epoch 51/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4870\n",
      "Epoch 52/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5578\n",
      "Epoch 53/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5670\n",
      "Epoch 54/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5569\n",
      "Epoch 55/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5050\n",
      "Epoch 56/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5369\n",
      "Epoch 57/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5190\n",
      "Epoch 58/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5142\n",
      "Epoch 59/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5505\n",
      "Epoch 60/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5588\n",
      "Epoch 61/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5098\n",
      "Epoch 62/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5096\n",
      "Epoch 63/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5657\n",
      "Epoch 64/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5905\n",
      "Epoch 65/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5390\n",
      "Epoch 66/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5176\n",
      "Epoch 67/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4862\n",
      "Epoch 68/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5819\n",
      "Epoch 69/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5704\n",
      "Epoch 70/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5353\n",
      "Epoch 71/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5063\n",
      "Epoch 72/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5977\n",
      "Epoch 73/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5671\n",
      "Epoch 74/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4854\n",
      "Epoch 75/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5620\n",
      "Epoch 76/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4514\n",
      "Epoch 77/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.4873\n",
      "Epoch 78/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5166\n",
      "Epoch 79/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5700\n",
      "Epoch 80/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5297\n",
      "Epoch 81/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5941\n",
      "Epoch 82/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5424\n",
      "Epoch 83/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5469\n",
      "Epoch 84/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5253\n",
      "Epoch 85/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5070\n",
      "Epoch 86/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4887\n",
      "Epoch 87/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5028\n",
      "Epoch 88/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5494\n",
      "Epoch 89/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.4712\n",
      "Epoch 90/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5667\n",
      "Epoch 91/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.4722\n",
      "Epoch 92/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5112\n",
      "Epoch 93/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.4944\n",
      "Epoch 94/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4901\n",
      "Epoch 95/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5166\n",
      "Epoch 96/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.4659\n",
      "Epoch 97/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5081\n",
      "Epoch 98/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4938\n",
      "Epoch 99/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5274\n",
      "Epoch 100/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.4720\n",
      "Epoch 101/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4711\n",
      "Epoch 102/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5054\n",
      "Epoch 103/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5656\n",
      "Epoch 104/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4984\n",
      "Epoch 105/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5067\n",
      "Epoch 106/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4667\n",
      "Epoch 107/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4903\n",
      "Epoch 108/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5469\n",
      "Epoch 109/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5530\n",
      "Epoch 110/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5707\n",
      "Epoch 111/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5124\n",
      "Epoch 112/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5689\n",
      "Epoch 113/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.4496\n",
      "Epoch 114/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4522\n",
      "Epoch 115/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5465\n",
      "Epoch 116/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5054\n",
      "Epoch 117/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5647\n",
      "Epoch 118/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6510\n",
      "Epoch 119/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5139\n",
      "Epoch 120/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5785\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5631\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5618\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5728\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5678\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5105\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6302\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.5742\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5259\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6037\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5412\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6178\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6166\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6066\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6663\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7165\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6958\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7526\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7665\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7395\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7156\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7803\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7795\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7896\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8022\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8141\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8420\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7975\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8808\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8068\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7301\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8060\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8536\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7939\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8631\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8504\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8018\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8649\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8056\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8138\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8613\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.8022\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8155\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8350\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8104\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8068\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8109\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8518\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8300\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8431\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8426\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7462\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8291\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7987\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8883\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7906\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8862\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8756\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8448\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8131\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8676\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8732\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8827\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8397\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8795\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9255\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8582\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8653\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8072\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8227\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8706\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8530\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8705\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7524\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8547\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8154\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8664\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8668\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8093\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8529\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.9066\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8652\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8836\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8928\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8519\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.91 - 0s 2ms/step - loss: 0.2737 - accuracy: 0.9047\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8340\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.9008\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8628\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8653\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8711\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8474\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8524\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8393\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8795\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8546\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8654\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8638\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8849\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8337\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8668\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8457\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8397\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9240\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8929: 0s - loss: 0.2788 - accuracy: \n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8598\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8676\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9210\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8592\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9081\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8689\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8548\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8607\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8136\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8597\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8338\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8174\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9062\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8848\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.6123\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5220\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5613\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5486\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5424\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.4880\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.5997\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.5641\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5317 ETA: 0s - loss: 0.7035 - accuracy\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.5682\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.5215\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6112 - accuracy: 0.6216\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6344\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7162\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6783\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7164\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7451\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7898\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8148\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.8202\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7528\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8007\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8484\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8535\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8163\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8489\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8692\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.8249\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8463\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8755\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7555\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8113\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8657\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8067\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8783\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8755\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8182\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8820\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8559\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8051\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8890\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7776\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8199\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8505\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8431\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8379\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8416\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8528\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8601\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8415\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8565\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8179\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8512\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7953\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.9256\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8173\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8819\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8397\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8158\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8463\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8782\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8337\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8919\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8255\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8925\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9313\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8696\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.9001\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8218\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8641\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8788\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8817\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8408\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8086\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.9046\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8692\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8708: 0s - loss: 0.3120 - accuracy: 0.87\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.9110\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8815\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.9011\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.9161\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8414\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9157\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9210\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8910\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9405\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.9069\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.9161\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.9234\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.9307\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9034\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8893\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9464\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9243\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9330\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8953\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9473\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.9110\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8907\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.9630\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8823\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.9028\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.9148\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9614\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9594\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9597\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.9424\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9444\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9238\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9567\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.9481\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.9221\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9527\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9330\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9203\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.9264\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9490\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9468\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.9583\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9148: 0s - loss: 0.2462 - accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5945\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4864\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5589\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5800\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5123\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.4976\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.5922\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5401\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5260\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.5504\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.5413\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6516\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6562\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6875\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7144\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7599\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.8357\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7919\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8166\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8287\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8312\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8422\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8466\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8379\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8207\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8443\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8533\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7708\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8189\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8828\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7611\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7707\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8042\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8228\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.9032\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8735\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8234\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8619\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8165\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8133\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.9061\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7672\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8219\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8030\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8169\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8215\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8142\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8342\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8715\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8455\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8043\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7654\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8368\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8009\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8785\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8006\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8444\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8347\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7926\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8300\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8241\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.7770\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8192\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8273\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8885\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9192\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8305\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8819\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7844\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4010 - accuracy: 0.7881\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8441\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8448\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8331\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7294\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8510\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8423\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8310\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8545\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7736\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8251\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8908\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.7965\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8155\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8733\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8450\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.9136\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8163\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8822\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8242\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8600\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8489\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8250\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8303\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8260\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8713\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8037\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8671\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8381\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8385\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8582\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8355\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8384\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8221\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8614\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8783\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.9135\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8236\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8937\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8268\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.8789\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.7785\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.8394\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8338\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8524\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8389\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3438 - accuracy: 0.8851\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8171\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8902: 0s - loss: 0.1620 - \n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.8855\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5681\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4932\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5335\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5881\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6893 - accuracy: 0.5034\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.4840\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.5936\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.5592\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.5922\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.7106\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.6435 - accuracy: 0.6292 ETA: 3s - loss: 0.6820 - \n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7275\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.6812\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5391 - accuracy: 0.7299\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7517\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7895\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.8458\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8238\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8299\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8419\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7320\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8240\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8270\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4942 - accuracy: 0.8254\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.4095 - accuracy: 0.8195\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.8694\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4488 - accuracy: 0.8446\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.5941 - accuracy: 0.7906\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7947\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8664\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.7387\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7694\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8326\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8334\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8836\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8713\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8170\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.8671\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8322\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.8263\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8916\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7742\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.8100\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8403\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.4147 - accuracy: 0.7839\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8472\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8137\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8379\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8322\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8314\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8566\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7990\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.7916\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.8018\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8899\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7779\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8660\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8211\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8070\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8314\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8513\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8249\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8759\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8513\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.9057\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9441\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8583\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8926\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8385\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8314\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.3183 - accuracy: 0.8999\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8365\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8502\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7749\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8833\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8577\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8919\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.9119\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8406\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8782\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.9158\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8608\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.9144\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.9090\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8645\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.9279\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8685\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8914\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8585\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8955\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2938 - accuracy: 0.8389\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8784\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8923\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.9233\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9383\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8599\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.9066\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8940\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8936\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.9086\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8318\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.9200\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8747\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8832\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.9120\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9438\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8909\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9275\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8665\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9307\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.9138\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8861\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9137\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.9100\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8946\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9107\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.9190\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9604\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9477\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.4805\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4697\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5231\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5893\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5244\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5610\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.6074\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5819\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5576\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5729\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5490\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5816\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5403\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5410\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5604\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5760\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5772\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5950\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5622\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5435\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5218\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.4904\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5909\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4901\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5798\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5177\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5915\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5242\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5218\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.4605\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5282\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5773\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5968\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5341\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5306\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5753\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5789\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5121\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.4709\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5579\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5980\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.5022\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5184\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5698\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5723\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.4809\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5710\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5276\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5397TA: 0s - loss: 0.6922 - accura\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5135\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7057 - accuracy: 0.4557\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.4783\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5578\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.4924\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5764\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5420\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5852\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5695\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5925\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5245\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5410\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5608\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5755\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.4896\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6390\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5434\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5546\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.4920\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5381\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5087\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5779\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5579\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5742\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.5046\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5451\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5927\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5719\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.4881\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5536\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5372\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6171\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5596\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5801\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5761\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5137\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.6197\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5380\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5803\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5686\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5113\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5548\n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.5034\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5657\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5191\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5163\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5808\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5432\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5869\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5224\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.5018\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5293\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5657\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.4779\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5745\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5833\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.4728\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5376\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.6069\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5171\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5761\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5387\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5529\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5984\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5338\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5459\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5914\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5853\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5426\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.6042\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5208\n",
      "Epoch 2/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4760\n",
      "Epoch 3/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5206\n",
      "Epoch 4/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.6044\n",
      "Epoch 5/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5323\n",
      "Epoch 6/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.5579\n",
      "Epoch 7/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.5798\n",
      "Epoch 8/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6136\n",
      "Epoch 9/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6397\n",
      "Epoch 10/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7342\n",
      "Epoch 11/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6992\n",
      "Epoch 12/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7514\n",
      "Epoch 13/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8060: 0s - loss: 0.4969 - accuracy: 0.80\n",
      "Epoch 14/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8104\n",
      "Epoch 15/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.8091\n",
      "Epoch 16/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8161\n",
      "Epoch 17/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8693: 0s - loss: 0.3052 - accuracy\n",
      "Epoch 18/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8537\n",
      "Epoch 19/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8760\n",
      "Epoch 20/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.7935\n",
      "Epoch 21/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8610\n",
      "Epoch 22/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8205\n",
      "Epoch 23/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8901\n",
      "Epoch 24/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8754\n",
      "Epoch 25/120\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8618\n",
      "Epoch 26/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8750\n",
      "Epoch 27/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8743\n",
      "Epoch 28/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8003\n",
      "Epoch 29/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8895\n",
      "Epoch 30/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8918\n",
      "Epoch 31/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8692\n",
      "Epoch 32/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8640\n",
      "Epoch 33/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8546\n",
      "Epoch 34/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8533\n",
      "Epoch 35/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9051\n",
      "Epoch 36/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.9059\n",
      "Epoch 37/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8996\n",
      "Epoch 38/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8845\n",
      "Epoch 39/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8754\n",
      "Epoch 40/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8370\n",
      "Epoch 41/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9092\n",
      "Epoch 42/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8159\n",
      "Epoch 43/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8713\n",
      "Epoch 44/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8684\n",
      "Epoch 45/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8549\n",
      "Epoch 46/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8732\n",
      "Epoch 47/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8732\n",
      "Epoch 48/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8918\n",
      "Epoch 49/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8850\n",
      "Epoch 50/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.9237\n",
      "Epoch 51/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8725\n",
      "Epoch 52/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8722\n",
      "Epoch 53/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8764: 0s - loss: 0.1776 - accura\n",
      "Epoch 54/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8639\n",
      "Epoch 55/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.9151\n",
      "Epoch 56/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8304\n",
      "Epoch 57/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8822\n",
      "Epoch 58/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8985\n",
      "Epoch 59/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8902\n",
      "Epoch 60/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8519\n",
      "Epoch 61/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8949\n",
      "Epoch 62/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9258\n",
      "Epoch 63/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8660\n",
      "Epoch 64/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9203\n",
      "Epoch 65/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9321\n",
      "Epoch 66/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9405\n",
      "Epoch 67/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.9094\n",
      "Epoch 68/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9094\n",
      "Epoch 69/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.8880\n",
      "Epoch 70/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8771\n",
      "Epoch 71/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8971\n",
      "Epoch 72/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8794\n",
      "Epoch 73/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8975\n",
      "Epoch 74/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8213\n",
      "Epoch 75/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9099\n",
      "Epoch 76/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8814\n",
      "Epoch 77/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8969\n",
      "Epoch 78/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.9071\n",
      "Epoch 79/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.8954\n",
      "Epoch 80/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9300\n",
      "Epoch 81/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.9077\n",
      "Epoch 82/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8987\n",
      "Epoch 83/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8770\n",
      "Epoch 84/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.9093\n",
      "Epoch 85/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8908\n",
      "Epoch 86/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9326\n",
      "Epoch 87/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.9023\n",
      "Epoch 88/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9309\n",
      "Epoch 89/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8777\n",
      "Epoch 90/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.8988\n",
      "Epoch 91/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.8919: 0s - loss: 0.1392 - accuracy: \n",
      "Epoch 92/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8789\n",
      "Epoch 93/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8646\n",
      "Epoch 94/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8960\n",
      "Epoch 95/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.8953\n",
      "Epoch 96/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8898\n",
      "Epoch 97/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9206\n",
      "Epoch 98/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8923\n",
      "Epoch 99/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.9043\n",
      "Epoch 100/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.9117\n",
      "Epoch 101/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9059\n",
      "Epoch 102/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8761\n",
      "Epoch 103/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.9059\n",
      "Epoch 104/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9168\n",
      "Epoch 105/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9447\n",
      "Epoch 106/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9294\n",
      "Epoch 107/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9310\n",
      "Epoch 108/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9231\n",
      "Epoch 109/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8778\n",
      "Epoch 110/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9141\n",
      "Epoch 111/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.8876\n",
      "Epoch 112/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8931\n",
      "Epoch 113/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9135\n",
      "Epoch 114/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.9148\n",
      "Epoch 115/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.9183\n",
      "Epoch 116/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9651\n",
      "Epoch 117/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.9134\n",
      "Epoch 118/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9339\n",
      "Epoch 119/120\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9457\n",
      "Epoch 120/120\n",
      "149/149 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5266\n",
      "Epoch 2/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5683\n",
      "Epoch 3/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5586\n",
      "Epoch 4/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4586\n",
      "Epoch 5/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5845\n",
      "Epoch 6/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.4929\n",
      "Epoch 7/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5603\n",
      "Epoch 8/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.4776\n",
      "Epoch 9/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.4973\n",
      "Epoch 10/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.4998\n",
      "Epoch 11/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6299\n",
      "Epoch 12/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.6922\n",
      "Epoch 13/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6872\n",
      "Epoch 14/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6147\n",
      "Epoch 15/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6070\n",
      "Epoch 16/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7332\n",
      "Epoch 17/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7174\n",
      "Epoch 18/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7056\n",
      "Epoch 19/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7811\n",
      "Epoch 20/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7173\n",
      "Epoch 21/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7938\n",
      "Epoch 22/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7970\n",
      "Epoch 23/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8525\n",
      "Epoch 24/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7313\n",
      "Epoch 25/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7657\n",
      "Epoch 26/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7954\n",
      "Epoch 27/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7833\n",
      "Epoch 28/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8242\n",
      "Epoch 29/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8333\n",
      "Epoch 30/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8355\n",
      "Epoch 31/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7397\n",
      "Epoch 32/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8079\n",
      "Epoch 33/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8036\n",
      "Epoch 34/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8805\n",
      "Epoch 35/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8895\n",
      "Epoch 36/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8602\n",
      "Epoch 37/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8484\n",
      "Epoch 38/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8575\n",
      "Epoch 39/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8487\n",
      "Epoch 40/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8749\n",
      "Epoch 41/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8657\n",
      "Epoch 42/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8420\n",
      "Epoch 43/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8557\n",
      "Epoch 44/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8405\n",
      "Epoch 45/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8553\n",
      "Epoch 46/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8460\n",
      "Epoch 47/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8910\n",
      "Epoch 48/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8405\n",
      "Epoch 49/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8278\n",
      "Epoch 50/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8565\n",
      "Epoch 51/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8422\n",
      "Epoch 52/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.9064\n",
      "Epoch 53/120\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3741 - accuracy: 0.8258\n",
      "Epoch 54/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8607\n",
      "Epoch 55/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8227\n",
      "Epoch 56/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8563\n",
      "Epoch 57/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8429\n",
      "Epoch 58/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8547\n",
      "Epoch 59/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8496\n",
      "Epoch 60/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8855\n",
      "Epoch 61/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.7950\n",
      "Epoch 62/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7658\n",
      "Epoch 63/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8573\n",
      "Epoch 64/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.9085\n",
      "Epoch 65/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8392\n",
      "Epoch 66/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8961\n",
      "Epoch 67/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8739\n",
      "Epoch 68/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.8233\n",
      "Epoch 69/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8977\n",
      "Epoch 70/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8769\n",
      "Epoch 71/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8729\n",
      "Epoch 72/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8320\n",
      "Epoch 73/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8159\n",
      "Epoch 74/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8602\n",
      "Epoch 75/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8826\n",
      "Epoch 76/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8621\n",
      "Epoch 77/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9088\n",
      "Epoch 78/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8944\n",
      "Epoch 79/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8925\n",
      "Epoch 80/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8793\n",
      "Epoch 81/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8482\n",
      "Epoch 82/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8581\n",
      "Epoch 83/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8520\n",
      "Epoch 84/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8527\n",
      "Epoch 85/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8736\n",
      "Epoch 86/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8771\n",
      "Epoch 87/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8788\n",
      "Epoch 88/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8601\n",
      "Epoch 89/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8813\n",
      "Epoch 90/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8757\n",
      "Epoch 91/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9200\n",
      "Epoch 92/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9283\n",
      "Epoch 93/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8792\n",
      "Epoch 94/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9060\n",
      "Epoch 95/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9264\n",
      "Epoch 96/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8734\n",
      "Epoch 97/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.8992\n",
      "Epoch 98/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8744\n",
      "Epoch 99/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.8896\n",
      "Epoch 100/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 0.8857\n",
      "Epoch 101/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.9153\n",
      "Epoch 102/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9265\n",
      "Epoch 103/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.9214\n",
      "Epoch 104/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.8998\n",
      "Epoch 105/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8766\n",
      "Epoch 106/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8783\n",
      "Epoch 107/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8765\n",
      "Epoch 108/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.9006\n",
      "Epoch 109/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8677\n",
      "Epoch 110/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9239\n",
      "Epoch 111/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9321\n",
      "Epoch 112/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9162\n",
      "Epoch 113/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9517\n",
      "Epoch 114/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9057\n",
      "Epoch 115/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9084\n",
      "Epoch 116/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.9167\n",
      "Epoch 117/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9241\n",
      "Epoch 118/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8795\n",
      "Epoch 119/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8686\n",
      "Epoch 120/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5365\n",
      "Epoch 2/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5426\n",
      "Epoch 3/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5365\n",
      "Epoch 4/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4608\n",
      "Epoch 5/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.6292\n",
      "Epoch 6/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.7843\n",
      "Epoch 7/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.7205\n",
      "Epoch 8/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6652\n",
      "Epoch 9/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6447\n",
      "Epoch 10/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7654\n",
      "Epoch 11/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7736\n",
      "Epoch 12/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.8304\n",
      "Epoch 13/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.8318\n",
      "Epoch 14/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7997\n",
      "Epoch 15/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7757\n",
      "Epoch 16/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.8492\n",
      "Epoch 17/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8059\n",
      "Epoch 18/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8171\n",
      "Epoch 19/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.8017\n",
      "Epoch 20/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8294\n",
      "Epoch 21/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8732\n",
      "Epoch 22/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8452\n",
      "Epoch 23/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8241\n",
      "Epoch 24/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8535\n",
      "Epoch 25/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8569\n",
      "Epoch 26/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8495\n",
      "Epoch 27/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8666\n",
      "Epoch 28/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8514\n",
      "Epoch 29/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.9040\n",
      "Epoch 30/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8758\n",
      "Epoch 31/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8875\n",
      "Epoch 32/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.9019\n",
      "Epoch 33/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8428\n",
      "Epoch 34/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.9005\n",
      "Epoch 35/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.9131\n",
      "Epoch 36/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.9093\n",
      "Epoch 37/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.9089\n",
      "Epoch 38/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8964\n",
      "Epoch 39/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8979\n",
      "Epoch 40/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.9433\n",
      "Epoch 41/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8751\n",
      "Epoch 42/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8651\n",
      "Epoch 43/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8951\n",
      "Epoch 44/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8894\n",
      "Epoch 45/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.9089\n",
      "Epoch 46/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.9040\n",
      "Epoch 47/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.9218\n",
      "Epoch 48/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8919\n",
      "Epoch 49/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8622\n",
      "Epoch 50/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9185\n",
      "Epoch 51/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8573\n",
      "Epoch 52/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9527\n",
      "Epoch 53/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.9115\n",
      "Epoch 54/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.9091\n",
      "Epoch 55/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8863\n",
      "Epoch 56/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.9120\n",
      "Epoch 57/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8702\n",
      "Epoch 58/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.9013\n",
      "Epoch 59/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2955 - accuracy: 0.8998\n",
      "Epoch 60/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.9120\n",
      "Epoch 61/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8599\n",
      "Epoch 62/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8790\n",
      "Epoch 63/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8818\n",
      "Epoch 64/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.9139\n",
      "Epoch 65/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8697\n",
      "Epoch 66/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.9089\n",
      "Epoch 67/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8390\n",
      "Epoch 68/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8718\n",
      "Epoch 69/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9392\n",
      "Epoch 70/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8974\n",
      "Epoch 71/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.9138\n",
      "Epoch 72/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8739\n",
      "Epoch 73/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8697\n",
      "Epoch 74/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8697\n",
      "Epoch 75/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8765\n",
      "Epoch 76/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9385\n",
      "Epoch 77/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8905\n",
      "Epoch 78/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.9288\n",
      "Epoch 79/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.9086\n",
      "Epoch 80/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.9352\n",
      "Epoch 81/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.9086\n",
      "Epoch 82/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9463\n",
      "Epoch 83/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8908\n",
      "Epoch 84/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7890\n",
      "Epoch 85/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8776\n",
      "Epoch 86/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.9022\n",
      "Epoch 87/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8849\n",
      "Epoch 88/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8711\n",
      "Epoch 89/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8376\n",
      "Epoch 90/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8940\n",
      "Epoch 91/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.9230\n",
      "Epoch 92/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.8987\n",
      "Epoch 93/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8920\n",
      "Epoch 94/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9393\n",
      "Epoch 95/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9265\n",
      "Epoch 96/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.9073\n",
      "Epoch 97/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9408\n",
      "Epoch 98/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8521\n",
      "Epoch 99/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.9310\n",
      "Epoch 100/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8976\n",
      "Epoch 101/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.9003\n",
      "Epoch 102/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.9229\n",
      "Epoch 103/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8843\n",
      "Epoch 104/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.9368\n",
      "Epoch 105/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8796\n",
      "Epoch 106/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8907\n",
      "Epoch 107/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9449\n",
      "Epoch 108/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.9127\n",
      "Epoch 109/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8267\n",
      "Epoch 110/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9356\n",
      "Epoch 111/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.9061\n",
      "Epoch 112/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.9030\n",
      "Epoch 113/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9559\n",
      "Epoch 114/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8658\n",
      "Epoch 115/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.9020\n",
      "Epoch 116/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9400\n",
      "Epoch 117/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8935\n",
      "Epoch 118/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8998\n",
      "Epoch 119/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.9060\n",
      "Epoch 120/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "150/150 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5661\n",
      "Epoch 2/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5353\n",
      "Epoch 3/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5293\n",
      "Epoch 4/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4482: 0s - loss: 0.6945 - accuracy\n",
      "Epoch 5/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5806\n",
      "Epoch 6/120\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4811\n",
      "Epoch 7/120\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6906 - accuracy: 0.5765\n",
      "Epoch 8/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5021\n",
      "Epoch 9/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4757\n",
      "Epoch 10/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4649\n",
      "Epoch 11/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5616\n",
      "Epoch 12/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.6008\n",
      "Epoch 13/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5459\n",
      "Epoch 14/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4670\n",
      "Epoch 15/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5010\n",
      "Epoch 16/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5525\n",
      "Epoch 17/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5248\n",
      "Epoch 18/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.4776\n",
      "Epoch 19/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5743\n",
      "Epoch 20/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5340\n",
      "Epoch 21/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5709\n",
      "Epoch 22/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5441\n",
      "Epoch 23/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5404\n",
      "Epoch 24/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5500\n",
      "Epoch 25/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5609\n",
      "Epoch 26/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5471\n",
      "Epoch 27/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5348\n",
      "Epoch 28/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5251\n",
      "Epoch 29/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5504\n",
      "Epoch 30/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5077\n",
      "Epoch 31/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5329\n",
      "Epoch 32/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5387\n",
      "Epoch 33/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.4587\n",
      "Epoch 34/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5828\n",
      "Epoch 35/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.6015\n",
      "Epoch 36/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5146\n",
      "Epoch 37/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4862\n",
      "Epoch 38/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5563\n",
      "Epoch 39/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5513\n",
      "Epoch 40/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5295\n",
      "Epoch 41/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5367\n",
      "Epoch 42/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5521\n",
      "Epoch 43/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5415\n",
      "Epoch 44/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5827\n",
      "Epoch 45/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5309\n",
      "Epoch 46/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5195\n",
      "Epoch 47/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5269\n",
      "Epoch 48/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4830\n",
      "Epoch 49/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5516\n",
      "Epoch 50/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5170\n",
      "Epoch 51/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5023\n",
      "Epoch 52/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5341\n",
      "Epoch 53/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5880\n",
      "Epoch 54/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5322\n",
      "Epoch 55/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5163\n",
      "Epoch 56/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5391\n",
      "Epoch 57/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5048\n",
      "Epoch 58/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5149\n",
      "Epoch 59/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5569\n",
      "Epoch 60/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5466\n",
      "Epoch 61/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5074\n",
      "Epoch 62/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5155\n",
      "Epoch 63/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5614\n",
      "Epoch 64/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5831\n",
      "Epoch 65/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5295\n",
      "Epoch 66/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5598\n",
      "Epoch 67/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4873\n",
      "Epoch 68/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5974\n",
      "Epoch 69/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5717\n",
      "Epoch 70/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5475\n",
      "Epoch 71/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.4979\n",
      "Epoch 72/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.6040\n",
      "Epoch 73/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5697\n",
      "Epoch 74/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5151\n",
      "Epoch 75/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5767\n",
      "Epoch 76/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.4632\n",
      "Epoch 77/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.4944\n",
      "Epoch 78/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5241\n",
      "Epoch 79/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5679\n",
      "Epoch 80/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5560\n",
      "Epoch 81/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6022\n",
      "Epoch 82/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5540\n",
      "Epoch 83/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5047\n",
      "Epoch 84/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5289\n",
      "Epoch 85/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5241\n",
      "Epoch 86/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5053\n",
      "Epoch 87/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.4995\n",
      "Epoch 88/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5577\n",
      "Epoch 89/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.4725\n",
      "Epoch 90/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5539\n",
      "Epoch 91/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5052\n",
      "Epoch 92/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5140\n",
      "Epoch 93/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.4445\n",
      "Epoch 94/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.4749\n",
      "Epoch 95/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5038\n",
      "Epoch 96/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.4687\n",
      "Epoch 97/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5382\n",
      "Epoch 98/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4913\n",
      "Epoch 99/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5333\n",
      "Epoch 100/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4862\n",
      "Epoch 101/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.4731\n",
      "Epoch 102/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5042\n",
      "Epoch 103/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5367\n",
      "Epoch 104/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5075\n",
      "Epoch 105/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5246\n",
      "Epoch 106/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.4602\n",
      "Epoch 107/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5033\n",
      "Epoch 108/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5586\n",
      "Epoch 109/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5669\n",
      "Epoch 110/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5716\n",
      "Epoch 111/120\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6916 - accuracy: 0.5291\n",
      "Epoch 112/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5735\n",
      "Epoch 113/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.4596\n",
      "Epoch 114/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.4603\n",
      "Epoch 115/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5235\n",
      "Epoch 116/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5149\n",
      "Epoch 117/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5669\n",
      "Epoch 118/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6575\n",
      "Epoch 119/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5145\n",
      "Epoch 120/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5371\n",
      "Epoch 2/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5459\n",
      "Epoch 3/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5267\n",
      "Epoch 4/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4563\n",
      "Epoch 5/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5934\n",
      "Epoch 6/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.4844\n",
      "Epoch 7/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5891\n",
      "Epoch 8/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.6843\n",
      "Epoch 9/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.6424\n",
      "Epoch 10/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6825\n",
      "Epoch 11/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6972\n",
      "Epoch 12/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7533\n",
      "Epoch 13/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.8162\n",
      "Epoch 14/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7942\n",
      "Epoch 15/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7232\n",
      "Epoch 16/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8104\n",
      "Epoch 17/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7745\n",
      "Epoch 18/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7752\n",
      "Epoch 19/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7463\n",
      "Epoch 20/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8181\n",
      "Epoch 21/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8006\n",
      "Epoch 22/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7865\n",
      "Epoch 23/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8175\n",
      "Epoch 24/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8289\n",
      "Epoch 25/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7728\n",
      "Epoch 26/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7584\n",
      "Epoch 27/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8218\n",
      "Epoch 28/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8430\n",
      "Epoch 29/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8578\n",
      "Epoch 30/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8593\n",
      "Epoch 31/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8590\n",
      "Epoch 32/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8161\n",
      "Epoch 33/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7807\n",
      "Epoch 34/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8370\n",
      "Epoch 35/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8249\n",
      "Epoch 36/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8222\n",
      "Epoch 37/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8000\n",
      "Epoch 38/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8788\n",
      "Epoch 39/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8774\n",
      "Epoch 40/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8659\n",
      "Epoch 41/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7860\n",
      "Epoch 42/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8127\n",
      "Epoch 43/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8061\n",
      "Epoch 44/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8531\n",
      "Epoch 45/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8611\n",
      "Epoch 46/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8209\n",
      "Epoch 47/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8651\n",
      "Epoch 48/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8419\n",
      "Epoch 49/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8534\n",
      "Epoch 50/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8987\n",
      "Epoch 51/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8249\n",
      "Epoch 52/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9259\n",
      "Epoch 53/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8003\n",
      "Epoch 54/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8648\n",
      "Epoch 55/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8832\n",
      "Epoch 56/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8133\n",
      "Epoch 57/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8374\n",
      "Epoch 58/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8350\n",
      "Epoch 59/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8030\n",
      "Epoch 60/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8712\n",
      "Epoch 61/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8734\n",
      "Epoch 62/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8002\n",
      "Epoch 63/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8301\n",
      "Epoch 64/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8698\n",
      "Epoch 65/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8340\n",
      "Epoch 66/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8367\n",
      "Epoch 67/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8161\n",
      "Epoch 68/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8498\n",
      "Epoch 69/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.9017\n",
      "Epoch 70/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8122\n",
      "Epoch 71/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8586\n",
      "Epoch 72/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8560\n",
      "Epoch 73/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8575\n",
      "Epoch 74/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8644\n",
      "Epoch 75/120\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.8183: 0s - loss: 0.3569 - accuracy: \n",
      "Epoch 76/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9155\n",
      "Epoch 77/120\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3603 - accuracy: 0.8623\n",
      "Epoch 78/120\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4583 - accuracy: 0.7936\n",
      "Epoch 79/120\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2632 - accuracy: 0.9035\n",
      "Epoch 80/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8716\n",
      "Epoch 81/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8458\n",
      "Epoch 82/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8390\n",
      "Epoch 83/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.9033: 0s - loss: 0.1469 - accura\n",
      "Epoch 84/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8477\n",
      "Epoch 85/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8785\n",
      "Epoch 86/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8243\n",
      "Epoch 87/120\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8333\n",
      "Epoch 88/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8183\n",
      "Epoch 89/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7997\n",
      "Epoch 90/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8707\n",
      "Epoch 91/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2654 - accuracy: 0.8824\n",
      "Epoch 92/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8888\n",
      "Epoch 93/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8515\n",
      "Epoch 94/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.8535\n",
      "Epoch 95/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8758\n",
      "Epoch 96/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8446\n",
      "Epoch 97/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8767\n",
      "Epoch 98/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8529\n",
      "Epoch 99/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8985\n",
      "Epoch 100/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8594\n",
      "Epoch 101/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8877\n",
      "Epoch 102/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.8980\n",
      "Epoch 103/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9174\n",
      "Epoch 104/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9268\n",
      "Epoch 105/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8772\n",
      "Epoch 106/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8398\n",
      "Epoch 107/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8763\n",
      "Epoch 108/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8705\n",
      "Epoch 109/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7666\n",
      "Epoch 110/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8793\n",
      "Epoch 111/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.9050\n",
      "Epoch 112/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8559\n",
      "Epoch 113/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8967\n",
      "Epoch 114/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.8023 ETA: 0s - loss: 0.7668 - accuracy: \n",
      "Epoch 115/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.8938\n",
      "Epoch 116/120\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9140\n",
      "Epoch 117/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.9025\n",
      "Epoch 118/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8891\n",
      "Epoch 119/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8128\n",
      "Epoch 120/120\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.6050\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5603\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6916 - accuracy: 0.5677\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.5726\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5649\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5173\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.6221\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6737 - accuracy: 0.5671\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.5323\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.5945\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.5480\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6136\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.6336\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.7330\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.7161\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7233\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7870\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8050\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8059\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8202\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8014\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8459\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8156\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8072\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8361\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8522\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8240\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8359\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8543\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7701\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8567\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8228\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8263\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8691\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.7919\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8523\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.7930\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7795\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8732\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8129\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7941\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8155\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8349\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7932\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8265\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8377\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8253\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8330\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7724\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7592\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8452\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7530\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8715\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7867\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8260\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8870\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8209\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8327\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8494\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8565\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8153\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8666\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8272\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8899\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.7993\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8797\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7907\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.7876\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8343\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8178\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8561\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7939\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.7681\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8478\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8425\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8857\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7421\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8085\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8891\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8404\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8749\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8479\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8556\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.8743\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8604\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8487\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8493\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8496\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.8701\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8381\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8598\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8114\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8494\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8393\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.8538\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.8590\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8814\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.6009\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5207\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5650\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5480\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5400\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.4963\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5911\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5560\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5364\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.5623\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.5290\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.5973\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.5896\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.7040\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.6748\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6725\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.6984\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7756\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.8268\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7744\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7931\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7982\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8296\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7965\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7849\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8375\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8443\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.8400\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8424\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.8498\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7369\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.8132\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8520\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8251\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8518\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8685\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8096\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8581\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8437\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7898\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.9204\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8095\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8080\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8666\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8454\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8332\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8324\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8465\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8441\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8756\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8155\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7767\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8705\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8117\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.9185\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8187\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8146\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8766\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8679\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8920\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8973\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8335\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8668\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.9043\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8156\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.9348\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8655\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8864\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.7818\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8216\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8573\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.9047\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8357\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8319\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8796\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8878\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8903\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8067\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8520\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8804\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3381 - accuracy: 0.8656\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.9196\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8934\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8722\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.9202\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8360\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8867\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.9133\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8702\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.9013\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8795\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.9210\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8748\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.8957\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8930\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.9267\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.9003\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.8628\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5047\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4854\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5600\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5746\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5126\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5062\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5845\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5327\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5306\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5444\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5237\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.5957\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.5727\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6837\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.6585\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7121\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.8329\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7538\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.8031\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8470\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.8443\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8359\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8481\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8705\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8241\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8594\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8582\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7890\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8282\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7927\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7755\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7828\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8531\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8130\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8247\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8443\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8080\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8465\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8270\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8067\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8947\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7761\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.7987\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8124\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8190\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8291\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.7789\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8105\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8076\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8122\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8019\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7706\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8308\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7655\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.8924\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7970\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8104\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8259\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.7813\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 0.8257\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8334\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8264\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8176\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8424\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8192\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.9151\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8339\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8661\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7905\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8120\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8347\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8312\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7654\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8114\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8080\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8335\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8413\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7516\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8227\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8742\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8171\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8238\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8347\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8406\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8727\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8626\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8743\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8362\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8212\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8374\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8052\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8468\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8688\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8247\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8331\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8473\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8227\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.4812\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.4918: 0s - loss: 0.6934 - accuracy: 0.46\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5337\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5817\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.4988\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.4945\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.5850\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.5452\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5724\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.5791\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.5539\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6130\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6793\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6863\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6943\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7396\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.8325\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7914\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.8318\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8171\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8158\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8316\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8367\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8556\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.7989\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8765\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8525\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7666\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8458\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8211\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7486\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7763\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8479\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8129\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8509\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8447\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8465\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8607\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8373\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8120\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8937\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8114\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8197\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8221\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8441\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8507\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8419\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8189\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8387\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8427\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8325\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7162\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8534\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8022\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.9046\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8119\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8456\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8758\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8434\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8389\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8445\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8770\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8479\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8756\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8687\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.9334\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8669\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8829\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8146\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8404\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8499\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8088\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8453\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.7745\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8765\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8548\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8604\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3068 - accuracy: 0.8828\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8078\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8415\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8926\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8432\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8616\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8820\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8611\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8918\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8747\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8614\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8864\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8592\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8483\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8583\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8421\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.9107\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.9090\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8430\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8808\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8605\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8502\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5096\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4699\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5242\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5840\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5194\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5685\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.6008\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.5733\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5572\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.5654\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.5503\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.5764\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.5496\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.5391\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.5524\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.5848\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7396\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7247\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7645\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7772\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.6548\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7315\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7514\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7329\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7362\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.8385\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7862\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8701\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7592\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7138\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7785\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8216\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8562\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8151\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8348\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8183\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8451\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8635\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7809\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8908\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7895\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8121\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.8283\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.8628\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.8291\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8322\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8438\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8435\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8493\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.8094\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7388\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8191\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7674\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8963\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8132\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8071\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8592\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8334\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8463\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8343\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8358\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8235\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8590\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8349\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.9337\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8549\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8657\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8356\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8289\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8325\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8587\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8566\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8046\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.7983\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8424\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8612\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8818\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8124\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8405\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8928\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7839\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8679\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8845\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8135\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8973\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8319\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8776\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8487\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8438\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8790\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8387\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8237\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8675\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8899\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8495\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8536\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8659\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8793\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5128\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4755\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5226\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5981\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5269\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5654\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.5753\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.5775\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5366\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.5733\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.5458\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.5926\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6869\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6712\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7031\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7457\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7559\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.8078\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8295\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8052\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7655\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7978\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8294\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7756\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7758\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8378\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8199\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.8050\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.8685\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8316\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8109\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.8322\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8688\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8820\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8546\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.9098\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8744\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8547\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8773\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7886\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8580\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8172\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8453\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8696\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8531\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8638\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8564\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8562\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8588\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8738\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8670\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8156\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8725\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8648\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.92 - 0s 3ms/step - loss: 0.3356 - accuracy: 0.9076\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.8330\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8564\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8768\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8633\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8852\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8566\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.9148\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8616\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.9331\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8489\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9372\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.9334\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8890\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.9123\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8603\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8645\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8692\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8949\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8959\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8648\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8588\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8538\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.9478\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8869\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.9299\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8858\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8465\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.9012\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8912\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.9187\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.9100\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.9136\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.9386\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.9255\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8945\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.9042\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.9174\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8815\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.9376\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.9272\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.9255\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.9003\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.9146\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.9015\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.9370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5170\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5730\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5600\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4702\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5823\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5007\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7022\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.6294\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.6431\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6367\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.7167\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.7230\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7366\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.8406\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.8122\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.8411\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7357\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.8411\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.8158\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.8169\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.8398\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7975\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8351\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.8072\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7799\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7972\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7959\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.8459\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8857\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8567\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8083\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8437\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8205\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8998\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8965\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8839\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8898\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8775\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8605\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8959\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8759\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8352\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8988\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8560\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8915\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8915\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.9129\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8847\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8890\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8981\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.9517\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.9236\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.9019\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8904\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8874\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.9043\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.9298\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.9291\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.9154\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.9206\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8480\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.9041\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.9305\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.9035\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.9308\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.9157\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.9016\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9263\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.9397\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.9387\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.9181\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8893\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.9524\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.9550\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9544\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.9441\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2632 - accuracy: 0.9577\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9519\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9536\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.9277\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9617\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9277\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9241\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2548 - accuracy: 0.9232\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9514\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.9289\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9263\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.9320\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9339\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9644\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9513\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9422\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9647\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9720\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9741\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9413\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.9275\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9739\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4752\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5473\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5373\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.4752\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5697\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5052\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5621\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.6543\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.6640\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6314 - accuracy: 0.6636\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7642\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.8488\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7287\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7805\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8518\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8183\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8341\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8241\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8623\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8424\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8449\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8564\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8321\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8389\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8135\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8629\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8589\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8811\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8457\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8422\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.9038\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8255\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8679\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.9047\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.9000\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8871\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8792\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8951\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9025\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8552\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7902\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8700\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8772\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8753\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8779\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9040\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8394\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8692\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8983\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8792\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.9142\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8526\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8892\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3030 - accuracy: 0.8895\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8351\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8486\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8613\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8818\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8488\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8342\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8326\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8846\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8477\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8550\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8745\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8243\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8070\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.9027\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8520\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8726\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8509\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8205\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8623\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8758\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9317\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8895\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.8746\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8831\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8910\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8598\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2950 - accuracy: 0.8479\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.9011\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8063\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8607\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8639\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8795\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8655\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8443\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8794\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.90 - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9002\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2332 - accuracy: 0.9078\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.9031\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.9071\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9335\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8802\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.8961\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8559\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.8977\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5621\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4872\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5301\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4583\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5794\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5152\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.7271\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5579\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6124\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6902\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.7782\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.6518\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7154\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.8019\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7761\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.8141\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7811\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.8038\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7714\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8478\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.8490\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.8115\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8414\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8293\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.8233\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7659\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8188\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8444\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8625\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8434\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8669\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8903\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8145\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8816\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8897\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8982\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8530\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.9174\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8717\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.9280\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8408\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8561\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8707\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8825\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8976\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8911\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.9169\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8754\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8928\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.9406\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8835\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.9456\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.9223\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.9156\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.9140\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.9101\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8814\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.9150\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.9036\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.9062\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8781\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8747\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8881\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8582\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8907\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.9169\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8719\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8624\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8998\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8609\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8900\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.9062\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8558\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.9003\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8785\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.9401\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8975\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8825\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.9087\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.9149\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.9305\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9323\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.9371\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4048 - accuracy: 0.8239\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8991\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8848\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8977\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.9031\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8685\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.9066\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9128\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.9205\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8928\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9363\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.9271\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8800\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9254\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8498\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.9119\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5511\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4553\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5266\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4623\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5924\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4961\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5722\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.6988\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.6471\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.6906\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.7675\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.6023\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6543\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6800\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7981\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7216\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7193\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7810\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.7216\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.8282\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7455\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7996\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7836\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7890\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.8035\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7991\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8330\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.8047\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.8402\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8481\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.8419\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8381\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7873\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8492\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7873\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8763\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8427\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.8878\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8680\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8244\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8179\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8450\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8790\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8645\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8721\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8546\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8016\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8433\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8735\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8768\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.9307\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8535\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8831\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8929\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8317\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8807\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8557\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8299\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8445\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8502\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8708\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8790\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8534\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8598\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8682\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8569\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8741\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.9049\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8377\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8598\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8891\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8382\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8811\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8620\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.9015\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8763\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8670\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8709\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8888\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.9082\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8911\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.9036\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8121\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8700\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8606\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8863\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8737\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8300\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8825\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8630\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.9024\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8759\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.9058\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.9124\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8590\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8932\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8339\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8783\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5530\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5603\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5677\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5726\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5649\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5173\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6221\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5671\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5323\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5945\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5480\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.6136\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.6259\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.5910\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5287\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.5997\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.5270\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6830\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6350 - accuracy: 0.6019\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.5562\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.5352\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.5955\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.5960\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.5338\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.6283\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6486\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.6976\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6433\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7001\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.6696\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6682\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6910\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7814\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7416\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7273\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8212\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7899\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8316\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7702\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7450\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8351\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.8182\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7738\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8056\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8262\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8218\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8237\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8419\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8109\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8559\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.8303\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7453\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8440\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7932\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8828\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7748\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8369\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8800\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7796\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8061\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8365\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8432\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8498\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8228\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8474\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.9114\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8250\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8592\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7896\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7860\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8174\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8397\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8326\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7430\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8377\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8271\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8425\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8720\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7493\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8203\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8878\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8202\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8848\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8379\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8341\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8773\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8129\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8643\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8536\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8574\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8264\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8204\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8235\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8641\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8192\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8297\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8434\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8557\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.7984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.5229\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5207\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5650\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5480\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5400\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4963\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5911\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5560\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5364\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.5623\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5290\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.6082\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.6401\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.7150\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.7148\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.7927\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.7685\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.8240\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6893\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.7867\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.8190\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.8548\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.8250\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7494\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.8321\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7707\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.8204\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5512 - accuracy: 0.8042\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8709\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8392\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7585\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7781\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8438\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7982\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.8088\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8490\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8246\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8419\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8076\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7934\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8363\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7726\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7871\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8328\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7904\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.8267\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8180\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8356\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8402\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8319\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8233\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7642\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8401\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8146\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8570\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7820\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8505\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8434\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.7732\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8503\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8435\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8408\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8173\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8383\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8780\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8472\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.8549\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7885\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8008\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8330\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8138\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8344\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.7907\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8257\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8551\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8806\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8627\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7605\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8184\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8873\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8332\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8479\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8496: 0s - loss: 0.2964 - accuracy: 0.85\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8648\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8944\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8049\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8419\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8898\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8363\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8760\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8218\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8782\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8517\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8657\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8388\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8574\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8669\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8030\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5827\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4854\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5600\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5746\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5126\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5062\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5845\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5327\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.5306\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.5444\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.5237\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.5957\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.5721\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.5579\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6169\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6750\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6743\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7382\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7331\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7561\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.6818\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7399\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7316\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.71 - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7298\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7526\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8027\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8335\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7325\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.8195\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.8385\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7543\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7698\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8389\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.8060\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8097\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8504\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7889\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8277\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8240\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7811\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8517\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.8036\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7940\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8023\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8032\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8418\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8142\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8413\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8647\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8309\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.8355\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7820\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8356\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8086\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8482\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8475\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8422\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8768\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8188\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8465\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8465\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8068\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8391\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8647\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8282\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.9201\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8726\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8729\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8282\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8744\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7988\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8751\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8695\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8253\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8337\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8699\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8547\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8865\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8572\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8824\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8661\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8327\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3275 - accuracy: 0.8758\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8472\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8848\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8696\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8545\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8699\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8672\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8528\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8806\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8907\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8287\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8782\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8891\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8860\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8937\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.9078\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8402\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.9010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.4812\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4918\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5337\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6915 - accuracy: 0.5817\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4988\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.4945\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5850\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5452\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5724\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5791\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5539\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.5904\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.5725\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.5827\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.5940\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6556\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6762\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.7042\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.7004\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6930\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6190\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6972\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.6661\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7168\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7433\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7580\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.8131\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7478\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8579\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8226\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7179\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8439\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.8356\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8590\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8249\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7962\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8226\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8258\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8065\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8380\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7686\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8068\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.7922\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8057\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8173\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8248\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8159\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.7996\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8349\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8291\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8236\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7999\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8888\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8026\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8519\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8901\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8020\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8216\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8497\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8506\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8543\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.7965\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8888\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.9285\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8444\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8564\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7884\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8059\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8484\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8028\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8425\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7648\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8315\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8310\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8213\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8814\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7853\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8118\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8811\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8412\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8419\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8639\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8364\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8909\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8499\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8817\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8707\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8537\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8568\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8276\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8258\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8511\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.9043\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8325\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8668\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8395\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8291\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4270\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4699\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5242\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.5840\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5194\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5685\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.6008\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5733\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5572\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5654\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5503\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.5764\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.5496\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.5391\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5524\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.5755\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.5771\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.5855\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.5685\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.5483\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.5565\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.6330\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6731\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6114\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.6793\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6512\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7168\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6506\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7114\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6383\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6705\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7266\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7312\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7974\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7442\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.8035\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7902\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.8059\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7428\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.76 - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7648\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8185\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7911\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7869\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8143\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8462\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.8596\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8118\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8361\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8323\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.8068\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.8109\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7582\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8481\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7840\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8783\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.8133\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8459\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.8519\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8195\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8366\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8414\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8327\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8126\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8413\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8411\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8986\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8327\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8561\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.8189\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8009\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8228\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8366\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8177\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7625\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8473\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8444\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8248\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.8752\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7813\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8430\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8887\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7883\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8701\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8568\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7899\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8597\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8074\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8435\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8627\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8368\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8169\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8621\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7803\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8524\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8467\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8297\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8599\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8460\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8555\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4758\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4755\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5226\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6917 - accuracy: 0.5981\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5269\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5654\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.5753\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6908 - accuracy: 0.5775\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5366\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5733\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5458\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5634\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.5365\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5389\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5603\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5600\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5874\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5531\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5903\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5505\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5353\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5030\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5917\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4770\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5657\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5250\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5832\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6925 - accuracy: 0.5198\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.45 - 0s 3ms/step - loss: 0.6956 - accuracy: 0.4851\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.4490\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5176\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5705\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5841\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5077\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5336\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5808\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5576\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4990\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4715\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5205\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5790\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5181\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5243\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5703\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5813\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.4668\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5434\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5420\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5289\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.5059\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.4681\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.4706\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5658\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.4811\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5403\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5235\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5754\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5668\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5760\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5157\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5413\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5520\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5899\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.4879\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.6346\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5421\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5393\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.4877\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5244\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.5095\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5243\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5543\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5721\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5041\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5365\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.6141\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.5808\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.4846\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5371\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5274\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.6081\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5587\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5774\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5718\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5109\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.6222\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5056\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.5772\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5726\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.4902\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5362\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5100\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5433\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5135\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4941\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5660\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5492\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5755\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4961\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.4895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4227\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5730\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5600\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4702\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5823\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5007\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5644\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4860\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5024\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5029\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5231\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5737\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5328\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4873\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4907\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5699\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5006\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4885\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5843\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5260\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5626\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5547\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5117\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5288\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.5453\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5446\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5026\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5261\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.5805\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5349\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5115\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5114\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.5040\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.5580\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.6027\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5011\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5108\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6020\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5592\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5242\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5287\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5368\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5856\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5910\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5144\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5296\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5127\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5252\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5388\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5230\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.4744\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.4963\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5903\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5227\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5204\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5564\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5720\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5129\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5653\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5564\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4906\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5055\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5556\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5783\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5144\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5604\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5134\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5959\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5724\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.6061\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5494\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5071\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5977\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5872\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6954 - accuracy: 0.4984\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.4657\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5615\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5510\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5562\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5374\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5866\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5226\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.60 - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5577\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5454\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.5379\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.4819\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5117\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5205\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5359\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5352\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5016\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6997 - accuracy: 0.4655\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4896\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5395\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.4740\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5599\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5198\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5448\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.4466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 1ms/step - loss: 0.6933 - accuracy: 0.5616\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5473\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5373\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4752\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5697\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5052\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5621\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5046\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.4967\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5412\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.6398\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.6929\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.6920\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.6409\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.5824\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.7401\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.7382\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6907\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7098\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.8026\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7726\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7775\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.8140\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7859\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8392\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8041\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8309\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8297\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8210\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8612\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8100\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8494\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8147\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8508\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8625\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8724\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8527\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8598\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8913\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8860\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8533\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8106\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8771\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8880\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8867\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8737\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8833\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8517\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8096\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8969\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8764\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.9202\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8517\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8892\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8895\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8492\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8397\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8575\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8630\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8586\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8292\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8149\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8812\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8397\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8494\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8813\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8209\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8137\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.9052\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8448\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8808\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8575\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8481\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8404\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8612\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.9079\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8754\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8795\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8780\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8746\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8467\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8612\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8715\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8124\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8445\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8562\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8646\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8428\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.8309\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8654\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8846\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.9074\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8588\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.9002\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9067\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8773\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.9154\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8198\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8642\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4386 \n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5400\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5301\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4583\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5794\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4927\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.5793\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5086\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4812\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4709\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5549\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5922\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5487\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4785\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5085\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5583\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5206\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4800\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5734\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5237\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5605\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5468\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5379\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5433\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5591\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5448\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5335\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5355\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5457\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5117\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5391\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5363\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.4637\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5864\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5986\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5149\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4998\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5617\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5452\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5268\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5252\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5452\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5345\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5837\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5430\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5306\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.5331\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4876\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5426\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5214\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4974\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5397\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5844\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5237\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5129\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5439\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5138\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5187\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5523\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5423\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5097\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5172\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5632\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6864 - accuracy: 0.5834\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5374\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5482\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.4862\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5870\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5682\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5504\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5091\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5965\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5814\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5167\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5704\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4759\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4938\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5372\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5659\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5527\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.5908\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5470\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5177\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5264\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5290\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.4999\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.4928\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5555\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.4811\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5456\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5045\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5115\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.4533\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.4743\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5073\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5380\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.4970\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5283\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.4874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4655\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4741\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5266\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4623\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5924\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4961\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5722\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4915\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4691\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4600\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5517\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5910\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5199\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4816\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5109\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5452\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5222\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.4553\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5388\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5219\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5552\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5406\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5308\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5334\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5557\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5182\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5223\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5155\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5311\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5083\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5457\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5238\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.4697\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5835\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.6080\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5015\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4897\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5593\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5448\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5214\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.5109\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5446\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5287\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5495\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5299\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5288\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5014\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4931\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5578\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5353\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.4828\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5619\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5599\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5440\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5019\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5413\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5267\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5186\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5458\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5536\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5118\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5109\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5669\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5905\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5466\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5050\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.4852\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5720\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5664\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5358\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5174\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5903\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5787\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4864\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5558\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4636\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4865\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5294\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.5673\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5274\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5834\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5350\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5471\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5226\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5128\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.4839\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.4963\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5468\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4797\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5577\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4705\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5081\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.4926\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.4895\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5226\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4713\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5116\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4992\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5225\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.5270\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5603\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5677\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5726\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5649\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5173\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6221\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.5671\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.5323\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.5945\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.5480\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6136\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.6259\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.5910\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.5287\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.6628\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7495\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7721\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.8244\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7999\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.8068\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7713\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7906\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7079\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7759\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8336\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8302\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7678\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8346\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8072\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7628\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7473\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8521\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8499\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8219\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8705\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8005\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8550\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8111\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7744\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8186\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8321\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8034\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8161\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8134\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.8171\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7996\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8269\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8103\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8325\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7661\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7288\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8629\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7657\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8719\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7890\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7851\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8846\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8336\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8262\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8142\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8639\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8294\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8539\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8123\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8816\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8538\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8417\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8012\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7779\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8209\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8377\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8417\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8278\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7820\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8509\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8458\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8791\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7651\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8464\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8783\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8370\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8929\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8718\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8384\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8764\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8442\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8651\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8909\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8526\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8775\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8237\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8696\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8092\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8793\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8687\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8736\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8963\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8965\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8253\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8920\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8015\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8321\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.9185\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8582\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8368\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8684\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.9081\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8914\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8880\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8056\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8238\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8465\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8589\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8927\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8434\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8520\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8723\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.9040\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5489\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.5207\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5650\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5480\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5400\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.4963\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5911\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5560\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5364\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.5623\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5290\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.5973\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.5853\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.5816\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.5083\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6725\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7039\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7664\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.8014\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8434\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8397\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8584\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8520\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8251\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8489\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8349\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8662\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8163\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8545\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8167\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7903\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8049\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8719\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8003\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8329\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8601\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8009\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8500\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8357\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.7806\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.9067\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8137\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8219\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8474\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8349\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8261\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8083\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8182\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8174\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8549\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8309\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7447\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8734\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8133\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.9069\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8040\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8185\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8402\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8156\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8518\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8648\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8445\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8265\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8599\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8266\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8901\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8194\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8795\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8187\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.7893\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8568\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8351\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3250 - accuracy: 0.8445\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.7994\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8176\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8568\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8815\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8739\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7861\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8483\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8858\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8581\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.8827\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8653\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3299 - accuracy: 0.8621\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.9154\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8613\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8646\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.8847\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8372\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.9002\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8325\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8567\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8654\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.8712\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8665\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8820\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8903\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8769\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8422\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8966\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8388\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3195 - accuracy: 0.8830\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9148\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8937\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8727\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8737\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9058\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8811\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9057\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8600\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8491\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2920 - accuracy: 0.8541\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8421\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8830\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.9006\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8690\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2304 - accuracy: 0.9054\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9121\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5047\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4854\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5600\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5746\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5126\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5062\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.5845\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.5327\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5306\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.5444\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5237\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6044\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6629\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6902\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6946\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7713\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8180\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8154\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8222\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8599\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8675\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8126\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8617\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8542\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8403\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8469\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8732\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7860\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8322\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.7829\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7647\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7814\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3241 - accuracy: 0.8673\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8054\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8486\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8555\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8139\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8411\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8232\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.7849\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.9084\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7866\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8119\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8023\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8190\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8291\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8099\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8091\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8111\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8150\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7870\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7392\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8308\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7605\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8776\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7992\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8366\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8464\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.7782\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8229\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8417\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8267\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8169\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8555\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8333\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.9320\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8373\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8706\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7965\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8052\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8215\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8627\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8239\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7688\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.7947\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8182\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8325\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8789\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7311\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8223\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8777\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8178\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8489\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8527\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8239\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8789\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8708\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8771\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8234\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8325\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8676\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8239\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8070\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8601\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8708\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8383\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8510\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8557\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8761\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7830\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8178\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8259\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8389\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.8723\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8793\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3195 - accuracy: 0.8425\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8360\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8662\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8301\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8838\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8101\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8476\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8042\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8293\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8683\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8430\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8513\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8893\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8929\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.4812\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4918\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5337\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.5817\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.4988\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.4945\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5850\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5452\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5724\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.5791\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.5539\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.5904\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.5719\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.5577\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6315\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.7013\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7055\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.7253\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7429\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7679\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7639\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8075\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8172\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8556\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8044\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8757\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8621\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7777\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8342\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7951\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7486\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7812\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8692\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8162\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8360\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8447\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8479\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8522\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8331\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8120\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8937\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8078\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8274\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8221\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8611\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8482\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8433\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8548\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8394\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8427\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8482\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7357\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8503\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8022\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.9084\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8119\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8501\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8758\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8434\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8420\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8445\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8770\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8377\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8756\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8687\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9334\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8669\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8996\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8146\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8263\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8594\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8088\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8453\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.7699\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8553\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8537\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8604\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8846\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8078\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8415\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8926\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8355\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.8616\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8714\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8611\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8951\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8716\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8614\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.8904\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8592\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8483\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8709\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8499\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.9107\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.9171\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8430\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8887\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8676\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8580\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8606\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8234\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8835\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8739\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2731 - accuracy: 0.8904\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.9079\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8719\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8845\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8970\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8412\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8900\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8523\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8691\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8524\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8536\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.9067\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8842\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.9049\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8882\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.9307\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5096\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4699\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5242\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5840\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5194\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.5685\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6008\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5733\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5572\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.5654\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.5503\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.5813\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6662\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6648\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6727\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7191\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7489\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7698\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7998\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.8533\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8129\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8192\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8443\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.8117\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8524\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8638\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8876\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8106\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8554\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8140\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7374\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8031\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8713\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8541\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8970\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8456\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8648\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8465\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8752\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8410\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8943\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7854\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8669\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8426\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8498\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8555\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8285\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8418\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8267\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8638\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8436\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7521\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8560\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7972\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9127\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8061\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8778\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8464\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8594\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8346\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8297\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8774\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8210\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8409\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8539\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8930\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8471\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8956\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8504\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8224\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8717\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8588\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8607\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.7966\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8352\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8505\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8709\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8497\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8090\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8379\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.9209\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.7732\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8768\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8823\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8326\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8904\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8624\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8913\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8604\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8530\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8630\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8504\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8179\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8750\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.8961\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8452\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8767\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8647\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8670\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8246\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8348\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8727\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8674\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.9001: 0s - loss: 0.2751 - accuracy: 0.90\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8954\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8686\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8807\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.9055\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8039\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.8732\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8462\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8405\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8295\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8198\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8771\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8649\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3060 - accuracy: 0.8666\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8962\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.9053\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4868\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4755\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5226\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5981\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5269\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5654\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5753\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.5775\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.5366\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.6295\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6568\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7046\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7117\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7886\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7633\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.8381\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8805\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8841\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8515\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8444\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8726\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8497\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8598\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8073\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8359\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 0.8780\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8860\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7947\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8739\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8061\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7680\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8425\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8743\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8633\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8889\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.8864\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2887 - accuracy: 0.8719\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.8729\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 0.8683\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8056\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.9072\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8292\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8493\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8565\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8901\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8882\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8609\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8549\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8915\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8531\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8033\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.7929\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.8495\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2949 - accuracy: 0.8943\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9146\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8340\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8655\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8856\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8659\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8605\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8548\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2237 - accuracy: 0.8905: 0s - loss: 0.2012 - accuracy: 0.\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8587\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9359\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.8853\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9305\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.8952\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9001\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9093\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.7929\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8443\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8807\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.8572\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8427\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8571\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8488\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.8798\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.9039\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8753\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8582\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9217\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8606\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9133\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8785\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8954\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.8899\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9126\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.9282\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.9080\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8609\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9087\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8656\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8201\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9313\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9086\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.9193\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9166\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.9027\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8707\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8429\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8532\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8556\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9000\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9278\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9117\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.8904\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9080\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9152\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8647\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.8878\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.8709\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.9228\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.9081\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.8660\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.8980\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9123\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.9010\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.8933\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9424\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4650\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5730\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5600\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4702\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5823\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5007\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5644\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4860\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5029\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5231\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5737\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5328\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4873\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4907\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5699\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5006\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4885\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5843\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5260\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5626\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5547\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5117\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5288\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5453\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5446\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5026\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5261\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5805\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.5349\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5115\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5114\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5040\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5580\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6027\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5011\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5108\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6847 - accuracy: 0.6020\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5592\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5242\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5287\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5368\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5856\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5910\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5144\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5296\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5127\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5252\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5388\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5230\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.4744\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4963\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5903\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5227\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5204\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5564\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5720\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5129\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5653\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5564\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.4906\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5055\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5556\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5783\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5144\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5604\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5134\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5959\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5724\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.6061\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.5494\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5071\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5977\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5872\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4984\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.4657\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5615\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5510\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5562\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5374\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5866\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5226\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5577\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5454\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5379\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.4819\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5117\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5205\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5359\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5352\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5016\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.4655\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.4896\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5395\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.4740\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5599\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5198\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5448\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.4466\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.4907\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4975\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5097\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6956 - accuracy: 0.4972\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5205\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4914\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5391\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5223\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5808\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5781\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5328\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5291\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4882\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4887\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4777\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5345\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5894\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6518\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5266\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5272\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5473\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5373\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4752\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5697\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5052\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5621\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5046\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4882\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5023\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5551\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5942\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5373\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.4751\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5002\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5794\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5236\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4958\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.6074\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5309\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5513\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5534\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5317\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5602\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5687\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5610\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5269\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5266\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5720\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5180\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5274\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5326\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4808\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5848\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6013\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5165\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5116\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5794\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5581\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5155\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5210\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5412\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5516\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5983\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5450\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5288\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5244\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5164\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5397\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5297\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6965 - accuracy: 0.4820\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5131\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5989\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5275\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5188\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5578\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5208\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5188\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5742\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5796\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5061\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5041\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5389\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5867\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5418\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5633\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4917\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5918\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.5819\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5760\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5220\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5481\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6109\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5018\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5826\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4715\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5036\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5880\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5667\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5506\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5854\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.5647\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5190\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5362\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5531\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5222\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.4909\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5341\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.5002\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5656\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5315\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4978\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.4745\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.4790\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5102\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4843\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5479\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5117\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5440\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6989 - accuracy: 0.4715\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.5005\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5153\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5147\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.4955\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5223\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.4556\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5342\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5418\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5954\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5900\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5393\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5397\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5031\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4811\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.4921\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5131\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5872\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.6461\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5283\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5101\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4959\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5301\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4583\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5794\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.4927\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5793\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.6488\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.6456\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.6648\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7005\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.7944\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7870\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7801\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7632\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8255\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8514\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.8288\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8009\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7944\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8262\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8387\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8345\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8025\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7799\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7735\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8387\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8040\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8436\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8235\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8336\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8429\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.7963\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8336\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8757\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8938\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8091\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3105 - accuracy: 0.8818\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3005 - accuracy: 0.8726\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8812\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8273\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8377\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8334\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8878\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.8413\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8438\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8550\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7491\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8450\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8636\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8647\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.9203\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8438\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.9015\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.9109\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8550\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8371\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8751\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8583\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8525\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8800\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8089\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3060 - accuracy: 0.8771\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8181\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8535\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8806\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8260\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.7883\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8799\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3565 - accuracy: 0.8356\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8633\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8619\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8482\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8496\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8550\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.8855\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8560\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8255\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.8622\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8857\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8933\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8318\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.8838\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8728\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2809 - accuracy: 0.8381\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8646\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8389\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8553\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8606\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8900\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.8984\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.9079\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8426\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.8824\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9136\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8607\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8685\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8571\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8872\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9095\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8701\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8731\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9385\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8878\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.8516\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8784\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.8867\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8490\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8565\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8670\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9084\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.8908\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.8905\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8434\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.8416\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.8940\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.8455\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.7861\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8223\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5511\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4553\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5266\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4623\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5924\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5146\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7375\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6274\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.6210\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.7006\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.7641\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6571\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6732\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7730\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7949\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.8081\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7419\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7902\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7213\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.8328\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7454\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.8270\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8421\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5234 - accuracy: 0.8060\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.8085\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.8190\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8304\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8333\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.8593\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8619\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8279\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8545\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8031\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8529\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.8048\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8772\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8635\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8901\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8824\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8956\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8268\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8375\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8494\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8740\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8724\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.8359\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8887\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8054\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8548\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.9018\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8923\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.9349\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8709\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8943\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.9101\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8400\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8874\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8588\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8387\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8420\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8571\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8697\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8784\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8534\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8753\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8558\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8656\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.9142\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8377\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8891\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8443\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8924\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8631\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8891\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8782\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8475\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8906\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8888\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.9082\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8976\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.9047\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.8055\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8700\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8606\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8989\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8635\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8396\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8825\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8808\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.9024\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8759\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.9058\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.9138\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8635\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8932\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8395\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8909\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8906\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8792\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8832\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.9133\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.9149\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8677\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8861\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8898\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.9015\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8281\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8794\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8954\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8793\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9114\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8427\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8936\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9215\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8559\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8911\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8792\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5270\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5603\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5677\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5726\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.5649\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5173\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6221\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5671\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5323\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5945\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5480\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.6136\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.6259\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5910\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5287\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5997\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5270\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.6830\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.6019\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5562\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5352\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5955\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5960\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5338\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.6252\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5432\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.6194\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5302\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5487\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5335\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5453\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5462\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.6146\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5340\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.5013\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.5752\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5793\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4952\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5330\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5586\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.6032\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5442\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5570\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.6141\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5884\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5274\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5179\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6064\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5218\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.5349\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.4536\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.4897\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5633\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5642\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5454\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5355\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5436\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6292\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5531\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5620\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5671\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.6425\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5762\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5343\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6535\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.6072\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5757\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5606\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4858\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5968\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5327\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6015\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5745\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7039 - accuracy: 0.4748\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5644\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5342\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5982\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5507\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5268\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.6669\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.5723\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5590\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5906\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.4941\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5358\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.6219\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.6026\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5339\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5800\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5617\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.5991\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.5084\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5752\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5942\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5295\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5384\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5476\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5658\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5247\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5396\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5564\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.6052\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.5021\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5373\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5895\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5501\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5848\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6090\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5765\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.6135\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.5059\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.5746\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.6072\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5078\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5531\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6036\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5739\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5476\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5965\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5359: 0s - loss: 0.6930 - accuracy: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 2s 3ms/step - loss: 0.6929 - accuracy: 0.6009\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6930 - accuracy: 0.5207\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5650\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5480\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5400\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.4963\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5911\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.5560\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5364\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.5623\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5290\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.5973\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5853\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.5816\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5050\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6585 - accuracy: 0.5584\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.5164\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6714\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.5813\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6072\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.5692\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6561\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6433\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.5964\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5484 - accuracy: 0.72 - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7005\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6186 - accuracy: 0.6473\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7222\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.6831\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7319\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5851 - accuracy: 0.6931\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.6811\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5619 - accuracy: 0.7147\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4827 - accuracy: 0.8015\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5633 - accuracy: 0.7806\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5394 - accuracy: 0.7674\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.4867 - accuracy: 0.8368\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5166 - accuracy: 0.7995: 0s - loss: 0.5155 - accuracy: 0.\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.5036 - accuracy: 0.8443\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5012 - accuracy: 0.8438\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5131 - accuracy: 0.7508\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.8359\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5216 - accuracy: 0.7883\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.8094\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.4381 - accuracy: 0.8364\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7905\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.8466\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4410 - accuracy: 0.8150\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.8533\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4200 - accuracy: 0.8269\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.8187\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.8468\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5029 - accuracy: 0.7511\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4273 - accuracy: 0.8384\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.7982\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8691\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7998\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.8317\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8261\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8021\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8270\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8792\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3781 - accuracy: 0.8006\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3449 - accuracy: 0.8623\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8084\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8187\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.2968 - accuracy: 0.8968\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8061\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3425 - accuracy: 0.8376\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8019\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3940 - accuracy: 0.8052\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8267\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8177\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3640 - accuracy: 0.8490\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.7930\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8353\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8391\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3270 - accuracy: 0.8827\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3439 - accuracy: 0.8856\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7630\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8376\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.9023\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3661 - accuracy: 0.8061\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.3015 - accuracy: 0.8827\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.8866\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8455\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2865 - accuracy: 0.8952\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8343\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8711\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8992\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8292\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2939 - accuracy: 0.8718\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8403\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3470 - accuracy: 0.8831\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8573\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2984 - accuracy: 0.8797\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8605\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3054 - accuracy: 0.8927\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.8807\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8415\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8387\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8998\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8314\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8569\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9056\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8955\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.8877\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8737\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9062\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8442\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8886\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8624\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8632\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8737\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8264\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8779\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8883\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8457\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9058\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9061\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2759 - accuracy: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 3s 3ms/step - loss: 0.6930 - accuracy: 0.5567\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4854\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5600\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6910 - accuracy: 0.5746\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5126\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.5062\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5845\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5327\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5306\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.5444\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5237\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.5957\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.5721\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.5538\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.5449\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.5829\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6286\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6891\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6749\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.6866\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6405\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6933\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.6816\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6446\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7391\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7347\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7540\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6996\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.8289\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.8017\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7088\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7432\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8271\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.8308\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8570\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.8539\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7921\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8209\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8307\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8247\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8515\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7683\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7848\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8173\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.76 - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7775\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.8217\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8057\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.8619\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8669\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4342 - accuracy: 0.8226\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.8199\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7509\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8242\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7877\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8833\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.8525\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.8417\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8649\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7997\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8221\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8499\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8177\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8276\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3973 - accuracy: 0.8635\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8304\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.9266\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8737\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8585\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4373 - accuracy: 0.8375\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3696 - accuracy: 0.8548\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4132 - accuracy: 0.8122\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8507\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8213\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.7978\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8604\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8680\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8094\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.9062\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8397\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8498\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8493\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4000 - accuracy: 0.8413\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8870\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8730\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8690\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3301 - accuracy: 0.8875\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8545\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8516\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8607\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8480\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8806\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8624\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8397\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8824\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.8732\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8915\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8862\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8879\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8464\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8748\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8598\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8369\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8576\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8788\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3587 - accuracy: 0.8551\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8988\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8530\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8742\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3807 - accuracy: 0.8628: 0s - loss: 0.3721 - accuracy: \n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8650\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.8188\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4116 - accuracy: 0.8536\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8497\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3974 - accuracy: 0.8257\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8558\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8561\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3145 - accuracy: 0.8847\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.9015\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2870 - accuracy: 0.9117\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3254 - accuracy: 0.8795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 3s 6ms/step - loss: 0.6931 - accuracy: 0.5591\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.4918\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6927 - accuracy: 0.5337\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6916 - accuracy: 0.5817\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4945\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6895 - accuracy: 0.5850\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.5452\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5724\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5791\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5539\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6744 - accuracy: 0.6111\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6740 - accuracy: 0.6073\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6655 - accuracy: 0.6699\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.6550\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6421 - accuracy: 0.6994\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.7083\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6193 - accuracy: 0.7160\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6174 - accuracy: 0.7291\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6150 - accuracy: 0.6944\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.6419\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5774 - accuracy: 0.7156\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.6793\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5677 - accuracy: 0.7748\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.7397\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7820\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7671\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7570\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.8544\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.8334\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5445 - accuracy: 0.7216\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5154 - accuracy: 0.7492\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4221 - accuracy: 0.8159\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.8291\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.8397\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8317\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.8130\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8170\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8080\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7909\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8268\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7788\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7894\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.7976\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.7964\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.8296\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8311\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8140\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.7911\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4148 - accuracy: 0.8172\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4515 - accuracy: 0.8031\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7258\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8202\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7999\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.8655\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7964\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8357\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8382\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.7974\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4223 - accuracy: 0.8053\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8419\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8446\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8416\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8116\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8789\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2789 - accuracy: 0.8934\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8444\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8564\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7782\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.7959\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8399\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8187\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8276\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7648\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.83 - 0s 6ms/step - loss: 0.3431 - accuracy: 0.8329\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8232\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8096\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.8391\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7853\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3687 - accuracy: 0.8094: 2s - loss: 0.3260 - accuracy\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.8715\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8319\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8376\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8445\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8364\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8895\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8146\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8817\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8681\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8537\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8243\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8276\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8258\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8371\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.9043\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8184\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8617\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8449\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8291\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8551\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8218\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8466\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8105\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8802\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.9089\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8729\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8573\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8437\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.79 - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8132\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8873\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8035\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8379\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.7803\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.7898\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8750\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.8530\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8495\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8620\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8761\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4790\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.4699\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5242\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5840\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5194\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5685\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.6008\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5733\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6888 - accuracy: 0.5572\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5654\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5503\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5764\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5496\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5391\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5524\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.5755\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5771\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.5855\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.6560 - accuracy: 0.5685\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6614 - accuracy: 0.5483\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.5298\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.4926\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.5863\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.4948\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.5832\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.5130\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6099\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6375\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6683\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.5711\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6365\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6783\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7147\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6872\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6422\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7240\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7400\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.6823\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7196\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7094\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7384\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7840\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7369\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7731\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7970\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.8112\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7822\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7972\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8366\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8136\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7897\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7621\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.8057\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7963\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8605\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.8207\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7915\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8690\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8375\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7890\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8383\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8639\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8404\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.8267\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8730\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.9086\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8403\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8760\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8242\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8172\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8483\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8287\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.8260\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7487\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8400\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8391\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8486\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.8369\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8090\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8694\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8959\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8173\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8503\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8492\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8312\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8740\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.8279\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8781\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8339\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8446\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8369\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8358\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7815\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8449\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8946\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8502\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8623\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8460\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8720\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8383\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8167\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8435\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8293\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8782\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8913\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8695\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8485\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8923\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7948\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8308\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.8147\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8234\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8505\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7948\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8529\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8481\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8785\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8765\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8758\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4411\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4755\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5226\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5981\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5269\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5654\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5753\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5775\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5366\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5813\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.5980\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6905\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6781\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6674\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.7031\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7219\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7355\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.8046\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7930\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7215\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7409\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.8032\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7667\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8351\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7771\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.8268\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8421\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7750\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8323\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8309\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8023\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8125\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8617\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8117\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8781\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8593\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.9014\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8736\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8257\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8067\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8903\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8262\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8284\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8324\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8358\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8543\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8455\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8527\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8770\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8761\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8582\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8269\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8789\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8519\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8802\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8221\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8671\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8428\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8507\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8502\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8341\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2422 - accuracy: 0.8931\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8633\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8962\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.8737\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9122\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8668\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.8868\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8676\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8561\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8427\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8574\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.8688\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.7970\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8531\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8758\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.8828\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8879\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8336\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8849\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.8802\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8836\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8726\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8544\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8959\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.8961\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8912\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.8998\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8853\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.8636\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.8848\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8427\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8327\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.8869\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.8933\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8915\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.8883\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8786\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8673\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.9205\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8819\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8760\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8937\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9049\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9268\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2373 - accuracy: 0.8849\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.88 - 0s 3ms/step - loss: 0.2423 - accuracy: 0.8841\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.8962\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8371\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.8859\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8492\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8973\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.9042\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8649\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.8879\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.8948\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.8941\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9098\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9232\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.8860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4227 \n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5730\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5600\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4702\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5823\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5007\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5644\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4860\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5024\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5029\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5231\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5737\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5328\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.4873\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.4907\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.5699\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.5006\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.4885\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.5843\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.5260\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6588 - accuracy: 0.5626\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.5547\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.5117\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.5308\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.5761\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.5981\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.5918\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6197\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.7097\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6753\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6434\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6318 - accuracy: 0.6183\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6150\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.6886\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7114\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6994\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.6928\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.6983\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7040\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6759\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7388\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.6592\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.7773\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7644\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7727\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.8201\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7851\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5389 - accuracy: 0.7220\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.8016\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8202\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7641\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.8196\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8374\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8384\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.8210\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8147\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8419\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8382\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8264\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8107\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7720\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7828\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8495\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4416 - accuracy: 0.8502\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7795\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8536\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.8405\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7902\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8660\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8207\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8644\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8428\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7823\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4471 - accuracy: 0.8272\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8758\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8251\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8491\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8032\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8251\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8461\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8036\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8517\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8147\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8005\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8065\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8887\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8447\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8367\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8351\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8123\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.8744\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8443\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8536\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8875\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.9038\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8750\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8543\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8672\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8703\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8530\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8316\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8430\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8936\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8984\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8320\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8656\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8885\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8801\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8603\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8635\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.9011\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8661\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.9073\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8926\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8828\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8757\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8995\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8087\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8701\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5452\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5473\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5373\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6935 - accuracy: 0.4752\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5697\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5052\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.5621\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5046\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.4882\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5023\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5551\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5942\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5373\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.4751\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5002\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5794\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5236\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4958\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6074\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5309\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5513\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5534\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5317\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5602\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5687\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5610\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5269\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5266\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5720\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5180\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5274\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5326\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4808\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5848\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.6013\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5165\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5116\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5794\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5581\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5155\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5210\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5516\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.5983: 0s - loss: 0.6740 - accuracy: 0.\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5450\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5288\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5244\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5164\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5397\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5297\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.4820\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5131\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5989\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.5275\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5188\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5578\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5208\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5188\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5742\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5796\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5061\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5041\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5389\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5867\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5418\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5633\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.4917\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5918\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5819\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5760\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5220\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5481\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6109\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5018\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5826\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.4715\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5036\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5880\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5667\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5506\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.5854\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.5647\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5190\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5362\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5531\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5222\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4909\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5341\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5002\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5656\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5315\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.4978\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.4745\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.4790\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5102\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.4843\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5479\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5117\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5440\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.4715\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.5005\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5153\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5147\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.4955\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5223\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4556\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5342\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5418\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.5954\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6834 - accuracy: 0.5900\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6902 - accuracy: 0.5393\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6901 - accuracy: 0.5397\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5031\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.4811\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.4921\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5131\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5872\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.6461\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6917 - accuracy: 0.5283\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.4386\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5400\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5301\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.4583\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6918 - accuracy: 0.5794\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.4927\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5793\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6914 - accuracy: 0.5086\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.4812\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.4709\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.5549\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6747 - accuracy: 0.5922\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6770 - accuracy: 0.5487\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.4785\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5085\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.5607\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.6102\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.5784\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6381 - accuracy: 0.6458\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6329 - accuracy: 0.6517\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.6825\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6184 - accuracy: 0.6512\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6141 - accuracy: 0.6642\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.7193\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.7022\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.6782\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5777 - accuracy: 0.7450\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5671 - accuracy: 0.7225 0s - loss: 0.5531 - accuracy\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7349\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7598\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7292\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7725\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5597 - accuracy: 0.7473\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.8106\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8302\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8336\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4871 - accuracy: 0.7920\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.8136\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8787\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.8513\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7977\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.8275\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7896\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.8483\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8618\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8386\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8378\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7966\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8100\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8719\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8594\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.9160\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7592\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8595\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8771\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8578\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8460\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8617\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8191\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8334\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8128\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8047\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8490\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8264\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8020\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8575\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8182\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8090\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8663\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8135\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8481\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3242 - accuracy: 0.8629\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8131\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8362\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.7951\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8522\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8047\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8258\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8593\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.8576\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8641\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8298\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.9014\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8273\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8478\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8680\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8536\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8224\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.7807\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8681\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8714\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.9007\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8651\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2968 - accuracy: 0.8639\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.8838\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8165\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8613\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8623\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3039 - accuracy: 0.8643\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2898 - accuracy: 0.8772\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8742\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8914\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8988\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8849\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8388\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8444\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2222 - accuracy: 0.9042\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8531\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8208\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8619\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2859 - accuracy: 0.8549\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8357\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8821\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8295\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8594\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8934\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8752\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8081\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.7822\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.8894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4655\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4741\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5266\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.4623\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5924\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4961\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5722\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4915\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4691\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4600\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5517\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5910\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5199\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4816\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5109\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5452\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5222\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4553\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5388\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5219\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5552\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.5406\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5308\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5334\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5557\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5182\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5223\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5155\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5311\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5083\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6914 - accuracy: 0.5457\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5238\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.4697\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6893 - accuracy: 0.5835\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6080\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5015\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.4897\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.5593\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6911 - accuracy: 0.5448\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5214\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.5109\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6910 - accuracy: 0.5446: 0s - loss: 0.6910 - accuracy: 0.54\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5287\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5495\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5299\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5288\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5014\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4931\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.5578\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5353\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4828\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5619\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5599\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5440\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5019\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5413\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5267\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5186\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5458\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5536\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5118\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5109\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5669\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5905\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.5466\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5050\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.4852\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5720\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5664\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5358\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5174\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5903\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5787\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.4864\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5558\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4636\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4865\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5294\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5673\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.5274\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5834\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5350\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5471\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5226\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5128\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.4839\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4963\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5468\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4797\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5577\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4705\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5081\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4926\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4895\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5226\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4713\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5116\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4992\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5225\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4735\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4775\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5111\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5746\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4980\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5109\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4609\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5006\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5410\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5592\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5728\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5114\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5641\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.4598\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.4585\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5389\n",
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5113\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5627\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.6370\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5071\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiadoriane/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5307\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5344\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5062\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.4910: 0s - loss: 0.6939 - accuracy: 0.\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5617\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5863\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5317\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5547\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5623\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5454\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5134\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4759\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5135\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.4770\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4947\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5279\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5686\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5104\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5383\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5497\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.6058\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5697\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5085\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5051\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5649\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4915\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5500\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5807\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5465\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5353\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5204\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5688\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5670\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5758\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5813\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.6279\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.4533\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5862\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.4876\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.4803\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5247\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.4725\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.4845\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5188\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5419\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5412\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5361\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5633\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.6254\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5261\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4895\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5389\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5554: 0s - loss: 0.6883 - accuracy: 0.55\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5481\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5364\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5514\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5483\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5393\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5117\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4476\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5122\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.5781: 0s - loss: 0.6853 - accuracy: 0.\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5182\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.6049\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.5834\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5543\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5728\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5193\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5054\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5580\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5209\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.6203\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5085\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6166\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5617\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.4993\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5986\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.5902\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.5793\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4900\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5012\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5903\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5587\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5655\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4803\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5903\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5259\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5722\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5672\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5227\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.4988\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.5483\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5166\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5704\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4742\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5592\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5190\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4893\n",
      "best_accuracy_score: 0.7772058823529411\n",
      "best_parameters: {'batch_size': 5, 'epochs': 100, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#construire le modèle\n",
    "#ajout des couches \n",
    "\n",
    "#def de la methode :initialisation\n",
    "def classifier(optimizer): \n",
    "    model = Sequential() \n",
    "    model.add(Dense(units=16, kernel_initializer='uniform', activation='relu', input_dim=60)) #premiere couche \n",
    "    \n",
    "    \n",
    "    #3 autres couches \n",
    "    #probabilité  de la classification grace a la sigmoid\n",
    "    model.add(Dense(units=8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid')) #couche de maxpooling\n",
    "    \n",
    "    #complile le model\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# choisir des hyperparamètres : gridsearchcv , permet de choisir l'optmiseur \n",
    "#from kerasclassifier avec les param par defaut\n",
    "model = KerasClassifier(build_fn=classifier)    \n",
    "\n",
    "#proposition de parametres a mon NN \n",
    "params = {'batch_size': [1, 5], 'epochs': [100, 120], 'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "\n",
    "#l'estimateur :\n",
    "gridSearch = GridSearchCV(estimator = model, param_grid=params, scoring='accuracy', cv=10)\n",
    "\n",
    "gridSearch = gridSearch.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "#il va generer les models jusqu'a trouver les meilleurs : on va les utiliser pour recalibrer le model \n",
    "score = gridSearch.best_score_\n",
    "bestParams = gridSearch.best_params_\n",
    "\n",
    "#affichage des best param qu'on va regler \n",
    "print('best_accuracy_score:',score)\n",
    "print('best_parameters:',  bestParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=16, kernel_initializer='uniform', activation='relu', input_dim=60))\n",
    "model.add(Dense(units=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4833\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5344\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5062\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4910\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5617\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.5863\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5317\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6746 - accuracy: 0.5827\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.7073\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6833\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7656\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6894\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.8003\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8113\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7588\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7859\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7818\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8114\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8487\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8638\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8095\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8459\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8504\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8288\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7854\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8913\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8722\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8293\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.7794\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7918\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8203\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8248\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8035\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8885\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8009\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8344\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8324\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8181\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8542\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8409\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8286\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8120\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8307\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8546\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8363\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8413\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8401\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8726\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8370\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8738\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8353\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8382\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8395\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.8936\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8830\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.8423\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8378\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8409\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8758\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8656\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8426\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8335\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8696\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8663\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8309\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.7967\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8315\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.7988: 0s - loss: 0.4081 - accuracy: 0.\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8601\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8181\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8827\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8917\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8459\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8538\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8475\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8508\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8170\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8587\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8041\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8846\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8438\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8364\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8527\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8844\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8956\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8787\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8323\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8821\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8642\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8793\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8567\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8970\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8003\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8782\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8265\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8738\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8291\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8314\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fedacff3e48>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilez le classifieur\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Maintenant ajustons sur les données: ici on lui mets les best params trouvés \n",
    "model.fit(train_x, train_y, batch_size=5, epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2827255 ],\n",
       "       [0.83986926],\n",
       "       [0.7965815 ],\n",
       "       [0.95956945],\n",
       "       [0.01813942],\n",
       "       [0.39557174],\n",
       "       [0.24249053],\n",
       "       [0.94935745],\n",
       "       [0.17204067],\n",
       "       [0.940915  ],\n",
       "       [0.46055388],\n",
       "       [0.0300855 ],\n",
       "       [0.63995236],\n",
       "       [0.55886364],\n",
       "       [0.8943293 ],\n",
       "       [0.39562887],\n",
       "       [0.02457607],\n",
       "       [0.50843585],\n",
       "       [0.66473955],\n",
       "       [0.04755324],\n",
       "       [0.01660672],\n",
       "       [0.9839742 ],\n",
       "       [0.09327632],\n",
       "       [0.5023264 ],\n",
       "       [0.98292387],\n",
       "       [0.5796765 ],\n",
       "       [0.9616091 ],\n",
       "       [0.42707172],\n",
       "       [0.5669898 ],\n",
       "       [0.95348066],\n",
       "       [0.9603173 ],\n",
       "       [0.07705304],\n",
       "       [0.8443377 ],\n",
       "       [0.03936383],\n",
       "       [0.49661332],\n",
       "       [0.00409046],\n",
       "       [0.00250122],\n",
       "       [0.44938898],\n",
       "       [0.97359395],\n",
       "       [0.8783289 ],\n",
       "       [0.15960297],\n",
       "       [0.6606711 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation du modèle\n",
    "\n",
    "#premiere evalutaion on teste les ypred sur les 20% de xtest pour voir si ypred correspond a y initial \n",
    "#mais le resultat donne des valeurs float au lieu de 0 et 1, donc on va mettre un filtre \n",
    "yPred = model.predict(test_x)\n",
    "yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#le filtre qui rends ypred binaire \n",
    "yPred = [1 if y > 0.5 else 0 for y in yPred]\n",
    "yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  4],\n",
       "       [ 4, 18]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(test_y, yPred)\n",
    "#formule de l'accuracy = TP+FN, bref la somme de la disgonale partant des TP/la somme de toute la matrice \n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.95238095238095%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (matrix[0][0] + matrix[1][1]) / (matrix[0][0] + matrix[0][1] + matrix[1][0] + matrix[1][1])\n",
    "#on multipplie par 100 pour avoir en %\n",
    "print(\"Accuracy: \" + str(accuracy * 100) + \"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history = history):\n",
    "    \n",
    "    # Retrieve a list of accuracy results on training and validation data sets for each training epoch\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    # Retrieve a list of list results on training and validation data sets for each training epoch\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Get number of epochs : 1 -> n_epochs\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Plot training and validation accuracy per epoch\n",
    "#     plt.figure(figsize = (20, 10))\n",
    "#     plt.plot(epochs, acc)\n",
    "#     plt.plot(epochs, val_acc)\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Validation'], loc = 'upper left')\n",
    "    \n",
    "#     plt.figure(figsize = (20, 10))\n",
    "\n",
    "    # Plot training and validation loss per epoch\n",
    "    plt.plot(epochs, loss)\n",
    "    plt.plot(epochs, val_loss)\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---------------------------------------------\n",
    "#### CREATION DU RESEAU DE NEURONES\n",
    "#---------------------------------------------\n",
    "#sans Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= sonar.iloc[:,0:60]\n",
    "nb_features = len(X.columns)\n",
    "nb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 60)]              0         \n",
      "_________________________________________________________________\n",
      "dense_674 (Dense)            (None, 16)                976       \n",
      "_________________________________________________________________\n",
      "dense_676 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 993\n",
      "Trainable params: 993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Exemple de création d'un NN avec `Functional API` \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Couche d'entrée\n",
    "inputs = Input(shape=(nb_features,))\n",
    "# inputs.get_shape()\n",
    "# inputs.name\n",
    "\n",
    "# Couches cachées : \n",
    "x = Dense(16, activation='relu')(inputs)\n",
    "x = Dense(8, activation='sigmoid')(x)\n",
    "\n",
    "# Couche de sortie\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.21210724e-01, -1.76968053e-01, -1.10031679e-01,\n",
       "         -2.49441266e-01, -1.77889019e-01,  1.66740716e-01,\n",
       "          2.67667264e-01, -1.48367137e-01,  2.03934073e-01,\n",
       "          1.62150860e-02,  9.89004970e-03,  2.42610604e-01,\n",
       "         -4.48458791e-02,  2.57367820e-01,  7.94455111e-02,\n",
       "         -1.78249836e-01],\n",
       "        [-1.83569163e-01, -2.73062348e-01, -5.44355363e-02,\n",
       "          2.77066320e-01,  2.22659141e-01, -1.83342397e-02,\n",
       "          1.44501299e-01,  6.13961220e-02,  2.92113721e-02,\n",
       "         -1.31214395e-01, -1.93780288e-01,  1.46505773e-01,\n",
       "          1.60967737e-01, -6.19110614e-02, -1.28613919e-01,\n",
       "          4.52965796e-02],\n",
       "        [ 2.01950908e-01,  2.15609461e-01,  4.67065871e-02,\n",
       "         -3.87221277e-02,  1.23799503e-01, -2.43149519e-01,\n",
       "         -1.92390591e-01, -4.40852046e-02,  4.94813919e-03,\n",
       "          2.52670437e-01,  2.26990014e-01,  1.08313918e-01,\n",
       "         -1.38878763e-01, -1.87501997e-01,  2.33670563e-01,\n",
       "         -2.07743853e-01],\n",
       "        [-1.07348189e-01,  2.71325082e-01, -2.66186327e-01,\n",
       "         -1.38337091e-01,  3.20510864e-02,  4.06974554e-02,\n",
       "          6.28737807e-02, -1.69393569e-01, -2.15884447e-01,\n",
       "          2.30836838e-01, -1.10930681e-01, -1.38189450e-01,\n",
       "          1.21694803e-03,  3.89948487e-02,  4.44376469e-02,\n",
       "          5.41360974e-02],\n",
       "        [ 3.03810239e-02,  5.33806384e-02, -3.27147543e-02,\n",
       "          6.43184781e-02, -3.93407196e-02, -2.42860585e-01,\n",
       "         -3.93249691e-02,  1.54235721e-01,  1.93438828e-01,\n",
       "          1.31645888e-01,  8.89866948e-02,  1.80934638e-01,\n",
       "          2.25567728e-01,  8.53518844e-02,  1.22158974e-01,\n",
       "          1.82373255e-01],\n",
       "        [ 1.12571537e-01, -1.76960617e-01,  1.02484584e-01,\n",
       "          6.28156364e-02,  7.25170374e-02,  1.58717752e-01,\n",
       "          2.28243381e-01,  8.89227092e-02, -2.04767883e-02,\n",
       "          9.72559154e-02,  1.62142128e-01,  4.32691276e-02,\n",
       "         -1.58839673e-01, -2.37413049e-01, -1.93893433e-01,\n",
       "          6.30048215e-02],\n",
       "        [-5.04775047e-02,  1.59636974e-01,  2.95002460e-02,\n",
       "         -1.20908946e-01, -1.20167032e-01, -2.16532111e-01,\n",
       "         -2.28414834e-01, -2.20800102e-01,  1.83306336e-02,\n",
       "          2.09197462e-01,  1.75792366e-01, -5.04316837e-02,\n",
       "         -1.77319139e-01, -6.94075227e-03, -4.77172583e-02,\n",
       "         -3.54328007e-02],\n",
       "        [-1.59187198e-01,  1.99226350e-01, -1.63600624e-01,\n",
       "          2.77951330e-01,  1.30859673e-01,  2.32946783e-01,\n",
       "          2.71303266e-01, -4.23789024e-04, -7.26518035e-03,\n",
       "          1.79922581e-03, -2.76328653e-01,  1.41195148e-01,\n",
       "          1.69121265e-01, -1.65716305e-01, -2.75020599e-02,\n",
       "          4.29591835e-02],\n",
       "        [ 5.73904514e-02, -2.74226964e-02,  9.76097584e-02,\n",
       "          2.38879472e-01,  7.52415061e-02, -1.25189930e-01,\n",
       "          1.21523976e-01,  6.89116418e-02, -1.07043788e-01,\n",
       "         -1.79538384e-01, -6.88582659e-04, -1.17031336e-02,\n",
       "         -2.03196436e-01,  1.26866430e-01,  2.05704600e-01,\n",
       "          1.44547313e-01],\n",
       "        [ 2.66032547e-01, -4.49358374e-02,  2.01979965e-01,\n",
       "          1.96260214e-02,  1.94480062e-01, -1.89148337e-01,\n",
       "         -5.17493784e-02, -3.95622849e-03,  5.97903728e-02,\n",
       "         -2.71836162e-01, -5.57657480e-02, -1.61946386e-01,\n",
       "          3.93198133e-02,  2.66760588e-04,  2.55315095e-01,\n",
       "          1.45597905e-01],\n",
       "        [ 2.05319822e-02, -1.45107344e-01,  2.46343106e-01,\n",
       "          1.84905529e-03,  2.76435345e-01,  7.17671514e-02,\n",
       "          3.24707031e-02,  6.08094335e-02, -9.72160548e-02,\n",
       "         -4.68248278e-02,  1.86257869e-01,  1.99987710e-01,\n",
       "         -2.07758591e-01, -1.84190422e-01, -1.02644712e-01,\n",
       "          2.35443085e-01],\n",
       "        [-1.17853269e-01,  2.57129073e-02,  6.23239875e-02,\n",
       "         -2.48543024e-02, -1.86989397e-01, -6.55245036e-02,\n",
       "          1.46728784e-01,  1.92613184e-01,  1.49596334e-02,\n",
       "         -2.38593668e-01, -3.69110703e-02,  8.88620913e-02,\n",
       "         -1.96747333e-01,  8.30797255e-02, -2.79492378e-01,\n",
       "          1.35492027e-01],\n",
       "        [ 3.45010459e-02,  2.61408597e-01,  1.95948869e-01,\n",
       "          1.14772469e-01,  1.64623290e-01,  3.56219113e-02,\n",
       "          1.74379170e-01,  2.62396008e-01,  2.75199085e-01,\n",
       "         -1.58985436e-01, -1.08032227e-01,  1.29765868e-02,\n",
       "          1.56219900e-01, -1.45507678e-01, -2.78248906e-01,\n",
       "         -1.48535818e-01],\n",
       "        [ 1.08310699e-01,  1.28827065e-01, -1.43475741e-01,\n",
       "          8.48373473e-02,  1.87882960e-01,  8.88091028e-02,\n",
       "          5.08633256e-03, -1.08924329e-01,  1.74692810e-01,\n",
       "         -1.12870499e-01,  1.35431886e-01,  2.66279191e-01,\n",
       "          1.16167277e-01, -2.71564454e-01,  6.69842064e-02,\n",
       "          1.47740781e-01],\n",
       "        [-1.43719792e-01, -1.89978272e-01, -2.08313674e-01,\n",
       "         -3.86273414e-02,  2.41301090e-01,  2.49110132e-01,\n",
       "         -5.21996170e-02, -2.05237091e-01,  1.59205437e-01,\n",
       "         -2.10547179e-01,  1.08137935e-01, -2.29901403e-01,\n",
       "         -2.20402583e-01, -2.04040989e-01, -1.78888977e-01,\n",
       "         -2.67139971e-02],\n",
       "        [ 2.43087441e-01, -5.54593503e-02,  8.28183293e-02,\n",
       "         -1.31263226e-01,  1.56431973e-01, -2.26023495e-01,\n",
       "          1.50596082e-01,  2.14099050e-01, -2.56200552e-01,\n",
       "         -1.03764638e-01,  2.86281109e-02,  2.14362770e-01,\n",
       "         -1.24180257e-01,  2.42848992e-02,  1.40944928e-01,\n",
       "         -2.29229361e-01],\n",
       "        [ 1.48522228e-01, -5.98159432e-03,  1.21988952e-01,\n",
       "          1.48909897e-01,  2.17142195e-01, -1.28000498e-01,\n",
       "          2.16245115e-01, -1.08097076e-01, -1.10621244e-01,\n",
       "         -1.75154507e-01,  1.80577993e-01,  1.32236809e-01,\n",
       "          6.71404898e-02,  1.87190443e-01, -2.12050349e-01,\n",
       "          5.94272912e-02],\n",
       "        [-1.94196358e-01, -8.47236514e-02,  1.56418681e-02,\n",
       "         -7.45505691e-02,  2.55539745e-01, -5.56461066e-02,\n",
       "         -2.35506982e-01, -6.80727214e-02, -1.98413700e-01,\n",
       "          2.41155177e-01,  2.61685044e-01, -2.06533134e-01,\n",
       "         -1.21621445e-01,  1.87427431e-01,  2.52185315e-01,\n",
       "          1.97870225e-01],\n",
       "        [ 2.80006319e-01,  2.08892316e-01, -6.95259422e-02,\n",
       "          3.73312831e-03, -2.39300683e-01,  2.64950305e-01,\n",
       "          1.39652699e-01,  2.28628814e-02,  2.00573444e-01,\n",
       "         -1.49884656e-01, -2.73201823e-01,  2.60420054e-01,\n",
       "         -7.40966499e-02,  4.30053473e-03, -1.52618513e-01,\n",
       "         -2.76277274e-01],\n",
       "        [ 1.98358566e-01, -2.11986661e-01,  1.77201450e-01,\n",
       "         -1.02849901e-01,  2.62345225e-01,  2.11279452e-01,\n",
       "         -1.30105585e-01, -1.83344871e-01, -2.58570790e-01,\n",
       "         -1.69356406e-01, -7.82640874e-02,  2.21896917e-01,\n",
       "          1.81630820e-01,  4.58479226e-02,  2.08123922e-02,\n",
       "          2.22110152e-02],\n",
       "        [ 2.03322768e-02, -2.71773815e-01,  1.68986946e-01,\n",
       "         -7.88189024e-02,  8.16519558e-02,  9.36504602e-02,\n",
       "         -1.35935843e-01, -2.39008412e-01, -1.18000507e-02,\n",
       "         -2.62012929e-01, -2.30245396e-01,  1.20530307e-01,\n",
       "          1.31758153e-02,  2.23030537e-01,  9.01275873e-02,\n",
       "         -6.21833205e-02],\n",
       "        [-4.70081717e-02, -5.49183339e-02, -2.75953025e-01,\n",
       "          1.59929991e-01,  2.59215206e-01, -2.38749832e-01,\n",
       "          1.52264684e-01, -1.30432352e-01, -1.07263789e-01,\n",
       "         -2.70008832e-01,  1.84948087e-01, -1.86168164e-01,\n",
       "          2.11329758e-01, -2.02805102e-01, -6.64204359e-04,\n",
       "          1.43710136e-01],\n",
       "        [ 1.09654784e-01, -1.87556148e-02, -5.94042391e-02,\n",
       "          2.31777281e-01, -2.57246315e-01, -1.48280397e-01,\n",
       "         -9.56626832e-02,  1.82838917e-01,  3.60640883e-03,\n",
       "          2.19708890e-01,  2.16321349e-01, -7.99304545e-02,\n",
       "         -4.55165803e-02, -2.51071274e-01,  2.19224125e-01,\n",
       "         -1.38124198e-01],\n",
       "        [ 1.73685253e-02,  1.02500945e-01,  8.26780498e-02,\n",
       "         -5.70715219e-02, -1.09540239e-01,  1.07617438e-01,\n",
       "         -2.38993064e-01,  1.22147799e-01,  1.57044590e-01,\n",
       "          2.37568468e-01,  2.55371898e-01, -9.69546586e-02,\n",
       "         -1.35846406e-01,  1.79541051e-01, -2.18718991e-01,\n",
       "         -1.26377329e-01],\n",
       "        [ 1.07648969e-01, -2.43539512e-02,  6.10134602e-02,\n",
       "         -7.08342493e-02, -2.51174271e-02,  1.66938931e-01,\n",
       "         -1.55351505e-01,  1.59664243e-01,  1.68032557e-01,\n",
       "         -2.89155543e-02,  1.66786879e-01, -1.46011114e-01,\n",
       "          1.18992567e-01,  1.94832891e-01, -2.20854104e-01,\n",
       "          2.47461528e-01],\n",
       "        [-1.75730884e-01,  3.90029550e-02,  1.49876684e-01,\n",
       "         -2.06226930e-01,  2.74605662e-01,  3.73198390e-02,\n",
       "         -2.13311166e-01, -2.59389937e-01,  8.79352093e-02,\n",
       "          8.36506188e-02,  1.18380547e-01, -7.56232888e-02,\n",
       "          1.47526473e-01, -1.30642951e-02, -1.65813982e-01,\n",
       "          2.03699738e-01],\n",
       "        [-7.84063339e-03, -1.37770891e-01, -1.60270631e-02,\n",
       "         -3.95127535e-02,  2.48879105e-01, -1.85567141e-02,\n",
       "         -2.39956975e-01,  8.04775655e-02, -2.43907377e-01,\n",
       "         -2.40870386e-01,  2.29146451e-01, -2.26000383e-01,\n",
       "          1.21084064e-01, -1.82313293e-01, -2.74481863e-01,\n",
       "          2.08682656e-01],\n",
       "        [ 2.79265255e-01,  2.01078027e-01, -2.34328091e-01,\n",
       "         -9.16824937e-02, -2.28315592e-03,  1.27213627e-01,\n",
       "          1.61332160e-01,  7.16844201e-02, -2.43616238e-01,\n",
       "         -1.87012509e-01,  2.62763530e-01, -1.03163347e-01,\n",
       "         -2.16921329e-01, -7.35244900e-02,  1.03554547e-01,\n",
       "          2.86886096e-02],\n",
       "        [ 1.71724081e-01, -1.83044821e-01, -9.90599394e-03,\n",
       "          7.60435760e-02, -2.02305913e-02,  1.95243955e-01,\n",
       "          2.52709836e-01,  6.92625940e-02, -2.61040956e-01,\n",
       "         -1.03079975e-02,  1.60186082e-01,  3.72884274e-02,\n",
       "          2.51730591e-01,  2.33628005e-01, -2.70894170e-02,\n",
       "          1.31381214e-01],\n",
       "        [-9.73394513e-02,  9.31346416e-03,  8.44057798e-02,\n",
       "          5.29235899e-02, -2.01919824e-01,  2.80926555e-01,\n",
       "          1.17567182e-03, -3.97949815e-02,  3.92581224e-02,\n",
       "         -1.26584396e-01,  2.10049629e-01,  1.19444877e-01,\n",
       "          1.23782873e-01, -1.89505875e-01, -1.33009925e-01,\n",
       "          2.43062764e-01],\n",
       "        [-8.16592574e-03,  2.21815914e-01,  2.36094296e-02,\n",
       "          2.16865927e-01,  7.93841481e-03, -1.19623840e-02,\n",
       "         -1.14305422e-01, -3.14639807e-02,  1.90654993e-02,\n",
       "         -2.03595966e-01, -2.70871848e-01,  4.88114357e-03,\n",
       "         -2.49932304e-01,  2.23635763e-01,  2.28460729e-02,\n",
       "         -2.79657245e-01],\n",
       "        [-2.73337960e-02,  1.53890252e-01, -7.26361424e-02,\n",
       "          2.44157284e-01,  7.55666196e-02, -1.48228869e-01,\n",
       "         -1.08060569e-01,  6.64516985e-02, -1.12853885e-01,\n",
       "          1.67375773e-01, -1.52375683e-01, -7.92734325e-02,\n",
       "         -1.16582468e-01, -1.08878911e-01, -5.69665432e-02,\n",
       "         -4.82374430e-02],\n",
       "        [ 6.85182214e-02, -1.52580142e-02,  1.06857091e-01,\n",
       "          2.11482346e-02,  1.58160925e-04,  2.04481184e-01,\n",
       "         -4.07863557e-02,  6.14653230e-02,  1.13470405e-01,\n",
       "          1.67180032e-01,  1.22820824e-01, -1.91407382e-01,\n",
       "          7.98057914e-02, -1.36601627e-02, -8.09407383e-02,\n",
       "          4.66309488e-02],\n",
       "        [ 2.17261821e-01, -2.73470581e-01, -2.13668555e-01,\n",
       "         -1.78337723e-01, -1.89638317e-01, -1.28901765e-01,\n",
       "          9.42400396e-02,  1.91138476e-01,  1.68553978e-01,\n",
       "         -1.01686150e-01, -1.40483648e-01, -2.08646134e-01,\n",
       "          5.09348512e-02,  2.51488656e-01, -1.87649369e-01,\n",
       "         -1.12248957e-02],\n",
       "        [-1.96880639e-01, -1.33594140e-01, -2.14202806e-01,\n",
       "          1.01395220e-01, -2.60677606e-01,  1.02649927e-02,\n",
       "          1.88702524e-01, -1.69808447e-01,  2.59069651e-01,\n",
       "          2.77666181e-01,  1.98540330e-01,  1.76293790e-01,\n",
       "         -2.73379683e-01, -1.52626291e-01,  2.07517892e-01,\n",
       "          7.33244717e-02],\n",
       "        [-1.46393418e-01,  1.50232404e-01,  1.46489829e-01,\n",
       "         -2.55997777e-02, -5.98433614e-02, -1.25081539e-02,\n",
       "         -2.15958267e-01,  3.05351615e-02,  2.68554956e-01,\n",
       "          2.40604192e-01,  1.18156940e-01,  2.07591712e-01,\n",
       "         -1.55033767e-02,  9.01589990e-02,  3.40649188e-02,\n",
       "          2.32173353e-01],\n",
       "        [ 1.26945674e-02,  1.56395465e-01, -2.03364655e-01,\n",
       "         -2.22403109e-01, -2.56648064e-02, -1.26629680e-01,\n",
       "         -2.67435491e-01,  1.56495690e-01,  3.54095399e-02,\n",
       "         -1.95507422e-01,  2.20506340e-01, -5.58129102e-02,\n",
       "         -1.82652682e-01,  1.80268288e-03,  7.32214153e-02,\n",
       "         -2.09748179e-01],\n",
       "        [-1.95045382e-01, -2.77190477e-01,  2.02584505e-01,\n",
       "         -8.01884383e-02, -1.56319842e-01, -1.68796226e-01,\n",
       "          2.63971895e-01, -8.69360566e-03,  1.58722967e-01,\n",
       "          2.02748895e-01, -4.54936624e-02, -2.20405996e-01,\n",
       "         -4.56886739e-02, -1.60755172e-01,  1.99261129e-01,\n",
       "          2.43848354e-01],\n",
       "        [-1.50765985e-01, -2.20975146e-01, -1.59985855e-01,\n",
       "          1.39754802e-01,  1.42729878e-01,  7.09730387e-02,\n",
       "          8.63273144e-02, -1.51817054e-01,  1.73806995e-01,\n",
       "          3.77191007e-02,  4.85753417e-02,  1.22162312e-01,\n",
       "          1.95055604e-02,  7.94467330e-02, -9.83082503e-02,\n",
       "          6.87339008e-02],\n",
       "        [ 1.81969315e-01, -2.30638832e-01,  1.99307472e-01,\n",
       "         -1.67903319e-01, -1.73080027e-01, -1.28378719e-01,\n",
       "         -1.21665731e-01,  2.23231167e-01,  1.82666332e-01,\n",
       "         -1.03963941e-01,  2.66756862e-01,  1.35580242e-01,\n",
       "         -2.52537996e-01,  7.45928586e-02, -1.25570297e-02,\n",
       "         -1.89852744e-01],\n",
       "        [ 6.51618242e-02,  2.59035498e-01, -3.66950184e-02,\n",
       "          2.54287034e-01, -2.38736957e-01,  3.18077803e-02,\n",
       "         -2.48104751e-01,  1.79691583e-01,  2.97609568e-02,\n",
       "         -5.55163473e-02,  1.89682722e-01, -7.92334378e-02,\n",
       "          1.43799096e-01,  1.06532186e-01, -7.73535669e-02,\n",
       "         -7.45742917e-02],\n",
       "        [ 2.35927999e-02,  2.64227599e-01,  2.48140991e-02,\n",
       "         -1.08221337e-01,  5.93127310e-02, -2.64077663e-01,\n",
       "          2.47575253e-01,  9.60959792e-02,  8.35337639e-02,\n",
       "          1.16868794e-01,  1.86426818e-01, -1.96345150e-02,\n",
       "          7.54570067e-02,  1.56358182e-02, -3.16468030e-02,\n",
       "         -1.68253541e-01],\n",
       "        [ 1.84973061e-01,  2.78063506e-01, -1.45528018e-02,\n",
       "         -2.11328268e-01,  2.16554344e-01,  1.65338159e-01,\n",
       "         -3.35410088e-02, -2.23972201e-01,  6.27616942e-02,\n",
       "          2.33562589e-02, -1.73527777e-01,  9.76995826e-02,\n",
       "         -1.51930124e-01, -7.14358836e-02, -1.97988331e-01,\n",
       "          2.49480754e-01],\n",
       "        [ 2.33038396e-01,  2.15363741e-01,  2.02115029e-01,\n",
       "         -1.99854583e-01, -2.61662155e-01, -1.41840652e-01,\n",
       "          1.76133484e-01,  5.53694963e-02, -1.15224525e-01,\n",
       "          1.05354577e-01,  2.06289977e-01,  1.93896383e-01,\n",
       "         -8.98562074e-02, -5.70204854e-03,  7.79975951e-02,\n",
       "          6.37895167e-02],\n",
       "        [ 1.33648068e-01,  1.84601128e-01,  2.43681878e-01,\n",
       "          3.49193215e-02,  6.42642081e-02, -6.26896918e-02,\n",
       "          8.78247321e-02,  1.09490126e-01,  1.83865309e-01,\n",
       "         -1.59100711e-01,  1.83406323e-01, -1.96259856e-01,\n",
       "          5.89260757e-02, -2.21056074e-01,  9.60889459e-03,\n",
       "         -5.53669631e-02],\n",
       "        [ 1.59094632e-01, -1.71489820e-01,  1.42979831e-01,\n",
       "          1.62988812e-01, -2.82770693e-02, -1.28484219e-01,\n",
       "          2.13382840e-01, -4.93219495e-03,  1.22141898e-01,\n",
       "         -2.46586025e-01, -6.10671937e-02, -8.81517231e-02,\n",
       "         -2.56140381e-01,  8.31984282e-02, -1.78067625e-01,\n",
       "         -2.43308350e-01],\n",
       "        [-1.49158567e-01, -2.46313184e-01, -9.66408104e-02,\n",
       "          1.54610515e-01, -2.17324525e-01, -3.31768394e-03,\n",
       "         -2.60858089e-01, -2.48952717e-01,  1.07426107e-01,\n",
       "         -2.69788504e-03, -7.11834431e-03,  2.06999660e-01,\n",
       "          1.15120292e-01, -7.21959472e-02, -6.84122294e-02,\n",
       "         -1.12431049e-01],\n",
       "        [ 2.20157832e-01, -2.29981527e-01, -2.19010606e-01,\n",
       "          1.46705925e-01, -1.65719450e-01, -2.19803751e-02,\n",
       "         -1.97333902e-01,  1.49999082e-01, -3.39349061e-02,\n",
       "          9.48953927e-02, -7.53939152e-02,  1.55891985e-01,\n",
       "         -1.46050975e-01, -1.05182618e-01, -1.00100935e-02,\n",
       "         -7.67133385e-02],\n",
       "        [ 2.79529363e-01,  9.03273523e-02, -1.42432243e-01,\n",
       "         -1.33537740e-01, -8.63669813e-02, -7.78025985e-02,\n",
       "          2.10291862e-01, -1.79576695e-01, -1.32268280e-01,\n",
       "          1.05746061e-01,  2.61644870e-01,  4.51385975e-04,\n",
       "          1.71410143e-02,  1.72876984e-01,  2.08242655e-01,\n",
       "         -1.05817273e-01],\n",
       "        [ 2.49925256e-03,  2.42604345e-01,  6.16916120e-02,\n",
       "         -9.43564475e-02, -1.22138754e-01, -1.60288855e-01,\n",
       "         -2.03235745e-02,  8.52154791e-02, -5.58923036e-02,\n",
       "         -1.39492154e-02,  1.43204093e-01, -2.23266602e-01,\n",
       "         -1.94724441e-01, -1.08967334e-01,  2.43448168e-01,\n",
       "          4.73667085e-02],\n",
       "        [ 2.18572021e-01,  7.70496428e-02,  2.37963289e-01,\n",
       "         -1.79626614e-01, -8.33093673e-02,  5.81203699e-02,\n",
       "         -1.54493168e-01,  2.30540425e-01,  2.15978026e-01,\n",
       "         -1.43188298e-01, -1.86356217e-01,  7.62346983e-02,\n",
       "         -2.34987736e-01,  1.82939112e-01,  2.37366468e-01,\n",
       "          2.34810621e-01],\n",
       "        [-8.37945044e-02, -1.61504120e-01,  2.66300470e-01,\n",
       "         -6.27858937e-02,  2.20429152e-01,  1.81754351e-01,\n",
       "         -2.24547923e-01,  6.83996379e-02, -2.65406340e-01,\n",
       "         -4.76015061e-02,  9.08409059e-02, -8.60942006e-02,\n",
       "         -2.07532495e-01, -1.38319537e-01,  2.26543278e-01,\n",
       "          1.39448464e-01],\n",
       "        [ 2.41143495e-01,  3.22339535e-02,  2.68961102e-01,\n",
       "          1.13196135e-01, -9.79138166e-02, -8.82110149e-02,\n",
       "          8.25142562e-02,  9.54514146e-02, -1.25968426e-01,\n",
       "         -2.78985381e-01,  2.55377680e-01,  2.65989095e-01,\n",
       "          2.04633117e-01, -7.51868486e-02,  2.77244955e-01,\n",
       "          2.31361598e-01],\n",
       "        [ 2.93232501e-02,  1.85844809e-01,  2.17009485e-01,\n",
       "          2.69376904e-01, -1.96626887e-01, -1.58026278e-01,\n",
       "         -1.32070854e-01, -2.15869114e-01, -1.63703054e-01,\n",
       "         -3.65978181e-02, -2.63923585e-01, -2.34220043e-01,\n",
       "         -1.49926603e-01,  6.29925728e-03, -8.98098946e-03,\n",
       "         -1.11810327e-01],\n",
       "        [ 1.66861892e-01,  3.66416276e-02, -4.04497981e-02,\n",
       "         -1.42266303e-01,  1.94106400e-01, -2.50464201e-01,\n",
       "         -7.61669129e-02, -1.09391659e-01,  3.68824601e-03,\n",
       "         -2.66300529e-01,  2.39607990e-02, -2.09227800e-01,\n",
       "         -1.67261690e-01, -2.96514332e-02,  9.24748182e-03,\n",
       "         -2.38878116e-01],\n",
       "        [ 2.38556713e-01, -4.40337509e-02, -4.49943542e-03,\n",
       "          7.50239193e-02,  9.04330611e-02,  1.60224736e-01,\n",
       "         -1.03173450e-01, -9.03123617e-03, -7.52390325e-02,\n",
       "          6.48026764e-02,  2.32144088e-01, -2.66641676e-02,\n",
       "          1.25196308e-01, -8.03486109e-02, -2.52138078e-01,\n",
       "         -1.39996633e-01],\n",
       "        [ 2.37341523e-02,  2.69534439e-01,  2.75693029e-01,\n",
       "          1.09033048e-01, -9.58248079e-02, -1.49532035e-01,\n",
       "         -2.06764519e-01, -2.46022984e-01,  1.93535447e-01,\n",
       "         -9.13220793e-02,  2.79433817e-01,  1.44368649e-01,\n",
       "          2.76234597e-01,  4.91574705e-02, -1.04723275e-02,\n",
       "          4.84593213e-02],\n",
       "        [ 4.01802957e-02, -1.70311138e-01, -2.57737339e-02,\n",
       "          1.10835880e-01, -2.13587582e-01,  1.92836732e-01,\n",
       "         -3.60700488e-03, -2.16806978e-01, -8.67897570e-02,\n",
       "          1.14794254e-01,  1.66176587e-01, -1.15297347e-01,\n",
       "          2.25177258e-01,  2.26187140e-01,  1.03603005e-01,\n",
       "          8.48945379e-02],\n",
       "        [-1.38302997e-01,  2.21739382e-01, -7.58522600e-02,\n",
       "         -2.61506081e-01,  9.40530002e-02, -1.36043027e-01,\n",
       "         -3.84117663e-02,  2.19067901e-01, -7.01533556e-02,\n",
       "         -1.59259498e-01,  1.27474964e-01, -7.14650303e-02,\n",
       "         -1.20712057e-01,  2.11832494e-01, -1.66813463e-01,\n",
       "         -6.02012128e-02],\n",
       "        [ 2.47806579e-01, -2.67826617e-02,  2.76784927e-01,\n",
       "          3.90097201e-02,  4.75977361e-02, -2.16256440e-01,\n",
       "          4.32859361e-02,  1.35843605e-01, -6.59153908e-02,\n",
       "          2.35170156e-01,  2.31823415e-01, -3.88134420e-02,\n",
       "          2.67142653e-02,  1.79668754e-01,  1.13050759e-01,\n",
       "          2.01372325e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 0.04746163],\n",
       "        [-0.05413109],\n",
       "        [-0.37267816],\n",
       "        [-0.08179384],\n",
       "        [-0.40366808],\n",
       "        [ 0.3920955 ],\n",
       "        [-0.5036851 ],\n",
       "        [-0.537413  ],\n",
       "        [ 0.43383765],\n",
       "        [-0.5472523 ],\n",
       "        [ 0.17296457],\n",
       "        [-0.09676951],\n",
       "        [-0.3869086 ],\n",
       "        [ 0.49873245],\n",
       "        [ 0.44682717],\n",
       "        [ 0.44163287]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.18615627e-01, -2.39069566e-01, -1.29395157e-01,\n",
       "         -2.20028982e-01,  2.35206157e-01,  8.89849961e-02,\n",
       "          2.09212601e-02, -1.73900455e-01, -3.27775180e-02,\n",
       "          1.86270326e-01, -1.19069681e-01, -1.25448048e-01,\n",
       "         -2.27643788e-01,  2.22024322e-03,  2.55556196e-01,\n",
       "          5.44823110e-02],\n",
       "        [ 2.40962714e-01,  9.60174799e-02, -2.33316541e-01,\n",
       "          4.90765572e-02, -2.51806676e-02,  2.72273272e-01,\n",
       "         -2.30854198e-01,  3.25873494e-03, -1.83123544e-01,\n",
       "         -7.13515282e-03, -1.46463811e-02, -1.63945228e-01,\n",
       "         -9.22224224e-02,  2.21354634e-01, -2.51115739e-01,\n",
       "         -1.57277852e-01],\n",
       "        [ 2.27757126e-01, -2.44432107e-01,  1.42461121e-01,\n",
       "          5.75274229e-03, -1.49893239e-01, -2.86638737e-04,\n",
       "         -2.20827505e-01,  2.15648770e-01, -2.26098195e-01,\n",
       "          5.02743423e-02,  2.40991324e-01, -8.16580653e-02,\n",
       "         -2.63278633e-01,  2.27240324e-02, -1.51056513e-01,\n",
       "         -1.88356653e-01],\n",
       "        [ 2.32641846e-01,  5.16674519e-02, -2.72021800e-01,\n",
       "          4.95913625e-03, -1.38573557e-01,  1.22751772e-01,\n",
       "          7.64256120e-02,  1.67433023e-02,  1.81793809e-01,\n",
       "          1.74445629e-01,  4.23181355e-02,  1.42785341e-01,\n",
       "         -1.96936637e-01,  1.74545556e-01, -2.13551000e-01,\n",
       "          2.03044713e-02],\n",
       "        [ 9.86997485e-02,  1.82739228e-01, -3.37054729e-02,\n",
       "          1.68514073e-01,  1.77913398e-01,  1.88589454e-01,\n",
       "          2.25768358e-01,  8.10852945e-02,  2.61366993e-01,\n",
       "          1.05276793e-01,  1.40625715e-01,  8.28028619e-02,\n",
       "          6.92606568e-02,  1.82954401e-01,  1.63164049e-01,\n",
       "          1.20539427e-01],\n",
       "        [ 7.68094063e-02,  2.01954305e-01,  2.80411273e-01,\n",
       "          1.30526602e-01,  2.08142698e-02, -1.30162254e-01,\n",
       "         -2.43625417e-01,  1.87475741e-01, -3.24082822e-02,\n",
       "          2.31673092e-01, -3.95749211e-02, -2.32912540e-01,\n",
       "         -1.56627983e-01, -2.15391606e-01, -1.77796915e-01,\n",
       "          2.47673005e-01],\n",
       "        [-1.15295261e-01,  2.78958678e-03,  1.74913406e-01,\n",
       "          2.29287833e-01, -1.86650291e-01, -7.44060725e-02,\n",
       "          8.03128481e-02,  1.79409891e-01, -1.01038814e-02,\n",
       "          1.63338900e-01, -8.68959278e-02, -1.29083782e-01,\n",
       "          2.15932280e-01,  1.26392871e-01, -1.34290099e-01,\n",
       "         -1.66820496e-01],\n",
       "        [-1.90603763e-01, -9.14768279e-02,  2.71510988e-01,\n",
       "         -2.65108913e-01, -1.15596250e-01, -1.25516713e-01,\n",
       "          2.46415824e-01, -5.16579449e-02, -2.39374176e-01,\n",
       "          1.35828793e-01,  8.36790204e-02, -2.87199616e-02,\n",
       "         -2.46231794e-01, -1.36579812e-01, -2.37808689e-01,\n",
       "         -6.69852793e-02],\n",
       "        [ 1.56774849e-01, -1.12742424e-01, -2.33801022e-01,\n",
       "         -2.76634395e-02, -1.28138065e-02, -2.60848284e-01,\n",
       "         -1.24815598e-01, -2.73420811e-01,  2.24135429e-01,\n",
       "          2.79125005e-01, -6.82232529e-02,  1.24285430e-01,\n",
       "          2.03218699e-01, -2.27807313e-01,  2.72563905e-01,\n",
       "          2.36567169e-01],\n",
       "        [ 9.13853943e-02,  2.03652918e-01, -6.81911558e-02,\n",
       "          2.39017397e-01,  6.39030635e-02,  6.20864332e-02,\n",
       "         -2.06994370e-01,  1.74530953e-01, -2.00515717e-01,\n",
       "          2.11389363e-01,  9.81622934e-03,  2.79014319e-01,\n",
       "         -1.58938199e-01,  2.72048414e-02, -1.93693668e-01,\n",
       "          1.59428298e-01],\n",
       "        [ 1.70645803e-01,  1.38021022e-01, -1.34704903e-01,\n",
       "          8.31740499e-02,  2.10885078e-01, -1.90998062e-01,\n",
       "         -1.80555880e-01, -5.34996837e-02,  1.29308522e-01,\n",
       "          1.63758516e-01,  1.56840086e-02, -2.36283258e-01,\n",
       "          7.15320706e-02, -7.24146068e-02,  2.00492054e-01,\n",
       "         -6.97230846e-02],\n",
       "        [ 5.08340895e-02,  2.54056156e-02, -4.50862348e-02,\n",
       "          5.50601482e-02, -2.30956972e-01, -1.61663949e-01,\n",
       "          3.72750759e-02,  7.66836107e-02, -2.22956166e-01,\n",
       "          1.67638630e-01, -1.70038417e-01,  2.14279383e-01,\n",
       "         -1.33003354e-01,  1.56823456e-01,  1.09976888e-01,\n",
       "          9.44510996e-02],\n",
       "        [-1.30683303e-01,  1.44398004e-01, -2.13609606e-01,\n",
       "         -1.40897244e-01, -1.73623174e-01, -5.38560152e-02,\n",
       "          2.25502342e-01,  1.78908616e-01, -1.82216302e-01,\n",
       "         -2.00219274e-01,  2.52988726e-01, -1.22925535e-01,\n",
       "         -2.67426848e-01, -1.26780942e-01, -2.24411458e-01,\n",
       "          2.30743200e-01],\n",
       "        [ 9.30734575e-02, -7.57738799e-02, -2.16230065e-01,\n",
       "          2.48972476e-02, -1.29475296e-02, -1.63409770e-01,\n",
       "         -3.26521248e-02,  3.55040729e-02, -3.14031541e-02,\n",
       "         -2.20501184e-01,  1.49992794e-01, -2.09277585e-01,\n",
       "         -1.61494806e-01,  2.22503453e-01,  1.11914366e-01,\n",
       "         -2.20658690e-01],\n",
       "        [-3.90296876e-02,  1.81709200e-01, -1.62218571e-01,\n",
       "         -2.03445375e-01,  2.01107085e-01, -1.88798666e-01,\n",
       "         -1.71215162e-01, -1.62368357e-01,  2.07848817e-01,\n",
       "         -1.02215096e-01,  2.24686235e-01,  1.12409413e-01,\n",
       "          7.93963671e-04,  2.23695129e-01, -2.50141650e-01,\n",
       "         -1.90978646e-01],\n",
       "        [-1.82875752e-01, -2.43704200e-01, -1.90118760e-01,\n",
       "         -1.66059136e-02, -2.03249499e-01,  2.43705124e-01,\n",
       "          4.56372201e-02, -2.00221300e-01, -1.56685263e-01,\n",
       "          1.44529492e-01,  7.33627677e-02, -6.79274946e-02,\n",
       "          1.15287602e-02, -2.58327603e-01, -1.71259642e-01,\n",
       "         -1.52258649e-01],\n",
       "        [-2.24599361e-01,  1.77449703e-01, -4.73210216e-03,\n",
       "          1.30511135e-01,  2.03063130e-01, -2.29960695e-01,\n",
       "          1.50155962e-01, -8.32810253e-02,  1.27684504e-01,\n",
       "         -2.27394909e-01,  8.78387392e-02,  2.30506063e-02,\n",
       "          1.57337219e-01, -2.77500242e-01, -2.50628412e-01,\n",
       "         -6.70607835e-02],\n",
       "        [-2.59588212e-01, -1.84381813e-01, -2.53766477e-01,\n",
       "         -2.08936736e-01, -1.61408320e-01,  2.69856542e-01,\n",
       "         -1.65998936e-02,  1.10922247e-01, -6.04310632e-02,\n",
       "         -2.62341112e-01, -2.68407762e-01, -2.07523718e-01,\n",
       "         -2.56237984e-02,  9.19445455e-02,  2.21364498e-02,\n",
       "         -1.46858662e-01],\n",
       "        [-1.21661440e-01,  1.39406383e-01,  7.54383206e-02,\n",
       "          5.78591824e-02, -2.46419698e-01, -1.34300679e-01,\n",
       "          3.95662189e-02,  2.59336829e-03,  1.24096334e-01,\n",
       "          1.19858354e-01, -4.44170684e-02, -9.49365795e-02,\n",
       "          1.83332682e-01, -1.63764015e-01, -2.59787500e-01,\n",
       "         -1.14706486e-01],\n",
       "        [-1.17993683e-01,  1.75455362e-01, -2.18377411e-02,\n",
       "         -2.04382092e-01,  7.80451596e-02,  1.01862401e-01,\n",
       "         -4.59929407e-02,  1.18785828e-01, -3.58949006e-02,\n",
       "          1.44866318e-01,  1.05738759e-01,  6.69595599e-03,\n",
       "          2.53483146e-01, -1.52043551e-01, -2.48394415e-01,\n",
       "          1.20824665e-01],\n",
       "        [-1.64427817e-01, -1.13518700e-01,  2.73893505e-01,\n",
       "         -3.99762541e-02, -2.61883497e-01,  2.04439461e-02,\n",
       "         -1.96988165e-01, -1.45699069e-01,  1.57473952e-01,\n",
       "          2.36318201e-01,  5.59110641e-02,  1.10482246e-01,\n",
       "          1.08645380e-01, -1.29866824e-01, -3.80769521e-02,\n",
       "         -2.17573643e-02],\n",
       "        [ 2.04674631e-01,  1.49752349e-01,  1.46853626e-02,\n",
       "         -7.22169876e-02, -1.67733133e-02,  1.38981998e-01,\n",
       "          2.72726983e-01,  2.78840870e-01,  2.22564548e-01,\n",
       "         -2.51168400e-01, -1.14042491e-01,  1.30676270e-01,\n",
       "         -8.52568299e-02, -1.96879804e-02,  1.40349001e-01,\n",
       "         -2.35058755e-01],\n",
       "        [-8.32295716e-02, -6.96958899e-02, -2.40570202e-01,\n",
       "         -2.70762652e-01, -1.34322524e-01,  2.75227457e-01,\n",
       "         -2.06815362e-01, -1.17560387e-01, -1.19633675e-02,\n",
       "          7.23615587e-02,  4.25796807e-02,  8.41653347e-03,\n",
       "         -1.50396392e-01, -1.38196751e-01,  3.34528387e-02,\n",
       "          7.22818971e-02],\n",
       "        [-8.14364552e-02, -2.07846746e-01, -9.53743011e-02,\n",
       "          1.28734887e-01,  2.79417127e-01, -2.11576730e-01,\n",
       "         -1.10588968e-02, -6.51359558e-02, -1.68480903e-01,\n",
       "          7.09047914e-03, -2.25022137e-01, -1.73524499e-01,\n",
       "          2.54556507e-01,  1.22126877e-01,  1.52991712e-01,\n",
       "         -2.46948645e-01],\n",
       "        [ 6.88216090e-02,  6.51529431e-03, -2.10203648e-01,\n",
       "          1.40045792e-01,  4.59260345e-02,  1.65542066e-02,\n",
       "         -1.16532907e-01, -1.30993724e-01, -2.31277168e-01,\n",
       "         -8.75952989e-02,  2.47040302e-01, -2.53028780e-01,\n",
       "         -1.05874285e-01,  1.53084099e-01, -2.33916774e-01,\n",
       "          1.29449874e-01],\n",
       "        [-7.81745911e-02, -1.15521848e-02,  4.31236327e-02,\n",
       "         -2.61283994e-01,  1.55791700e-01, -2.76358783e-01,\n",
       "         -3.44932675e-02, -6.79248124e-02, -1.94042355e-01,\n",
       "          2.37109929e-01, -2.26889133e-01,  8.07147026e-02,\n",
       "         -2.46967375e-02, -6.37355298e-02,  5.43113947e-02,\n",
       "          1.64455205e-01],\n",
       "        [ 2.02022970e-01, -2.14313805e-01,  2.35453933e-01,\n",
       "          2.89094448e-03, -3.68904322e-02, -1.95230961e-01,\n",
       "         -1.17147669e-01, -2.65359879e-04, -6.18750304e-02,\n",
       "         -1.44102573e-02, -1.12513185e-01, -2.43043199e-01,\n",
       "          2.70987660e-01, -1.91094935e-01, -1.41502157e-01,\n",
       "          2.27727145e-01],\n",
       "        [ 4.38907444e-02, -7.68878460e-02,  2.59346873e-01,\n",
       "         -2.42593765e-01,  2.50650018e-01, -6.41236007e-02,\n",
       "          8.15910101e-03,  2.56352991e-01,  8.73935223e-02,\n",
       "         -1.96238950e-01, -2.16882259e-01, -1.76619172e-01,\n",
       "          1.67411745e-01, -2.41950542e-01, -2.42775977e-01,\n",
       "         -2.23678321e-01],\n",
       "        [ 1.91609293e-01, -2.51118213e-01,  1.96202159e-01,\n",
       "          7.83226490e-02, -1.02194265e-01, -2.03764722e-01,\n",
       "         -2.16515362e-01,  1.51899099e-01,  1.88246042e-01,\n",
       "          9.13706422e-02,  8.86519253e-02,  1.80507779e-01,\n",
       "         -1.46900132e-01, -2.80322522e-01, -1.75929308e-01,\n",
       "          2.38606483e-01],\n",
       "        [-2.77262092e-01, -7.01701045e-02, -2.00787187e-03,\n",
       "          2.95129418e-03,  1.65434867e-01,  2.53699034e-01,\n",
       "         -2.71001816e-01, -2.32796162e-01,  2.67553896e-01,\n",
       "         -2.23347247e-01, -8.46832544e-02,  1.52157575e-01,\n",
       "          2.44182020e-01, -1.37328491e-01,  2.15141147e-01,\n",
       "          3.03811729e-02],\n",
       "        [-1.91392034e-01, -2.68810987e-03, -2.59095907e-01,\n",
       "         -9.69979912e-02, -1.41981542e-02, -2.61804849e-01,\n",
       "         -1.21262044e-01,  1.24759078e-02,  1.16731256e-01,\n",
       "         -8.71382952e-02,  5.10106087e-02, -2.64216423e-01,\n",
       "          4.30308580e-02, -1.76008016e-01,  1.30859554e-01,\n",
       "         -7.63691515e-02],\n",
       "        [-1.00501701e-01,  6.88695014e-02, -1.65508837e-01,\n",
       "         -6.36484474e-02, -2.31918931e-01, -2.55892575e-02,\n",
       "         -1.19728178e-01, -2.65075624e-01, -2.56984651e-01,\n",
       "          1.70050681e-01, -2.04921961e-02,  5.43630123e-03,\n",
       "         -2.58238852e-01, -2.35648125e-01, -2.30835646e-01,\n",
       "          1.60168678e-01],\n",
       "        [ 1.29446596e-01, -1.84198260e-01,  1.52048230e-01,\n",
       "          4.53225672e-02,  1.24755293e-01, -1.42309070e-02,\n",
       "          7.26521611e-02,  2.44402975e-01, -1.26541585e-01,\n",
       "         -4.48589325e-02, -1.69194415e-01,  2.58180112e-01,\n",
       "         -1.76215410e-01,  1.47069812e-01, -2.09118068e-01,\n",
       "         -2.08352447e-01],\n",
       "        [-8.42801183e-02, -9.74702090e-02, -1.71903491e-01,\n",
       "         -1.92881554e-01,  2.24146336e-01, -9.23180133e-02,\n",
       "         -2.41455808e-01,  9.27681327e-02,  2.25518435e-01,\n",
       "          1.76757365e-01,  2.52372593e-01,  2.69649476e-01,\n",
       "          1.06946528e-02,  1.51382744e-01, -1.25461817e-02,\n",
       "         -1.30478576e-01],\n",
       "        [-6.95868284e-02, -2.28743553e-01, -1.75022185e-02,\n",
       "          4.33339179e-02,  1.82229221e-01,  1.35360926e-01,\n",
       "          2.13014483e-01,  1.79215223e-01,  1.40308410e-01,\n",
       "         -2.75857985e-01, -3.96686792e-03, -5.74501455e-02,\n",
       "         -1.57073677e-01, -1.17663085e-01, -2.19820440e-01,\n",
       "         -1.96728438e-01],\n",
       "        [ 1.50358826e-01, -2.63749629e-01,  1.28306359e-01,\n",
       "         -1.28475845e-01,  2.46380299e-01,  2.23799437e-01,\n",
       "         -1.43213570e-02,  1.16545558e-01,  7.01510906e-03,\n",
       "          1.14927411e-01,  9.56141353e-02, -3.61022949e-02,\n",
       "         -1.34638652e-01, -6.14426136e-02, -2.11978555e-01,\n",
       "          1.61574185e-02],\n",
       "        [ 4.22687232e-02,  1.36938602e-01, -1.44889772e-01,\n",
       "         -2.21903294e-01,  1.48004055e-01, -9.83089209e-02,\n",
       "         -1.21853575e-01, -2.08245739e-01,  8.14938843e-02,\n",
       "          1.17312253e-01, -1.85771048e-01,  3.97786498e-03,\n",
       "          8.63798261e-02,  1.49154603e-01,  5.50117195e-02,\n",
       "         -8.43045563e-02],\n",
       "        [ 2.31269926e-01, -1.90356910e-01, -1.80461034e-01,\n",
       "         -6.62739873e-02,  1.55654222e-01, -5.87464720e-02,\n",
       "         -2.67429113e-01,  1.26425922e-02,  6.92196488e-02,\n",
       "          1.45756006e-01, -6.96391463e-02,  2.62671500e-01,\n",
       "          6.98073506e-02, -8.68496299e-03, -1.04214147e-01,\n",
       "         -1.36702061e-01],\n",
       "        [-5.08927852e-02,  9.65631008e-03,  4.29199934e-02,\n",
       "          2.28823632e-01,  2.06667334e-01,  2.28849083e-01,\n",
       "          2.55657703e-01, -1.41361281e-01,  6.80557191e-02,\n",
       "          1.57294273e-01, -1.17146060e-01,  2.43602395e-02,\n",
       "         -1.19805336e-03, -1.68434620e-01,  1.53864384e-01,\n",
       "         -3.33560407e-02],\n",
       "        [ 1.80160046e-01, -1.04638189e-01, -1.14594698e-02,\n",
       "          1.71540260e-01,  1.74690515e-01, -4.69157249e-02,\n",
       "          2.41662353e-01, -7.92944431e-03, -1.77773595e-01,\n",
       "          1.77622139e-01, -2.51081258e-01, -1.26968786e-01,\n",
       "         -1.36951134e-01,  1.88733935e-02,  2.76649266e-01,\n",
       "          3.71693075e-02],\n",
       "        [-6.57473058e-02, -2.71587491e-01,  2.18279064e-01,\n",
       "         -9.50254798e-02, -1.97974116e-01, -8.18952769e-02,\n",
       "         -4.99591231e-03, -2.23646104e-01, -1.54988825e-01,\n",
       "         -1.77688181e-01,  2.29128629e-01, -2.43678063e-01,\n",
       "          2.34757066e-02,  2.70429224e-01,  2.00350583e-01,\n",
       "         -7.57452846e-03],\n",
       "        [-9.99152064e-02, -1.41400263e-01,  6.68677688e-03,\n",
       "         -1.62925780e-01, -8.60700756e-02,  7.70624280e-02,\n",
       "          2.73934335e-01, -1.86483413e-01,  2.46643722e-02,\n",
       "         -2.75185853e-01, -2.07011715e-01, -1.37796417e-01,\n",
       "         -2.09431916e-01, -2.77900696e-02, -1.66106120e-01,\n",
       "         -9.17205364e-02],\n",
       "        [-2.64788300e-01, -2.74377912e-01,  1.66408718e-02,\n",
       "          1.47010475e-01, -1.20214328e-01,  2.51587629e-02,\n",
       "          1.83531374e-01, -2.40856588e-01, -2.01281548e-01,\n",
       "         -2.00375974e-01, -7.75129348e-02,  2.45584220e-01,\n",
       "         -2.16175929e-01, -1.39997900e-01,  2.53140241e-01,\n",
       "          1.50855064e-01],\n",
       "        [ 1.47251636e-01, -2.66559452e-01, -1.89630330e-01,\n",
       "          7.11942613e-02,  8.34109783e-02, -1.31647557e-01,\n",
       "          2.32429713e-01, -2.29153529e-01, -1.29480064e-02,\n",
       "         -8.79247636e-02, -1.64792448e-01,  2.34891564e-01,\n",
       "          1.70115530e-01, -6.55202121e-02, -4.90361601e-02,\n",
       "          1.65150493e-01],\n",
       "        [ 1.76485866e-01, -1.16573095e-01,  1.76973403e-01,\n",
       "         -1.65877953e-01, -1.85900748e-01,  2.39923507e-01,\n",
       "          4.06659245e-02, -2.09527120e-01, -2.18872398e-01,\n",
       "          3.39892209e-02, -2.26135045e-01,  6.44716918e-02,\n",
       "         -1.62326217e-01,  2.78659910e-01, -2.59426236e-02,\n",
       "         -1.33703798e-01],\n",
       "        [-1.30364224e-01, -3.81955951e-02,  1.89414233e-01,\n",
       "          1.14304692e-01, -2.34831125e-01,  4.62268591e-02,\n",
       "          7.37146735e-02,  2.06199795e-01,  2.61792272e-01,\n",
       "         -1.82817876e-02,  8.96969140e-02,  1.99670494e-02,\n",
       "         -2.56659389e-02,  4.81894612e-02, -1.09398156e-01,\n",
       "         -1.70944452e-01],\n",
       "        [ 2.66760290e-02, -1.95765868e-01, -1.34231880e-01,\n",
       "          1.01903677e-02,  2.18946010e-01,  1.93202645e-01,\n",
       "         -7.34917372e-02,  1.42011017e-01, -1.97698474e-02,\n",
       "          1.37365669e-01, -1.53936878e-01,  1.22850120e-01,\n",
       "         -3.55377048e-02, -2.27381513e-01,  1.35026991e-01,\n",
       "         -1.58258528e-01],\n",
       "        [-2.31422752e-01, -5.17303497e-02,  2.12173343e-01,\n",
       "          6.86734319e-02, -1.98175758e-01, -2.22283721e-01,\n",
       "         -1.69789687e-01, -6.47413135e-02,  3.72663736e-02,\n",
       "         -2.24324301e-01,  2.02587306e-01,  1.02910131e-01,\n",
       "         -1.66590050e-01,  2.50521928e-01,  9.73422527e-02,\n",
       "         -2.54599273e-01],\n",
       "        [ 2.09899724e-01,  1.96911246e-01,  1.19175583e-01,\n",
       "         -6.68758154e-02,  2.30284333e-02, -1.56117857e-01,\n",
       "         -1.30558163e-01, -2.72385418e-01,  1.57041460e-01,\n",
       "         -2.39692509e-01, -7.46311694e-02, -5.25079072e-02,\n",
       "         -3.81924510e-02, -7.56837130e-02, -1.82296813e-01,\n",
       "         -2.02034369e-01],\n",
       "        [ 2.43965656e-01,  1.41080052e-01,  1.16478652e-01,\n",
       "          8.80138576e-02, -2.05162793e-01,  1.91602528e-01,\n",
       "          1.46681070e-01,  1.87994242e-02,  1.84995830e-01,\n",
       "         -9.76867229e-02, -1.47585034e-01,  1.91291213e-01,\n",
       "          3.89877558e-02,  2.39297181e-01, -9.43583250e-02,\n",
       "         -1.41235471e-01],\n",
       "        [ 5.40713072e-02, -6.73236400e-02, -1.29619241e-03,\n",
       "          1.88173980e-01, -2.53513634e-01,  1.79636657e-01,\n",
       "         -6.04774803e-02, -2.34999329e-01, -2.28029773e-01,\n",
       "         -2.35695153e-01,  1.81987882e-02,  2.78191239e-01,\n",
       "          2.00492471e-01,  2.06920147e-01,  1.60861075e-01,\n",
       "         -2.43027195e-01],\n",
       "        [ 2.57125527e-01, -1.48317307e-01, -2.63875425e-01,\n",
       "          2.65204877e-01, -1.91619068e-01, -6.38155192e-02,\n",
       "         -2.70877957e-01, -4.62312251e-02,  1.85504824e-01,\n",
       "         -5.87319285e-02, -2.23055989e-01,  1.21244043e-01,\n",
       "          6.46307170e-02,  2.62576640e-02,  1.29869044e-01,\n",
       "          1.15277648e-01],\n",
       "        [ 2.51815945e-01,  2.22670346e-01,  3.33070755e-02,\n",
       "          2.41820961e-01, -1.61140233e-01,  5.40638864e-02,\n",
       "          1.23026967e-01,  2.01276988e-01,  8.10906291e-03,\n",
       "          1.22116029e-01,  1.05575711e-01, -8.40821862e-03,\n",
       "         -1.76299483e-01, -6.02927804e-03,  2.52830058e-01,\n",
       "         -2.61124551e-01],\n",
       "        [ 1.48820192e-01, -1.21944740e-01,  1.69034898e-01,\n",
       "         -2.09057316e-01,  1.72417164e-01, -6.38681799e-02,\n",
       "          2.51999706e-01,  1.73587888e-01, -1.02627277e-03,\n",
       "         -7.58941174e-02, -3.57315093e-02,  2.18404680e-01,\n",
       "          2.00016201e-02,  1.51807010e-01, -2.02891976e-01,\n",
       "         -7.32597411e-02],\n",
       "        [ 1.80970371e-01, -1.51375517e-01,  8.40226710e-02,\n",
       "         -2.61739075e-01, -1.76777542e-01,  2.60331243e-01,\n",
       "          2.02648073e-01, -2.27766305e-01, -3.32766771e-03,\n",
       "          1.55731857e-01, -2.54002392e-01,  1.37257874e-01,\n",
       "         -1.95941120e-01, -2.61037886e-01, -2.07909942e-03,\n",
       "         -7.16266036e-02],\n",
       "        [ 2.45842248e-01, -2.17090279e-01,  1.80494338e-01,\n",
       "          8.14663470e-02, -2.02897996e-01,  1.44907326e-01,\n",
       "         -1.60635054e-01, -2.27333218e-01,  2.20771402e-01,\n",
       "         -5.57688326e-02,  1.08158290e-01, -2.43171424e-01,\n",
       "         -1.83784276e-01, -2.61042893e-01,  7.91704059e-02,\n",
       "         -2.33568758e-01],\n",
       "        [ 1.68310225e-01, -1.30279019e-01, -1.56252444e-01,\n",
       "          5.82541525e-02,  3.72961760e-02, -2.64953643e-01,\n",
       "         -7.14597255e-02,  1.10748410e-01, -2.70976216e-01,\n",
       "         -2.00135946e-01, -2.34846801e-01, -7.93418884e-02,\n",
       "         -1.99630916e-01,  7.25714862e-02,  3.32441032e-02,\n",
       "          8.82000923e-02],\n",
       "        [ 1.86780453e-01,  3.76537740e-02,  2.28634626e-01,\n",
       "          7.09371567e-02,  2.79146641e-01,  1.19207680e-01,\n",
       "         -1.92761570e-01, -1.09569043e-01,  1.89833313e-01,\n",
       "          1.82205737e-02,  2.19091922e-01,  3.10315788e-02,\n",
       "         -6.76838458e-02, -2.09235370e-01, -2.63927490e-01,\n",
       "         -1.83810726e-01],\n",
       "        [ 1.89189017e-01,  3.79422307e-03,  2.61500627e-01,\n",
       "          8.00448656e-02, -2.17844367e-01, -7.65059441e-02,\n",
       "          3.53489816e-02,  2.38951445e-02,  2.04342306e-02,\n",
       "         -1.90082043e-01,  9.07511413e-02, -4.17563766e-02,\n",
       "          1.75645739e-01,  9.88569856e-03, -2.41640508e-02,\n",
       "          1.20529234e-01],\n",
       "        [ 6.37049973e-02, -1.97038740e-01,  1.48410678e-01,\n",
       "          4.08820808e-02,  9.85491574e-02,  1.84702694e-01,\n",
       "         -9.17699933e-03,  2.81709135e-02,  1.33101553e-01,\n",
       "          2.65632898e-01, -3.19894552e-02, -1.97496280e-01,\n",
       "         -1.88289329e-01,  1.78219289e-01,  5.81254661e-02,\n",
       "         -2.31212065e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 0.3127979 , -0.07669926, -0.24612892, -0.41239977, -0.12144411,\n",
       "          0.44290888,  0.3660797 , -0.10656571],\n",
       "        [-0.14680362,  0.32505798, -0.4504553 ,  0.24215817,  0.44398105,\n",
       "         -0.3964821 ,  0.10952115,  0.4154744 ],\n",
       "        [ 0.16363811,  0.21358788,  0.38826418,  0.23603463, -0.48809743,\n",
       "         -0.27549028,  0.10819507,  0.1164726 ],\n",
       "        [-0.23400474,  0.2736634 ,  0.3734269 , -0.06493151,  0.11260796,\n",
       "         -0.48600495,  0.39491928, -0.33431804],\n",
       "        [-0.30219436, -0.11628795,  0.33875346, -0.12756538,  0.00169277,\n",
       "          0.33086765,  0.3001424 ,  0.01095796],\n",
       "        [ 0.48831058, -0.41661835,  0.47832632,  0.14179027,  0.05451024,\n",
       "         -0.24663079,  0.3927405 , -0.17155433],\n",
       "        [-0.06927979,  0.16709971,  0.07031894, -0.48553717, -0.1509558 ,\n",
       "         -0.41098762, -0.43766963,  0.21606195],\n",
       "        [-0.46499324, -0.22263336,  0.26232696, -0.1341052 , -0.00055969,\n",
       "          0.45640457, -0.05959725, -0.49164248],\n",
       "        [-0.42690897,  0.47719657,  0.21953428,  0.42846692,  0.48493743,\n",
       "         -0.49035072,  0.38273156, -0.10943472],\n",
       "        [-0.4183457 ,  0.08836031, -0.1352458 ,  0.31231403, -0.30137563,\n",
       "         -0.31507993, -0.31888378,  0.29756558],\n",
       "        [ 0.36934638, -0.47581732, -0.05774498, -0.04936182, -0.33404565,\n",
       "          0.08042133,  0.37057257,  0.3301543 ],\n",
       "        [-0.22575426, -0.48189557, -0.27397037,  0.49634504,  0.11062574,\n",
       "          0.4160428 , -0.1336956 ,  0.31133294],\n",
       "        [-0.37819684,  0.30013537, -0.01012862, -0.05197275, -0.10538018,\n",
       "          0.3662666 , -0.12306619, -0.35137486],\n",
       "        [-0.04578888, -0.37102544, -0.48370504, -0.23771131, -0.30922806,\n",
       "          0.29208803,  0.08628666, -0.17223036],\n",
       "        [ 0.08796227,  0.12526834, -0.42323637,  0.220806  , -0.3614416 ,\n",
       "         -0.21784699,  0.39756024,  0.18184507],\n",
       "        [ 0.08733726, -0.2521037 ,  0.12542808, -0.2369703 , -0.40745366,\n",
       "         -0.08013535,  0.49305034, -0.38322794]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.7258351 ],\n",
       "        [-0.3156895 ],\n",
       "        [ 0.53344953],\n",
       "        [ 0.31346822],\n",
       "        [ 0.49094856],\n",
       "        [ 0.035815  ],\n",
       "        [ 0.35910904],\n",
       "        [-0.01547611]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Est-ce qu'on obtient les mêmes poids initiaux (en recréant le NN, reproduire les résultats) ? \n",
    "model2 = Sequential()\n",
    "model2.add(Dense(units=16, input_dim=60, activation=\"sigmoid\"))\n",
    "model2.add(Dense(units=8, activation='relu'))\n",
    "\n",
    "model2.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "model1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "9/9 [==============================] - 1s 48ms/step - loss: 0.7225 - accuracy: 0.5407 - val_loss: 0.7289 - val_accuracy: 0.5909\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7255 - accuracy: 0.3921 - val_loss: 0.7460 - val_accuracy: 0.3636\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7113 - accuracy: 0.4899 - val_loss: 0.7566 - val_accuracy: 0.1818\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7110 - accuracy: 0.4552 - val_loss: 0.7511 - val_accuracy: 0.2727\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6912 - accuracy: 0.5405 - val_loss: 0.7366 - val_accuracy: 0.2727\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6801 - accuracy: 0.5019 - val_loss: 0.7350 - val_accuracy: 0.3636\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6807 - accuracy: 0.5435 - val_loss: 0.7407 - val_accuracy: 0.3182\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6693 - accuracy: 0.6088 - val_loss: 0.7343 - val_accuracy: 0.3636\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.6676 - accuracy: 0.6148 - val_loss: 0.7387 - val_accuracy: 0.3636\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6547 - accuracy: 0.6450 - val_loss: 0.7342 - val_accuracy: 0.3636\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.6365 - val_loss: 0.7337 - val_accuracy: 0.3636\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6596 - accuracy: 0.5938 - val_loss: 0.7316 - val_accuracy: 0.4091\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5661 - val_loss: 0.7308 - val_accuracy: 0.4091\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6694 - accuracy: 0.6154 - val_loss: 0.7282 - val_accuracy: 0.4091\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6777 - accuracy: 0.5836 - val_loss: 0.7308 - val_accuracy: 0.3636\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6538 - accuracy: 0.6493 - val_loss: 0.7285 - val_accuracy: 0.4091\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6697 - accuracy: 0.6311 - val_loss: 0.7192 - val_accuracy: 0.4091\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6671 - accuracy: 0.6070 - val_loss: 0.7136 - val_accuracy: 0.4091\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6524 - accuracy: 0.6323 - val_loss: 0.7167 - val_accuracy: 0.4091\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6492 - accuracy: 0.6512 - val_loss: 0.7252 - val_accuracy: 0.5000\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6379 - accuracy: 0.6152 - val_loss: 0.7252 - val_accuracy: 0.5000\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.6697 - accuracy: 0.5886 - val_loss: 0.7264 - val_accuracy: 0.5000\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6387 - accuracy: 0.6645 - val_loss: 0.7196 - val_accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6727 - accuracy: 0.5978 - val_loss: 0.7237 - val_accuracy: 0.5000\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6494 - accuracy: 0.5928 - val_loss: 0.7221 - val_accuracy: 0.5000\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6474 - accuracy: 0.6065 - val_loss: 0.7131 - val_accuracy: 0.5000\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6138 - accuracy: 0.7447 - val_loss: 0.7126 - val_accuracy: 0.5000\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6339 - accuracy: 0.7046 - val_loss: 0.7206 - val_accuracy: 0.5000\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6659 - accuracy: 0.6607 - val_loss: 0.7160 - val_accuracy: 0.5000\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6362 - accuracy: 0.6655 - val_loss: 0.7194 - val_accuracy: 0.5455\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6701 - accuracy: 0.5483 - val_loss: 0.7231 - val_accuracy: 0.5455\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6467 - accuracy: 0.5977 - val_loss: 0.7184 - val_accuracy: 0.5000\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6571 - accuracy: 0.5650 - val_loss: 0.7126 - val_accuracy: 0.5000\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6143 - accuracy: 0.7341 - val_loss: 0.7016 - val_accuracy: 0.5000\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6407 - accuracy: 0.6678 - val_loss: 0.7027 - val_accuracy: 0.5000\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6218 - accuracy: 0.6602 - val_loss: 0.7117 - val_accuracy: 0.5000\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6208 - accuracy: 0.6860 - val_loss: 0.7042 - val_accuracy: 0.5000\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.6145 - accuracy: 0.7273 - val_loss: 0.7035 - val_accuracy: 0.5000\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6313 - accuracy: 0.6773 - val_loss: 0.7029 - val_accuracy: 0.5000\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6495 - accuracy: 0.6251 - val_loss: 0.7078 - val_accuracy: 0.5000\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6352 - accuracy: 0.6237 - val_loss: 0.7132 - val_accuracy: 0.5455\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6146 - accuracy: 0.6844 - val_loss: 0.7064 - val_accuracy: 0.5000\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6188 - accuracy: 0.6539 - val_loss: 0.6997 - val_accuracy: 0.5000\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6383 - accuracy: 0.6715 - val_loss: 0.6998 - val_accuracy: 0.5000\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6414 - accuracy: 0.6353 - val_loss: 0.6997 - val_accuracy: 0.5000\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6464 - accuracy: 0.6166 - val_loss: 0.7028 - val_accuracy: 0.5000\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6334 - accuracy: 0.6054 - val_loss: 0.7037 - val_accuracy: 0.5455\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6159 - accuracy: 0.6887 - val_loss: 0.7033 - val_accuracy: 0.5000\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6025 - accuracy: 0.6716 - val_loss: 0.6972 - val_accuracy: 0.5000\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5989 - accuracy: 0.7239 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.6583 - accuracy: 0.5620 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6200 - accuracy: 0.6745 - val_loss: 0.6970 - val_accuracy: 0.5000\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6032 - accuracy: 0.6809 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6310 - accuracy: 0.6243 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5694 - accuracy: 0.7952 - val_loss: 0.6979 - val_accuracy: 0.5000\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6545 - accuracy: 0.5875 - val_loss: 0.7057 - val_accuracy: 0.5455\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6211 - accuracy: 0.6743 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6127 - accuracy: 0.6439 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6098 - accuracy: 0.6875 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5887 - accuracy: 0.7433 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6233 - accuracy: 0.6531 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6257 - accuracy: 0.6603 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5907 - accuracy: 0.7195 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.5891 - accuracy: 0.6816 - val_loss: 0.6863 - val_accuracy: 0.5000\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6144 - accuracy: 0.6535 - val_loss: 0.6866 - val_accuracy: 0.5000\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5816 - accuracy: 0.7192 - val_loss: 0.6817 - val_accuracy: 0.5000\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5859 - accuracy: 0.7139 - val_loss: 0.6775 - val_accuracy: 0.5000\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6055 - accuracy: 0.7090 - val_loss: 0.6848 - val_accuracy: 0.5000\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5974 - accuracy: 0.6647 - val_loss: 0.6891 - val_accuracy: 0.5909\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5923 - accuracy: 0.7496 - val_loss: 0.6884 - val_accuracy: 0.5000\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5806 - accuracy: 0.7039 - val_loss: 0.6824 - val_accuracy: 0.5000\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5856 - accuracy: 0.7047 - val_loss: 0.6803 - val_accuracy: 0.5000\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6008 - accuracy: 0.6926 - val_loss: 0.6747 - val_accuracy: 0.5000\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6086 - accuracy: 0.6659 - val_loss: 0.6811 - val_accuracy: 0.5000\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5754 - accuracy: 0.7235 - val_loss: 0.6783 - val_accuracy: 0.5000\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6001 - accuracy: 0.6726 - val_loss: 0.6734 - val_accuracy: 0.5000\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5897 - accuracy: 0.7094 - val_loss: 0.6745 - val_accuracy: 0.5000\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5907 - accuracy: 0.7079 - val_loss: 0.6791 - val_accuracy: 0.5455\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5785 - accuracy: 0.6772 - val_loss: 0.6811 - val_accuracy: 0.5455\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.5955 - accuracy: 0.6863 - val_loss: 0.6719 - val_accuracy: 0.5000\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6286 - accuracy: 0.6587 - val_loss: 0.6831 - val_accuracy: 0.5455\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.5703 - accuracy: 0.7409 - val_loss: 0.6756 - val_accuracy: 0.5000\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5830 - accuracy: 0.7401 - val_loss: 0.6705 - val_accuracy: 0.5000\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6077 - accuracy: 0.6524 - val_loss: 0.6682 - val_accuracy: 0.5455\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5966 - accuracy: 0.6457 - val_loss: 0.6768 - val_accuracy: 0.5455\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5730 - accuracy: 0.6946 - val_loss: 0.6704 - val_accuracy: 0.5909\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5914 - accuracy: 0.6935 - val_loss: 0.6693 - val_accuracy: 0.5909\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5838 - accuracy: 0.6708 - val_loss: 0.6735 - val_accuracy: 0.5455\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5363 - accuracy: 0.7576 - val_loss: 0.6692 - val_accuracy: 0.5909\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5800 - accuracy: 0.7247 - val_loss: 0.6721 - val_accuracy: 0.5455\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5770 - accuracy: 0.7187 - val_loss: 0.6729 - val_accuracy: 0.5455\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5737 - accuracy: 0.7035 - val_loss: 0.6693 - val_accuracy: 0.6364\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5885 - accuracy: 0.6686 - val_loss: 0.6685 - val_accuracy: 0.5909\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6193 - accuracy: 0.6472 - val_loss: 0.6765 - val_accuracy: 0.5455\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5791 - accuracy: 0.7175 - val_loss: 0.6642 - val_accuracy: 0.5909\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5453 - accuracy: 0.7506 - val_loss: 0.6718 - val_accuracy: 0.5909\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5751 - accuracy: 0.6837 - val_loss: 0.6714 - val_accuracy: 0.5909\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5952 - accuracy: 0.6767 - val_loss: 0.6711 - val_accuracy: 0.5455\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.6674 - val_loss: 0.6713 - val_accuracy: 0.5909\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5687 - accuracy: 0.7183 - val_loss: 0.6710 - val_accuracy: 0.5909\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5524 - accuracy: 0.7192 - val_loss: 0.6587 - val_accuracy: 0.5909\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.6088 - accuracy: 0.6090 - val_loss: 0.6578 - val_accuracy: 0.6364\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5814 - accuracy: 0.7018 - val_loss: 0.6617 - val_accuracy: 0.5909\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.6035 - accuracy: 0.6567 - val_loss: 0.6675 - val_accuracy: 0.6364\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5738 - accuracy: 0.6938 - val_loss: 0.6682 - val_accuracy: 0.5909\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.5449 - accuracy: 0.7420 - val_loss: 0.6636 - val_accuracy: 0.6364\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5659 - accuracy: 0.7065 - val_loss: 0.6598 - val_accuracy: 0.6364\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5664 - accuracy: 0.7227 - val_loss: 0.6647 - val_accuracy: 0.6364\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5607 - accuracy: 0.6628 - val_loss: 0.6564 - val_accuracy: 0.6364\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6008 - accuracy: 0.6252 - val_loss: 0.6702 - val_accuracy: 0.5455\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5343 - accuracy: 0.6979 - val_loss: 0.6570 - val_accuracy: 0.6364\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5564 - accuracy: 0.7195 - val_loss: 0.6594 - val_accuracy: 0.6364\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5498 - accuracy: 0.7028 - val_loss: 0.6652 - val_accuracy: 0.5909\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5545 - accuracy: 0.6852 - val_loss: 0.6633 - val_accuracy: 0.6364\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5967 - accuracy: 0.6414 - val_loss: 0.6636 - val_accuracy: 0.5909\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5455 - accuracy: 0.7350 - val_loss: 0.6637 - val_accuracy: 0.5909\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5586 - accuracy: 0.6862 - val_loss: 0.6573 - val_accuracy: 0.5909\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.6869 - val_loss: 0.6532 - val_accuracy: 0.6818\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5471 - accuracy: 0.7416 - val_loss: 0.6552 - val_accuracy: 0.5909\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5278 - accuracy: 0.7274 - val_loss: 0.6658 - val_accuracy: 0.5909\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5440 - accuracy: 0.6873 - val_loss: 0.6558 - val_accuracy: 0.5909\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5286 - accuracy: 0.7230 - val_loss: 0.6579 - val_accuracy: 0.5909\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5573 - accuracy: 0.6997 - val_loss: 0.6589 - val_accuracy: 0.5909\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5714 - accuracy: 0.6554 - val_loss: 0.6653 - val_accuracy: 0.5455\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5383 - accuracy: 0.7383 - val_loss: 0.6565 - val_accuracy: 0.5909\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5496 - accuracy: 0.7165 - val_loss: 0.6529 - val_accuracy: 0.5909\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5416 - accuracy: 0.7177 - val_loss: 0.6498 - val_accuracy: 0.6364\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5723 - accuracy: 0.6852 - val_loss: 0.6470 - val_accuracy: 0.6818\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5192 - accuracy: 0.7661 - val_loss: 0.6502 - val_accuracy: 0.5909\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5551 - accuracy: 0.6986 - val_loss: 0.6649 - val_accuracy: 0.5909\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5457 - accuracy: 0.7694 - val_loss: 0.6565 - val_accuracy: 0.5909\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5468 - accuracy: 0.7057 - val_loss: 0.6563 - val_accuracy: 0.5909\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5236 - accuracy: 0.7180 - val_loss: 0.6540 - val_accuracy: 0.5909\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5554 - accuracy: 0.6773 - val_loss: 0.6471 - val_accuracy: 0.6364\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5056 - accuracy: 0.7570 - val_loss: 0.6483 - val_accuracy: 0.5909\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5428 - accuracy: 0.7513 - val_loss: 0.6623 - val_accuracy: 0.5455\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5313 - accuracy: 0.7065 - val_loss: 0.6511 - val_accuracy: 0.6364\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5674 - accuracy: 0.6663 - val_loss: 0.6463 - val_accuracy: 0.6364\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5479 - accuracy: 0.6883 - val_loss: 0.6533 - val_accuracy: 0.5455\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5596 - accuracy: 0.6805 - val_loss: 0.6530 - val_accuracy: 0.5909\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4913 - accuracy: 0.7783 - val_loss: 0.6531 - val_accuracy: 0.5909\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5204 - accuracy: 0.7183 - val_loss: 0.6577 - val_accuracy: 0.5455\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5143 - accuracy: 0.7566 - val_loss: 0.6516 - val_accuracy: 0.5909\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7284 - val_loss: 0.6475 - val_accuracy: 0.6364\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5074 - accuracy: 0.7843 - val_loss: 0.6471 - val_accuracy: 0.6364\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5395 - accuracy: 0.7527 - val_loss: 0.6483 - val_accuracy: 0.6364\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5525 - accuracy: 0.7154 - val_loss: 0.6481 - val_accuracy: 0.6364\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.7481 - val_loss: 0.6520 - val_accuracy: 0.6364\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.8098 - val_loss: 0.6496 - val_accuracy: 0.6364\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.7794 - val_loss: 0.6577 - val_accuracy: 0.5455\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=100, random_state=42, stratify = y)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=500, stratify = y, random_state = 42)\n",
    "\n",
    "# Apprentissage\n",
    "history = model1.fit(train_x, train_y, epochs=150, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476744</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.728925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.718329</td>\n",
       "      <td>0.746025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.710868</td>\n",
       "      <td>0.756636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.698868</td>\n",
       "      <td>0.751070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.694138</td>\n",
       "      <td>0.736576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.522423</td>\n",
       "      <td>0.648331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.648113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.651968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.519915</td>\n",
       "      <td>0.649606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.519869</td>\n",
       "      <td>0.657659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          acc   val_acc      loss  val_loss\n",
       "0    0.476744  0.590909  0.736111  0.728925\n",
       "1    0.430233  0.363636  0.718329  0.746025\n",
       "2    0.488372  0.181818  0.710868  0.756636\n",
       "3    0.511628  0.272727  0.698868  0.751070\n",
       "4    0.511628  0.272727  0.694138  0.736576\n",
       "..        ...       ...       ...       ...\n",
       "145  0.767442  0.636364  0.522423  0.648331\n",
       "146  0.767442  0.636364  0.521739  0.648113\n",
       "147  0.755814  0.636364  0.521259  0.651968\n",
       "148  0.767442  0.636364  0.519915  0.649606\n",
       "149  0.744186  0.545455  0.519869  0.657659\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "    \n",
    "pd.DataFrame({'acc' : acc, 'val_acc' : val_acc, 'loss' : loss, 'val_loss' : val_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 8.90917331e-02, -1.12014413e-01, -8.34873244e-02,\n",
       "         -4.79597487e-02, -2.23082423e-01,  2.15943769e-01,\n",
       "          4.38224763e-01, -1.89161628e-01,  8.35683495e-02,\n",
       "         -5.01602851e-02,  1.57785963e-03,  3.04785669e-01,\n",
       "          1.95452258e-01,  5.77692986e-01,  7.94455111e-02,\n",
       "         -1.22845061e-01],\n",
       "        [-1.25624418e-01, -3.05912346e-01, -1.20107777e-01,\n",
       "          3.14294040e-01,  4.40770447e-01,  2.67140828e-02,\n",
       "          2.25622892e-01, -7.59188533e-02,  1.09051436e-01,\n",
       "         -4.22639966e-01, -1.15319349e-01,  3.73665579e-02,\n",
       "          5.49227595e-01,  2.61803895e-01, -1.28613919e-01,\n",
       "          1.48195788e-01],\n",
       "        [ 3.69639546e-01,  1.30590126e-01, -7.54640400e-02,\n",
       "         -1.11647137e-01,  4.99227047e-02, -7.11768344e-02,\n",
       "          1.44558534e-01, -2.24275380e-01, -3.31139505e-01,\n",
       "          1.46833658e-01,  3.55272114e-01,  5.54846674e-02,\n",
       "         -2.12868024e-02,  1.77189812e-01,  2.33670563e-01,\n",
       "         -6.56988844e-02],\n",
       "        [ 2.16477320e-01,  6.66094422e-02, -5.02013743e-01,\n",
       "         -3.59154820e-01, -3.40783298e-01,  3.42476428e-01,\n",
       "          1.37273744e-01, -4.08889085e-01, -4.57885116e-01,\n",
       "          1.58318669e-01,  1.46374881e-01, -5.04274189e-01,\n",
       "         -6.84976652e-02,  5.64842999e-01,  4.44376469e-02,\n",
       "          3.07858378e-01],\n",
       "        [ 2.56169438e-01, -6.68596923e-02, -1.84686333e-01,\n",
       "         -9.99061316e-02, -1.60492480e-01, -6.82846131e-03,\n",
       "          9.87361819e-02,  2.25424822e-02, -1.33615553e-01,\n",
       "          1.14039421e-01,  2.75505781e-01, -2.89318804e-02,\n",
       "          2.25214541e-01,  3.25383395e-01,  1.22158974e-01,\n",
       "          3.77976060e-01],\n",
       "        [ 1.74245760e-01, -1.77929208e-01,  7.47027248e-02,\n",
       "          9.94746983e-02,  2.35733725e-02,  2.43447334e-01,\n",
       "          3.48917425e-01,  9.46395472e-02, -1.99587181e-01,\n",
       "          2.67543286e-01,  2.23170176e-01,  2.17766091e-02,\n",
       "         -4.26278681e-01, -1.41988650e-01, -1.93893433e-01,\n",
       "          1.28142893e-01],\n",
       "        [ 1.50953993e-01,  5.67965657e-02, -1.10403754e-01,\n",
       "         -2.17174232e-01, -3.17298800e-01, -8.19717869e-02,\n",
       "         -4.27476525e-01, -3.13245982e-01,  1.94847032e-01,\n",
       "          3.30296367e-01,  3.37561220e-01, -2.74368912e-01,\n",
       "         -4.31728780e-01,  4.15274613e-02, -4.77172583e-02,\n",
       "          6.86624125e-02],\n",
       "        [ 3.99378501e-02,  1.14236005e-01, -2.91482538e-01,\n",
       "          1.86536938e-01, -5.48347607e-02,  3.53471637e-01,\n",
       "          1.68629214e-01, -1.02644347e-01,  1.39113560e-01,\n",
       "          1.82722569e-01, -1.31444961e-01, -9.75846633e-05,\n",
       "          7.33085871e-02, -1.24411739e-01, -2.75020599e-02,\n",
       "          1.42082900e-01],\n",
       "        [ 7.47673884e-02,  3.99100371e-02,  1.13013066e-01,\n",
       "          3.35851014e-01, -1.09439328e-01, -5.08815236e-02,\n",
       "          2.92482018e-01,  1.16312124e-01, -3.10248166e-01,\n",
       "          3.95331353e-01, -2.96215108e-03,  1.38929203e-01,\n",
       "         -2.88452446e-01,  3.16156223e-02,  2.05704600e-01,\n",
       "          1.80363476e-01],\n",
       "        [ 5.01190543e-01, -1.85072422e-01,  3.08489390e-02,\n",
       "         -9.06394869e-02, -1.08114127e-02,  6.96727168e-03,\n",
       "         -2.22953469e-01, -1.17487691e-01,  9.22907814e-02,\n",
       "         -8.75333995e-02,  1.36411816e-01, -3.30992758e-01,\n",
       "         -2.34388307e-01, -1.47518322e-01,  2.55315095e-01,\n",
       "          3.12924564e-01],\n",
       "        [ 2.58593082e-01, -2.98212200e-01,  6.77550733e-02,\n",
       "         -1.28843814e-01,  7.75666833e-02,  2.78487742e-01,\n",
       "         -8.22265670e-02, -7.00557902e-02, -1.87012330e-02,\n",
       "         -1.24971293e-01,  3.88121635e-01, -1.51731577e-02,\n",
       "         -2.98185974e-01, -2.04121351e-01, -1.02644712e-01,\n",
       "          4.29866970e-01],\n",
       "        [ 1.91688657e-01, -1.62094951e-01, -1.41570330e-01,\n",
       "         -1.72062144e-01, -4.71110553e-01,  2.08957627e-01,\n",
       "          1.62177622e-01,  2.19515283e-02, -1.63479134e-01,\n",
       "         -3.33703041e-01,  1.96540132e-01, -1.17075481e-01,\n",
       "         -2.30500922e-01,  2.14203551e-01, -2.79492378e-01,\n",
       "          3.66386563e-01],\n",
       "        [ 1.66350856e-01,  2.01766044e-01,  1.04133859e-01,\n",
       "          5.72994910e-02,  1.98667590e-02,  1.39524117e-01,\n",
       "          2.96774749e-02,  2.08135709e-01,  4.29838479e-01,\n",
       "         -3.71510208e-01,  1.56790521e-02, -1.56493604e-01,\n",
       "          3.07988048e-01, -6.08431967e-03, -2.78248906e-01,\n",
       "         -4.53666151e-02],\n",
       "        [ 1.39918387e-01,  1.33401573e-01, -1.60142884e-01,\n",
       "          1.81017190e-01,  1.55804515e-01,  1.51864380e-01,\n",
       "         -2.22194716e-01, -1.18755318e-01,  1.75407171e-01,\n",
       "         -1.90852314e-01,  1.90009132e-01,  2.30114922e-01,\n",
       "          3.71606648e-01, -1.30936861e-01,  6.69842064e-02,\n",
       "          2.15668321e-01],\n",
       "        [ 2.49869321e-02, -2.85428584e-01, -3.15116882e-01,\n",
       "         -6.75805211e-02,  2.41269544e-01,  4.08061236e-01,\n",
       "         -2.90705591e-01, -2.94969916e-01,  2.35012397e-01,\n",
       "         -2.64225334e-01,  2.50115007e-01, -3.79697114e-01,\n",
       "         -1.35186791e-01, -9.62340459e-02, -1.78888977e-01,\n",
       "          1.19047321e-01],\n",
       "        [ 3.94327700e-01, -8.93320963e-02,  8.72377492e-03,\n",
       "         -1.74514741e-01,  1.71177492e-01, -7.46355876e-02,\n",
       "         -3.00339377e-03,  2.14642629e-01, -2.71326303e-01,\n",
       "         -4.83697886e-03,  1.34733111e-01,  1.02343999e-01,\n",
       "         -3.51144612e-01,  1.31643806e-02,  1.40944928e-01,\n",
       "         -1.18050292e-01],\n",
       "        [ 1.84717923e-01,  8.09880495e-02,  1.52734444e-01,\n",
       "          1.87627122e-01,  2.58361906e-01, -7.91401416e-02,\n",
       "          1.56571433e-01, -4.36038477e-03, -2.34643534e-01,\n",
       "         -8.70626494e-02,  1.80169493e-01,  1.24478370e-01,\n",
       "         -7.76480064e-02,  1.68574333e-01, -2.12050349e-01,\n",
       "          6.28156364e-02],\n",
       "        [-1.57720938e-01, -2.22583371e-03,  4.16840017e-02,\n",
       "         -3.55091803e-02,  2.76531905e-01, -4.17057564e-03,\n",
       "         -3.29356670e-01,  2.23941151e-02, -4.29874331e-01,\n",
       "          3.21879417e-01,  2.59925902e-01, -2.16411471e-01,\n",
       "         -1.89875916e-01,  2.00480357e-01,  2.52185315e-01,\n",
       "          1.96167916e-01],\n",
       "        [ 3.34480822e-01,  2.47898549e-01, -7.70449489e-02,\n",
       "          1.99821964e-02, -3.23451221e-01,  3.47338676e-01,\n",
       "          9.51679498e-02,  7.71771893e-02,  9.95811168e-03,\n",
       "         -3.67877297e-02, -2.42907509e-01,  2.70246893e-01,\n",
       "         -9.14986506e-02,  5.76827861e-02, -1.52618513e-01,\n",
       "         -2.24990070e-01],\n",
       "        [ 2.37445071e-01, -1.82189494e-01,  1.70087084e-01,\n",
       "         -3.44182178e-02,  1.50573134e-01,  2.86102712e-01,\n",
       "         -9.93481427e-02, -1.76891237e-01, -3.68634194e-01,\n",
       "         -1.10444508e-01, -5.20390905e-02,  3.10325116e-01,\n",
       "          2.56065845e-01,  1.39726549e-01,  2.08123922e-02,\n",
       "          7.74659291e-02],\n",
       "        [ 3.71362194e-02, -2.19863623e-01,  1.86242551e-01,\n",
       "         -1.73732899e-02,  4.58447784e-02,  1.59318119e-01,\n",
       "         -2.46151313e-02, -2.47936919e-01, -1.87146798e-01,\n",
       "         -2.00640276e-01, -2.30843797e-01,  2.09313959e-01,\n",
       "          1.45549431e-01,  3.02416593e-01,  9.01275873e-02,\n",
       "         -3.45585421e-02],\n",
       "        [-8.14518780e-02,  1.62320714e-02, -2.27497771e-01,\n",
       "          2.50020772e-01,  2.52133131e-01, -2.14156240e-01,\n",
       "          2.10860953e-01, -1.09739222e-01, -2.43285373e-01,\n",
       "         -2.77449310e-01,  1.55055165e-01, -1.03175291e-03,\n",
       "          3.04429442e-01, -1.93975911e-01, -6.64204359e-04,\n",
       "          1.40820503e-01],\n",
       "        [ 8.21692795e-02,  7.12049901e-02,  9.13140737e-03,\n",
       "          3.20760667e-01, -3.36928964e-01, -1.32965297e-01,\n",
       "         -9.90792364e-02,  2.31126949e-01, -2.10631102e-01,\n",
       "          3.88679743e-01,  1.62103325e-01,  1.06895939e-01,\n",
       "         -7.31869340e-02, -2.62700588e-01,  2.19224125e-01,\n",
       "         -1.67565256e-01],\n",
       "        [ 1.63005125e-02,  1.59432769e-01,  1.18668482e-01,\n",
       "         -6.33130372e-02, -1.62234455e-01,  1.50645465e-01,\n",
       "         -1.48611560e-01,  1.51471391e-01, -1.14941657e-01,\n",
       "          3.90249729e-01,  2.25210354e-01, -6.52308017e-02,\n",
       "         -2.40787700e-01,  1.73076138e-01, -2.18718991e-01,\n",
       "         -1.26109213e-01],\n",
       "        [ 1.29904777e-01, -2.97784265e-02,  4.56977375e-02,\n",
       "         -1.46367043e-01,  7.30140600e-03,  2.16454044e-01,\n",
       "         -1.20410003e-01,  1.51985005e-01,  1.28928408e-01,\n",
       "         -1.27533570e-01,  1.85700357e-01, -2.13552758e-01,\n",
       "          2.89550284e-03,  1.58678561e-01, -2.20854104e-01,\n",
       "          2.83878088e-01],\n",
       "        [-2.24890962e-01,  6.99302852e-02,  1.73872009e-01,\n",
       "         -2.13421971e-01,  3.95261049e-01,  3.37041281e-02,\n",
       "         -2.42313802e-01, -2.60334909e-01,  1.02298915e-01,\n",
       "         -1.13392085e-01,  9.78304222e-02, -1.85665730e-02,\n",
       "          1.36574373e-01, -3.11905053e-02, -1.65813982e-01,\n",
       "          1.99553385e-01],\n",
       "        [-5.08387126e-02, -1.04053587e-01,  1.29067022e-02,\n",
       "         -7.00403005e-02,  2.98945099e-01,  6.35510078e-03,\n",
       "         -2.22170249e-01,  7.99449906e-02, -3.40587527e-01,\n",
       "         -3.16960454e-01,  2.04739794e-01, -1.82766363e-01,\n",
       "          1.82795167e-01, -1.18548460e-01, -2.74481863e-01,\n",
       "          2.14226440e-01],\n",
       "        [ 2.86762625e-01,  2.15019166e-01, -2.28274032e-01,\n",
       "         -2.04126447e-01, -3.59550379e-02,  1.57396168e-01,\n",
       "          1.28484175e-01,  6.92368820e-02, -2.41919920e-01,\n",
       "         -2.08743677e-01,  2.60506660e-01, -1.97588012e-01,\n",
       "         -1.63696870e-01,  7.44023127e-03,  1.03554547e-01,\n",
       "          3.30298319e-02],\n",
       "        [ 1.60234615e-01, -1.39868081e-01,  2.62909811e-02,\n",
       "          1.50934223e-03, -1.74729470e-02,  1.90895185e-01,\n",
       "          2.48289138e-01,  8.59665275e-02, -2.62762189e-01,\n",
       "         -6.07480621e-03,  1.26399308e-01,  3.18723023e-02,\n",
       "          2.54721344e-01,  1.52466118e-01, -2.70894170e-02,\n",
       "          1.05814524e-01],\n",
       "        [-2.38896444e-01,  1.75798997e-01,  2.28232220e-01,\n",
       "          1.51839346e-01, -5.60630150e-02,  1.69747859e-01,\n",
       "          3.26228105e-02,  6.52738437e-02, -2.89782565e-02,\n",
       "         -6.02024868e-02,  6.93405196e-02,  3.45748812e-01,\n",
       "          2.11008489e-01, -4.97768015e-01, -1.33009925e-01,\n",
       "          1.31871536e-01],\n",
       "        [-2.01347321e-01,  4.23913151e-01,  1.90157250e-01,\n",
       "          4.04062659e-01,  2.05380261e-01, -1.47007897e-01,\n",
       "         -9.89527907e-03,  1.15172677e-01, -9.35817063e-02,\n",
       "         -6.89275116e-02, -4.35899347e-01,  2.30404377e-01,\n",
       "         -1.15566164e-01,  1.24377443e-03,  2.28460729e-02,\n",
       "         -3.92422795e-01],\n",
       "        [-2.32721400e-02,  1.50945336e-01, -9.02928114e-02,\n",
       "          2.50482112e-01,  2.34635007e-02, -1.59914792e-01,\n",
       "         -6.13939688e-02,  6.42355829e-02, -6.27540201e-02,\n",
       "          1.71578899e-01, -1.32050619e-01, -1.50303379e-01,\n",
       "         -2.02916607e-01, -1.41477823e-01, -5.69665432e-02,\n",
       "         -1.63733829e-02],\n",
       "        [ 2.00231239e-01, -1.09874487e-01, -2.65220646e-04,\n",
       "         -1.17590301e-01, -1.86783805e-01,  2.78710783e-01,\n",
       "         -1.06544353e-01, -1.40116336e-02,  2.60423511e-01,\n",
       "          8.10519680e-02,  2.35484749e-01, -4.57797229e-01,\n",
       "         -1.06360748e-01,  3.19286399e-02, -8.09407383e-02,\n",
       "          1.51913181e-01],\n",
       "        [ 1.60766050e-01, -1.47021905e-01, -1.38028085e-01,\n",
       "         -1.17565960e-01, -2.84742504e-01, -1.74580529e-01,\n",
       "          2.02454343e-01,  2.88015813e-01,  1.69432342e-01,\n",
       "         -2.41288245e-02, -2.14031890e-01, -1.38870820e-01,\n",
       "         -1.55548885e-01,  3.13875109e-01, -1.87649369e-01,\n",
       "         -5.35605662e-02],\n",
       "        [-3.71352285e-01,  8.61708075e-02, -5.64463399e-02,\n",
       "          2.04637721e-01, -2.10558265e-01, -1.03016190e-01,\n",
       "          4.11509901e-01,  1.00806234e-02,  2.26424724e-01,\n",
       "          4.00723934e-01,  4.56418358e-02,  2.99099445e-01,\n",
       "         -3.92212540e-01, -7.24171400e-02,  2.07517892e-01,\n",
       "         -3.01129986e-02],\n",
       "        [-2.46432766e-01,  2.63195097e-01,  2.25707531e-01,\n",
       "         -5.54317795e-02,  4.78908047e-02, -8.22395086e-02,\n",
       "         -7.20165819e-02,  1.11437008e-01,  2.91378409e-01,\n",
       "          3.03546727e-01,  4.04921807e-02,  2.38578334e-01,\n",
       "          6.71002865e-02,  1.18874826e-01,  3.40649188e-02,\n",
       "          1.69065654e-01],\n",
       "        [ 3.32386680e-02,  1.30390823e-01, -2.31533393e-01,\n",
       "         -3.47307950e-01, -2.29227841e-02, -1.21379122e-01,\n",
       "         -2.89904922e-01,  1.25928357e-01,  1.54827759e-01,\n",
       "         -2.92035460e-01,  2.56093115e-01, -1.22485138e-01,\n",
       "          2.75575612e-02,  1.19430944e-01,  7.32214153e-02,\n",
       "         -2.13320285e-01],\n",
       "        [-3.67327154e-01, -1.27588451e-01,  3.14760089e-01,\n",
       "         -3.85123007e-02, -1.54872850e-01, -3.27188253e-01,\n",
       "          2.26773933e-01,  1.09474339e-01,  2.63404667e-01,\n",
       "          2.16541424e-01, -1.50586903e-01, -8.30250829e-02,\n",
       "          1.05149589e-01, -2.48858020e-01,  1.99261129e-01,\n",
       "          7.60571957e-02],\n",
       "        [-2.64331758e-01, -8.80061388e-02, -7.21860826e-02,\n",
       "          2.20714375e-01,  1.07507572e-01, -4.63414900e-02,\n",
       "          3.15343961e-03, -7.35886171e-02,  2.43971735e-01,\n",
       "          9.53319594e-02, -3.21160294e-02,  1.16562665e-01,\n",
       "          2.64841676e-01,  2.22829133e-01, -9.83082503e-02,\n",
       "         -8.70835185e-02],\n",
       "        [ 3.23805541e-01, -3.04594636e-01,  1.05977736e-01,\n",
       "         -2.15077683e-01, -2.48720184e-01, -2.50041671e-02,\n",
       "         -2.92751282e-01,  1.35817721e-01,  1.81023642e-01,\n",
       "         -8.40687677e-02,  3.59660715e-01, -8.43026638e-02,\n",
       "         -1.86526582e-01,  4.87915874e-02, -1.25570297e-02,\n",
       "         -1.61523923e-01],\n",
       "        [ 1.59386978e-01,  2.27768764e-01, -8.23223740e-02,\n",
       "          2.67282397e-01, -4.24956232e-01,  8.32277834e-02,\n",
       "         -2.40479439e-01,  1.41602084e-01, -7.27274343e-02,\n",
       "         -1.22677289e-01,  2.35103056e-01, -1.87244937e-01,\n",
       "         -2.35343084e-01, -6.91170394e-02, -7.73535669e-02,\n",
       "         -8.24462250e-02],\n",
       "        [-7.54404394e-03,  3.27738613e-01,  8.85838196e-02,\n",
       "         -2.12229118e-02, -3.12191471e-02, -3.31116170e-01,\n",
       "          4.24139887e-01,  1.24126829e-01, -3.54652628e-02,\n",
       "          3.15789655e-02,  1.33360267e-01, -2.05117371e-03,\n",
       "         -6.72363937e-02, -9.18042511e-02, -3.16468030e-02,\n",
       "         -2.49175832e-01],\n",
       "        [ 3.81232500e-02,  4.19980168e-01,  1.11024886e-01,\n",
       "         -1.03784226e-01,  1.38431609e-01,  4.97384369e-02,\n",
       "          6.00092933e-02, -1.43175036e-01, -6.41756058e-02,\n",
       "          1.42430112e-01, -2.86990613e-01,  2.27645934e-01,\n",
       "         -2.58693863e-02, -2.35854641e-01, -1.97988331e-01,\n",
       "          1.29891947e-01],\n",
       "        [ 2.69380119e-02,  3.86560947e-01,  3.37026596e-01,\n",
       "         -9.31751356e-02, -4.40969855e-01, -2.34342456e-01,\n",
       "          4.47683990e-01,  1.72665715e-01, -2.61001885e-01,\n",
       "          4.19762373e-01,  7.24890530e-02,  5.19130230e-01,\n",
       "         -1.48981363e-01, -2.75479376e-01,  7.79975951e-02,\n",
       "         -1.93191804e-02],\n",
       "        [ 1.66425571e-01,  1.40903562e-01,  2.05872267e-01,\n",
       "         -9.30934548e-02, -9.34030041e-02, -3.03027481e-02,\n",
       "          2.29311436e-01,  8.15638378e-02,  2.79659659e-01,\n",
       "         -2.01048404e-01,  2.33192205e-01, -1.07380390e-01,\n",
       "         -1.20773211e-01, -2.64973491e-01,  9.60889459e-03,\n",
       "         -1.60148423e-02],\n",
       "        [ 5.28306589e-02, -8.78748670e-02,  2.18118191e-01,\n",
       "          1.86753303e-01,  8.83285925e-02, -2.79555261e-01,\n",
       "          2.19939485e-01,  6.56102598e-02,  2.77716130e-01,\n",
       "         -4.42830533e-01, -1.24665447e-01,  4.56273220e-02,\n",
       "         -1.17425784e-01, -1.04361683e-01, -1.78067625e-01,\n",
       "         -3.80020738e-01],\n",
       "        [-2.07041934e-01, -1.85968637e-01, -4.82202210e-02,\n",
       "          1.91778839e-01, -9.10593793e-02, -1.29053682e-01,\n",
       "         -3.57606560e-01, -2.16530189e-01,  3.04499030e-01,\n",
       "         -1.13974400e-01, -5.21483421e-02,  3.41362029e-01,\n",
       "          3.77521157e-01, -3.79842490e-01, -6.84122294e-02,\n",
       "         -2.36115143e-01],\n",
       "        [ 2.54019856e-01, -2.74131715e-01, -2.59148479e-01,\n",
       "          1.99908111e-02, -1.89279020e-01, -4.64197733e-02,\n",
       "         -2.19179019e-01,  1.11796305e-01,  5.18672913e-02,\n",
       "         -3.23422663e-02, -2.93503664e-02,  1.46335036e-01,\n",
       "         -2.05514044e-01, -3.16622019e-01, -1.00100935e-02,\n",
       "         -1.00920707e-01],\n",
       "        [ 4.64734346e-01, -7.02251941e-02, -2.96793938e-01,\n",
       "         -3.51917624e-01, -1.39773503e-01, -2.64085662e-02,\n",
       "         -3.24213430e-02, -3.38269532e-01,  9.18414146e-02,\n",
       "         -8.80225897e-02,  4.27063614e-01, -2.01715231e-01,\n",
       "          2.35386789e-02,  1.54890150e-01,  2.08242655e-01,\n",
       "         -5.53719178e-02],\n",
       "        [-2.42188141e-01,  5.48559427e-01,  3.46842408e-01,\n",
       "          1.89831346e-01,  2.06031114e-01, -5.23498535e-01,\n",
       "         -2.48786405e-01,  3.45194906e-01,  1.48008674e-01,\n",
       "          1.31867066e-01, -1.13325797e-01,  1.93472460e-01,\n",
       "          1.17650688e-01, -5.60716391e-01,  2.43448168e-01,\n",
       "         -3.67493778e-01],\n",
       "        [-4.00547162e-02,  3.49485993e-01,  4.66180682e-01,\n",
       "          1.22924969e-01, -1.75542429e-01, -2.01221511e-01,\n",
       "          2.51297615e-02,  4.77441669e-01,  2.92130023e-01,\n",
       "         -1.04861490e-01, -3.92114997e-01,  3.52277666e-01,\n",
       "          4.94638421e-02,  4.14830595e-01,  2.37366468e-01,\n",
       "         -6.55457145e-03],\n",
       "        [-4.16254908e-01,  1.47720858e-01,  5.15875518e-01,\n",
       "          2.09405333e-01,  1.82050228e-01, -9.21920240e-02,\n",
       "          4.36711721e-02,  3.28673780e-01, -2.71688849e-01,\n",
       "          6.69729039e-02, -1.31280228e-01,  2.42962897e-01,\n",
       "         -1.73334733e-01, -2.40967304e-01,  2.26543278e-01,\n",
       "         -7.38274753e-02],\n",
       "        [ 1.36434520e-02,  1.65631756e-01,  3.89422953e-01,\n",
       "          3.33977699e-01, -1.34751111e-01, -2.58385539e-01,\n",
       "          1.49486363e-01,  2.16987073e-01, -9.45263728e-02,\n",
       "         -2.98847198e-01,  1.58470899e-01,  5.80756068e-01,\n",
       "          6.26474023e-01, -3.12028915e-01,  2.77244955e-01,\n",
       "          1.55920729e-01],\n",
       "        [-9.77838188e-02,  3.93569946e-01,  3.77987385e-01,\n",
       "          5.34045696e-01, -8.22616443e-02, -2.40651011e-01,\n",
       "          1.23630024e-01, -3.75208668e-02, -1.41754255e-01,\n",
       "         -1.13596218e-02, -4.12820041e-01, -9.31080803e-02,\n",
       "         -5.70044713e-03,  6.18049540e-02, -8.98098946e-03,\n",
       "         -2.34418780e-01],\n",
       "        [ 1.12405829e-01,  8.85103270e-02, -3.06938887e-02,\n",
       "         -1.18001945e-01,  2.75095552e-01, -3.45145851e-01,\n",
       "         -2.98935980e-01, -3.95975634e-02,  4.36311364e-01,\n",
       "         -8.35751057e-01,  3.88286859e-02, -3.14756453e-01,\n",
       "          9.86469015e-02,  5.98518997e-02,  9.24748182e-03,\n",
       "         -2.56596595e-01],\n",
       "        [-2.73122311e-01,  3.93439591e-01,  3.72488201e-01,\n",
       "          6.18905842e-01, -1.12712262e-02, -2.66788960e-01,\n",
       "          1.77773163e-01,  3.89227599e-01, -1.86369911e-01,\n",
       "         -3.22294384e-02, -1.38981819e-01,  4.90518391e-01,\n",
       "          1.75416008e-01, -9.17129442e-02, -2.52138078e-01,\n",
       "         -5.15089273e-01],\n",
       "        [ 5.18656000e-02,  3.33804101e-01,  3.06425571e-01,\n",
       "          1.18445128e-01, -2.26367787e-01, -5.96211888e-02,\n",
       "          1.19548835e-01, -2.18354881e-01, -1.74786910e-01,\n",
       "          1.11343183e-01,  2.54073083e-01,  2.39270972e-03,\n",
       "          4.28947538e-01,  4.31373566e-01, -1.04723275e-02,\n",
       "          7.02558607e-02],\n",
       "        [-1.73303351e-01,  6.17965423e-02,  1.51834548e-01,\n",
       "          4.49015945e-01, -2.76596367e-01,  1.53939025e-02,\n",
       "          7.30455443e-02,  2.93970648e-02, -2.34109178e-01,\n",
       "          1.30023658e-01,  2.05552438e-03,  4.26498726e-02,\n",
       "          5.73858380e-01,  6.70519173e-01,  1.03603005e-01,\n",
       "         -6.90828636e-02],\n",
       "        [-5.49298346e-01,  6.59879684e-01,  2.62521595e-01,\n",
       "          1.89350635e-01, -1.43390387e-01, -3.66726220e-01,\n",
       "          3.18893969e-01,  5.75003505e-01, -4.64006633e-01,\n",
       "          2.23230883e-01, -1.86559036e-01,  3.16556633e-01,\n",
       "         -1.39118925e-01,  3.14148098e-01, -1.66813463e-01,\n",
       "         -3.29117984e-01],\n",
       "        [ 2.52266884e-01,  2.87817046e-02,  3.04402441e-01,\n",
       "          1.56737030e-01, -1.30131975e-01, -6.80826753e-02,\n",
       "          5.99482842e-02,  1.92195192e-01, -4.02458280e-01,\n",
       "          4.27494824e-01,  2.22436145e-01, -6.54425286e-03,\n",
       "         -8.55596736e-02,  3.68168145e-01,  1.13050759e-01,\n",
       "          1.72491670e-01]], dtype=float32),\n",
       " array([-0.03458152,  0.07324153,  0.04377855,  0.01312482, -0.01028148,\n",
       "        -0.00929066, -0.0464382 ,  0.04109639, -0.02517296,  0.05938857,\n",
       "        -0.02997674,  0.02836474,  0.05298721, -0.06309867,  0.        ,\n",
       "        -0.01849931], dtype=float32),\n",
       " array([[ 0.25538966],\n",
       "        [-0.1919462 ],\n",
       "        [-0.48104525],\n",
       "        [-0.44472945],\n",
       "        [-0.7471472 ],\n",
       "        [ 0.57655096],\n",
       "        [-1.0940189 ],\n",
       "        [-0.5887116 ],\n",
       "        [ 0.82325107],\n",
       "        [-1.5421866 ],\n",
       "        [ 0.21888067],\n",
       "        [-0.60385305],\n",
       "        [-1.2320873 ],\n",
       "        [ 1.0208439 ],\n",
       "        [ 0.44682717],\n",
       "        [ 0.53097385]], dtype=float32),\n",
       " array([-0.02747042], dtype=float32)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les poids finaux après entraînement\n",
    "model1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history = history):\n",
    "    \n",
    "    # Retrieve a list of accuracy results on training and validation data sets for each training epoch\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    # Retrieve a list of list results on training and validation data sets for each training epoch\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Get number of epochs : 1 -> n_epochs\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Plot training and validation accuracy per epoch\n",
    "#     plt.figure(figsize = (20, 10))\n",
    "#     plt.plot(epochs, acc)\n",
    "#     plt.plot(epochs, val_acc)\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Validation'], loc = 'upper left')\n",
    "    \n",
    "#     plt.figure(figsize = (20, 10))\n",
    "\n",
    "    # Plot training and validation loss per epoch\n",
    "    plt.plot(epochs, loss)\n",
    "    plt.plot(epochs, val_loss)\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "y_proba = model1.predict(test_x)\n",
    "#yPred = model.predict(test_x)\n",
    "# y_proba\n",
    "#y_pred = rn_tf_d2.predict_classes(X_test)\n",
    "# y_pred\n",
    "\n",
    "pd.DataFrame({'y_proba' : y_proba, 'yPred' : yPred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8005 - accuracy: 0.4600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8005412220954895, 0.46000000834465027]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perfermance en test\n",
    "score = model1.evaluate(test_x, test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(test_y, yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
